#include "solver/optimizer/CMAES/CMAES.hpp"
#include "engine/sample/sample.hpp"
#include "conduit/conduit.hpp"

#include <stdio.h>
#include <unistd.h>
#include <chrono>
#include <numeric>   // std::iota
#include <algorithm> // std::sort

void korali::solver::optimizer::CMAES::initialize()
{
 korali::solver::Optimizer::initialize();

 // Initializing RNGs
 auto jsNormal = nlohmann::json();
 jsNormal["Name"] = "Normal Generator";
 jsNormal["Type"] = "Univariate/Normal";
 jsNormal["Mean"] = 0.0;
 jsNormal["Standard Deviation"] = 1.0;
 _normalGenerator = dynamic_cast<korali::distribution::univariate::Normal*>(korali::Module::getModule(jsNormal));
 _normalGenerator->initialize();

 auto jsUniform = nlohmann::json();
 jsUniform["Name"] = "Uniform Generator";
 jsUniform["Type"] = "Univariate/Uniform";
 jsUniform["Minimum"] = 0.0;
 jsUniform["Maximum"] = 1.0;
 _uniformGenerator = dynamic_cast<korali::distribution::univariate::Uniform*>(korali::Module::getModule(jsUniform));
 _uniformGenerator->initialize();

 _directProblem = dynamic_cast<korali::problem::evaluation::Direct*>(_k->_problem);
 bool isDirectProblem = _directProblem != NULL;

 _evaluationProblem = dynamic_cast<korali::problem::Evaluation*>(_k->_problem);
 bool isEvaluationProblem = _evaluationProblem != NULL;

 if (isEvaluationProblem == false)
  korali::logError("CMAES can only optimize problems of type 'Evaluation' or derived.\n");

 if(isDirectProblem == true)
 if (_directProblem->_objective == "Maximize") _bestEverValue = -std::numeric_limits<double>::infinity();
 else /* Minimize */                           _bestEverValue = +std::numeric_limits<double>::infinity();
 
 _bestEverValue = -std::numeric_limits<double>::infinity();

 N = _k->_variables.size();

 if (_currentGeneration > 1) return;

 size_t s_max  = std::max(_populationSize,  _viabilityPopulationSize);
 size_t mu_max = std::max(_muValue, _viabilityMuValue);

 _chiSquareNumber = sqrt((double) N) * (1. - 1./(4.*N) + 1./(21.*N*N));
 _chiSquareNumberDiscreteMutations = sqrt((double) N) * (1. - 1./(4.*N) + 1./(21.*N*N));

 if (isDirectProblem == false)
 {
  _areConstraintsDefined = false;
  _hasDiscreteVariables = false;
 }
 else
 {
  _areConstraintsDefined = (_directProblem->_constraints.size() > 0);
  _hasDiscreteVariables = _directProblem->_hasDiscreteVariables;
 }

 _isViabilityRegime = _areConstraintsDefined;

 if(_isViabilityRegime) {
     _currentPopulationSize = _viabilityPopulationSize;
     _currentMuValue    = _viabilityMuValue;
 } else {
     _currentPopulationSize = _populationSize;
     _currentMuValue    = _muValue;
 }

 // Allocating Memory
 _samplePopulation.resize(s_max);
 for(size_t i = 0; i < s_max; i++) _samplePopulation[i].resize(N);

 _evolutionPath.resize(N);
 _conjugateEvolutionPath.resize(N);
 _auxiliarBDZMatrix.resize(N);
 _meanUpdate.resize(N);
 _currentMean.resize(N);
 _previousMean.resize(N);
 _bestEverVariables.resize(N);
 _axisLengths.resize(N);
 _auxiliarAxisLengths.resize(N);
 _currentBestVariables.resize(N);

 _sortingIndex.resize(s_max);
 _valueVector.resize(s_max);

 _covarianceMatrix.resize(N*N);
 _auxiliarCovarianceMatrix.resize(N*N);
 _covarianceEigenvectorMatrix.resize(N*N);
 _auxiliarCovarianceEigenvectorMatrix.resize(N*N);
 _bDZMatrix.resize(s_max*N);

 _maskingMatrix.resize(N);
 _maskingMatrixSigma.resize(N);
 _discreteMutations.resize(N*_populationSize);
 std::fill( std::begin(_discreteMutations), std::end(_discreteMutations), 0.0);

 _numberMaskingMatrixEntries = 0;
 _numberOfDiscreteMutations = 0;
 _muWeights.resize(mu_max);

 // Initializing variable defaults

 if (isDirectProblem == false)
 {
  for (size_t i = 0; i < N; i++)
  {
    if( std::isfinite(_k->_variables[i]->_initialMean) == false )
      korali::logError("Initial Mean of variable \'%s\' not defined (no defaults can be calculated).\n", _k->_variables[i]->_name.c_str());
    if( std::isfinite(_k->_variables[i]->_initialStandardDeviation) == false)
      korali::logError("Initial Standard Deviation of variable \'%s\' not defined (no defaults can be calculated).\n", _k->_variables[i]->_name.c_str());
  }
 }
 else
 {
  for (size_t i = 0; i < N; i++)
  {
    if(std::isfinite(_k->_variables[i]->_initialMean) == false)
    {
     if(std::isfinite(_k->_variables[i]->_lowerBound) == false) korali::logError("Initial Mean of variable \'%s\' not defined, and cannot be inferred because variable lower bound is not finite.\n", _k->_variables[i]->_name.c_str());
     if(std::isfinite(_k->_variables[i]->_upperBound) == false) korali::logError("Initial Mean of variable \'%s\' not defined, and cannot be inferred because variable upper bound is not finite.\n", _k->_variables[i]->_name.c_str());
     _k->_variables[i]->_initialMean = (_k->_variables[i]->_upperBound + _k->_variables[i]->_lowerBound)*0.5;
    }

    if(std::isfinite(_k->_variables[i]->_initialStandardDeviation) == false)
    {
     if(std::isfinite(_k->_variables[i]->_lowerBound) == false) korali::logError("Initial Mean of variable \'%s\' not defined, and cannot be inferred because variable lower bound is not finite.\n", _k->_variables[i]->_name.c_str());
     if(std::isfinite(_k->_variables[i]->_upperBound) == false) korali::logError("Initial Standard Deviation \'%s\' not defined, and cannot be inferred because variable upper bound is not finite.\n", _k->_variables[i]->_name.c_str());
     _k->_variables[i]->_initialStandardDeviation = (_k->_variables[i]->_upperBound - _k->_variables[i]->_lowerBound)*0.3;
    }

    if(_k->_variables[i]->_initialMean < _k->_variables[i]->_lowerBound || _k->_variables[i]->_initialMean > _k->_variables[i]->_upperBound)
    korali::logError("Initial Mean (%.4f) of variable \'%s\' is out of bounds (%.4f-%.4f).\n",
             _k->_variables[i]->_initialMean,
             _k->_variables[i]->_name.c_str(),
             _k->_variables[i]->_lowerBound,
             _k->_variables[i]->_upperBound);
  }
 }

 // CMAES variables
 if (_areConstraintsDefined)
 {
  if( (_globalSuccessLearningRate <= 0.0) || (_globalSuccessLearningRate > 1.0) )
    korali::logError("Invalid Global Success Learning Rate (%f), must be greater than 0.0 and less than 1.0\n",  _globalSuccessLearningRate );
  if( (_targetSuccessRate <= 0.0) || (_targetSuccessRate > 1.0) )
    korali::logError("Invalid Target Success Rate (%f), must be greater than 0.0 and less than 1.0\n",  _targetSuccessRate );
  if(_covarianceMatrixAdaptionStrength <= 0.0)
    korali::logError("Invalid Adaption Size (%f), must be greater than 0.0\n", _covarianceMatrixAdaptionStrength );

  _globalSuccessRate = 0.5;
  _bestValidSample   = -1;
  _sampleConstraintViolationCounts.resize(s_max);
  _viabilityBoundaries.resize(_directProblem->_constraints.size());

  _viabilityImprovement.resize(s_max);
  _viabilityIndicator.resize(_directProblem->_constraints.size());
  _constraintEvaluations.resize(_directProblem->_constraints.size());

  for (size_t c = 0; c < _directProblem->_constraints.size(); c++) _viabilityIndicator[c].resize(s_max);
  for (size_t c = 0; c < _directProblem->_constraints.size(); c++) _constraintEvaluations[c].resize(s_max);

  _normalConstraintApproximation.resize(_directProblem->_constraints.size());
  for (size_t i = 0; i < _directProblem->_constraints.size(); i++) _normalConstraintApproximation[i].resize(N);

  _bestConstraintEvaluations.resize(_directProblem->_constraints.size());

  _normalVectorLearningRate = 1.0/(2.0+N);
  _covarianceMatrixAdaptionFactor = _covarianceMatrixAdaptionStrength/(N+2.);
 }
 else
 {
  _globalSuccessRate = -1.0;
  _covarianceMatrixAdaptionFactor = -1.0;
  _bestValidSample = 0;
 }

 _covarianceMatrixAdaptationCount = 0;
 _maxConstraintViolationCount = 0;

 // Setting algorithm internal variables
 if (_areConstraintsDefined) initMuWeights(_viabilityMuValue);
 else initMuWeights(_muValue);

 initCovariance();

 _infeasibleSampleCount   = 0;
 _resampledParameterCount = 0;

 _conjugateEvolutionPathL2Norm = 0.0;

 for (size_t i = 0; i < N; i++) _currentMean[i] = _previousMean[i] = _k->_variables[i]->_initialMean;

 _currentMinStandardDeviation = +std::numeric_limits<double>::infinity();
 _currentMaxStandardDeviation = -std::numeric_limits<double>::infinity();

}

void korali::solver::optimizer::CMAES::runGeneration()
{

 if ( _areConstraintsDefined ) checkMeanAndSetRegime();
 prepareGeneration();
 if ( _areConstraintsDefined ){ updateConstraints(); handleConstraints(); }

 // Initializing Sample Evaluation
 std::vector<korali::Sample> samples(_currentPopulationSize);
 for (size_t i = 0; i < _currentPopulationSize; i++)
 {
  samples[i]["Operation"] = "Basic Evaluation";
  samples[i]["Parameters"] = _samplePopulation[i];
  samples[i]["Sample Id"] = i;
  _modelEvaluationCount++;
  _k->_conduit->start(samples[i]);
 }

 // Waiting for samples to finish
 _k->_conduit->waitAll(samples);

 // Processing results
 for (size_t i = 0; i < _currentPopulationSize; i++)
  _valueVector[i] = samples[i]["Evaluation"];

 updateDistribution();
}

void korali::solver::optimizer::CMAES::initMuWeights(size_t numsamplesmu)
{
 // Initializing Mu Weights
 if      (_muType == "Linear")       for (size_t i = 0; i < numsamplesmu; i++) _muWeights[i] = numsamplesmu - i;
 else if (_muType == "Equal")        for (size_t i = 0; i < numsamplesmu; i++) _muWeights[i] = 1.;
 else if (_muType == "Logarithmic")  for (size_t i = 0; i < numsamplesmu; i++) _muWeights[i] = log(std::max( (double)numsamplesmu, 0.5*_currentPopulationSize)+0.5)-log(i+1.);
 else  korali::logError("Invalid setting of Mu Type (%s) (Linear, Equal, or Logarithmic accepted).",  _muType.c_str());

 // Normalize weights vector and set mueff
 double s1 = 0.0;
 double s2 = 0.0;

 for (size_t i = 0; i < numsamplesmu; i++)
 {
  s1 += _muWeights[i];
  s2 += _muWeights[i]*_muWeights[i];
 }
 _effectiveMu = s1*s1/s2;

 for (size_t i = 0; i < numsamplesmu; i++) _muWeights[i] /= s1;

 // Setting Cumulative Covariancea
 if( (_initialCumulativeCovariance <= 0) || (_initialCumulativeCovariance > 1) ) _cumulativeCovariance = (4.0 + _effectiveMu/(1.0*N)) / (N+4.0 + 2.0*_effectiveMu/(1.0*N));
 else _cumulativeCovariance = _initialCumulativeCovariance;

 // Setting Sigma Cumulation Factor
 _sigmaCumulationFactor = _initialSigmaCumulationFactor;
 if (_sigmaCumulationFactor <= 0 || _sigmaCumulationFactor >= 1)
    if (_areConstraintsDefined) _sigmaCumulationFactor = sqrt(_effectiveMu) / ( sqrt(_effectiveMu) + sqrt(N) );
    else                     _sigmaCumulationFactor = (_effectiveMu + 2.0) / (N + _effectiveMu + 3.0);

 // Setting Damping Factor
 _dampFactor = _initialDampFactor;
 if (_dampFactor <= 0.0)
     _dampFactor = (1.0 + 2*std::max(0.0, sqrt((_effectiveMu-1.0)/(N+1.0)) - 1)) + _sigmaCumulationFactor;

}


void korali::solver::optimizer::CMAES::initCovariance()
{

 // Setting Sigma
 _trace = 0.0;
 for (size_t i = 0; i < N; ++i) _trace += _k->_variables[i]->_initialStandardDeviation*_k->_variables[i]->_initialStandardDeviation;
 _sigma = sqrt(_trace/N);

 // Setting B, C and _axisD
 for (size_t i = 0; i < N; ++i)
 {
  _covarianceEigenvectorMatrix[i*N+i] = 1.0;
  _covarianceMatrix[i*N+i] = _axisLengths[i] = _k->_variables[i]->_initialStandardDeviation * sqrt(N / _trace);
  _covarianceMatrix[i*N+i] *= _covarianceMatrix[i*N+i];
 }

 _minimumCovarianceEigenvalue = *std::min_element(std::begin(_axisLengths), std::end(_axisLengths));
 _maximumCovarianceEigenvalue = *std::max_element(std::begin(_axisLengths), std::end(_axisLengths));

 _minimumCovarianceEigenvalue = _minimumCovarianceEigenvalue * _minimumCovarianceEigenvalue;
 _maximumCovarianceEigenvalue = _maximumCovarianceEigenvalue * _maximumCovarianceEigenvalue;

 _maximumDiagonalCovarianceMatrixElement=_covarianceMatrix[0]; for(size_t i=1;i<N;++i) if(_maximumDiagonalCovarianceMatrixElement<_covarianceMatrix[i*N+i]) _maximumDiagonalCovarianceMatrixElement=_covarianceMatrix[i*N+i];
 _minimumDiagonalCovarianceMatrixElement=_covarianceMatrix[0]; for(size_t i=1;i<N;++i) if(_minimumDiagonalCovarianceMatrixElement>_covarianceMatrix[i*N+i]) _minimumDiagonalCovarianceMatrixElement=_covarianceMatrix[i*N+i];
}


void korali::solver::optimizer::CMAES::checkMeanAndSetRegime()
{
  if (_isViabilityRegime == false) return; /* mean already inside valid domain, no udpates */

  korali::Sample sample;
  sample["Parameters"] = _currentMean;
  sample["Operation"] = "Evaluate Constraints";
  _k->_conduit->start(sample);
  _k->_conduit->wait(sample);
  _constraintEvaluationCount++;

  for (size_t c = 0; c < _directProblem->_constraints.size(); c++)
    if (sample["Constraint Evaluations"][c] > 0.0) return; /* mean violates constraint, do nothing */

  /* mean inside domain, switch regime and update internal variables */
  _isViabilityRegime = false;

  for (size_t c = 0; c < _directProblem->_constraints.size(); c++) { _viabilityBoundaries[c] = 0; }
  _currentPopulationSize = _populationSize;
  _currentMuValue = _muValue;

  _bestEverValue = -std::numeric_limits<double>::infinity();
  initMuWeights(_currentMuValue);
  initCovariance();
}


void korali::solver::optimizer::CMAES::updateConstraints()
{
 for(size_t i = 0; i < _currentPopulationSize; i++)
 {
  _sampleConstraintViolationCounts[i] = 0;

  korali::Sample sample;
  sample["Parameters"] = _samplePopulation[i];
  sample["Operation"] = "Evaluate Constraints";
  _k->_conduit->start(sample);
  _k->_conduit->wait(sample);
  _constraintEvaluationCount++;

  for(size_t c = 0; c < _directProblem->_constraints.size(); c++) _constraintEvaluations[c][i] = sample["Constraint Evaluations"][c];
 }

 _maxConstraintViolationCount = 0;

 for(size_t c = 0; c < _directProblem->_constraints.size(); c++)
 {
  double maxviolation = 0.0;
  for(size_t i = 0; i < _currentPopulationSize; ++i)
  {
    if ( _constraintEvaluations[c][i] > maxviolation ) maxviolation = _constraintEvaluations[c][i];
    if ( _currentGeneration == 1 && _isViabilityRegime ) _viabilityBoundaries[c] = maxviolation;

    if ( _constraintEvaluations[c][i] > _viabilityBoundaries[c] + 1e-12 ) _sampleConstraintViolationCounts[i]++;
    if ( _sampleConstraintViolationCounts[i] > _maxConstraintViolationCount ) _maxConstraintViolationCount = _sampleConstraintViolationCounts[i];
  }
 }
}


void korali::solver::optimizer::CMAES::reEvaluateConstraints()
{
  _maxConstraintViolationCount = 0;

  for(size_t i = 0; i < _currentPopulationSize; ++i) if(_sampleConstraintViolationCounts[i] > 0)
  {
   korali::Sample sample;
   sample["Parameters"] = _samplePopulation[i];
   sample["Operation"] = "Evaluate Constraints";
   _k->_conduit->start(sample);
   _k->_conduit->wait(sample);
   _constraintEvaluationCount++;

    _sampleConstraintViolationCounts[i] = 0;
    for(size_t c = 0; c < _directProblem->_constraints.size(); c++)
    {
      _constraintEvaluations[c][i] = sample["Constraint Evaluations"][c];
      if( _constraintEvaluations[c][i] > _viabilityBoundaries[c] + 1e-12 ) { _viabilityIndicator[c][i] = true; _sampleConstraintViolationCounts[i]++; }
      else _viabilityIndicator[c][i] = false;
    }
    if (_sampleConstraintViolationCounts[i] > _maxConstraintViolationCount) _maxConstraintViolationCount = _sampleConstraintViolationCounts[i];
  }
}


void korali::solver::optimizer::CMAES::updateViabilityBoundaries()
{
 for(size_t c = 0; c < _directProblem->_constraints.size(); c++)
 {
  double maxviolation = 0.0;
  for(size_t i = 0; i < _currentMuValue /* _currentPopulationSize alternative */ ; ++i) if (_constraintEvaluations[c][_sortingIndex[i]] > maxviolation)
    maxviolation = _constraintEvaluations[c][_sortingIndex[i]];

  _viabilityBoundaries[c] = std::max( 0.0, std::min(_viabilityBoundaries[c], 0.5*(maxviolation + _viabilityBoundaries[c])) );
 }
}

void korali::solver::optimizer::CMAES::prepareGeneration()
{
 for (size_t d = 0; d < N; ++d) _auxiliarCovarianceMatrix = _covarianceMatrix;
 updateEigensystem(_auxiliarCovarianceMatrix);
 for (size_t i = 0; i < _currentPopulationSize; ++i)
 {
   sampleSingle(i);

   korali::Sample sample;
   sample["Parameters"] = _samplePopulation[i];
   while(_evaluationProblem->isSampleFeasible(sample) == false )
   {
     _infeasibleSampleCount++;
     sampleSingle(i);
     sample["Parameters"] = _samplePopulation[i];
   }
 }
}

void korali::solver::optimizer::CMAES::sampleSingle(size_t sampleIdx)
{
  for (size_t d = 0; d < N; ++d)
  {
   double randomNumber = _normalGenerator->getRandomNumber();

   if (_isDiagonal)
   {
     _bDZMatrix[sampleIdx*N+d] = _axisLengths[d] * randomNumber;
     _samplePopulation[sampleIdx][d] = _currentMean[d] + _sigma * _bDZMatrix[sampleIdx*N+d];
   }
   else _auxiliarBDZMatrix[d] = _axisLengths[d] * randomNumber;
  }

  if (!_isDiagonal) for (size_t d = 0; d < N; ++d)
   {
    _bDZMatrix[sampleIdx*N+d] = 0.0;
    for (size_t e = 0; e < N; ++e) _bDZMatrix[sampleIdx*N+d] += _covarianceEigenvectorMatrix[d*N+e] * _auxiliarBDZMatrix[e];
    _samplePopulation[sampleIdx][d] = _currentMean[d] + _sigma * _bDZMatrix[sampleIdx*N+d];
  }

  if(_hasDiscreteVariables)
  {
    if ( (sampleIdx+1) < _numberOfDiscreteMutations )
    {
      double p_geom = std::pow(0.7, 1.0/_numberMaskingMatrixEntries);
      size_t select = std::floor(_uniformGenerator->getRandomNumber() * _numberMaskingMatrixEntries);

      for(size_t d = 0; d < N; ++d) if( (_maskingMatrix[d] == 1.0) && (select-- == 0) )
      {
        double dmutation = 1.0;
        while(  _uniformGenerator->getRandomNumber() > p_geom ) dmutation += 1.0;
        dmutation *= _k->_variables[d]->_granularity;

        if( _uniformGenerator->getRandomNumber() > 0.5 ) dmutation*=-1.0;
        _discreteMutations[sampleIdx*N+d] = dmutation;
        _samplePopulation[sampleIdx][d] += dmutation;
      }
    }
    else if ( (sampleIdx+1) == _numberOfDiscreteMutations )
    {
      for(size_t d = 0; d < N; ++d) if( _k->_variables[d]->_granularity != 0.0 )
      {
        double dmutation = std::round(_bestEverVariables[d]/_k->_variables[d]->_granularity) * _k->_variables[d]->_granularity - _samplePopulation[sampleIdx][d];
        _discreteMutations[sampleIdx*N+d] = dmutation;
        _samplePopulation[sampleIdx][d] += dmutation;
      }
    }
  }
}


void korali::solver::optimizer::CMAES::updateDistribution()
{

 /* Generate _sortingIndex */
 sort_index(_valueVector, _sortingIndex, _currentPopulationSize);

 if( (_areConstraintsDefined == false) ||  _isViabilityRegime )
  _bestValidSample = _sortingIndex[0];
 else
 {
  _bestValidSample = -1;
  for (size_t i = 0; i < _currentPopulationSize; i++) if(_sampleConstraintViolationCounts[_sortingIndex[i]] == 0) _bestValidSample = _sortingIndex[i];
  if(_bestValidSample == -1) { korali::logWarning("Detailed", "All samples violate constraints, no updates taking place.\n"); return; }
 }

 /* update function value history */
 _previousBestValue = _currentBestValue;

 /* update current best */
 _currentBestValue = _valueVector[_bestValidSample];
 for (size_t d = 0; d < N; ++d) _currentBestVariables[d] = _samplePopulation[_bestValidSample][d];

 /* update xbestever */
 if ( _currentBestValue > _bestEverValue )
 {
  _previousBestEverValue = _bestEverValue;
  _bestEverValue = _currentBestValue;

  for (size_t d = 0; d < N; ++d)
   _bestEverVariables[d] = _currentBestVariables[d];

  if ( _areConstraintsDefined )
   for (size_t c = 0; c < _directProblem->_constraints.size(); c++)
    _bestConstraintEvaluations[c] = _constraintEvaluations[c][_bestValidSample];
 }

 /* set weights */
 for (size_t d = 0; d < N; ++d) {
   _previousMean[d] = _currentMean[d];
   _currentMean[d] = 0.;
   for (size_t i = 0; i < _currentMuValue; ++i)
     _currentMean[d] += _muWeights[i] * _samplePopulation[_sortingIndex[i]][d];

   _meanUpdate[d] = (_currentMean[d] - _previousMean[d])/_sigma;
 }

 /* calculate z := D^(-1) * B^(T) * _meanUpdate into _auxiliarBDZMatrix */
 for (size_t d = 0; d < N; ++d) {
  double sum = 0.0;
  if (_isDiagonal) sum = _meanUpdate[d];
  else for (size_t e = 0; e < N; ++e) sum += _covarianceEigenvectorMatrix[e*N+d] * _meanUpdate[e]; /* B^(T) * _meanUpdate ( iterating B[e][d] = B^(T) ) */

  _auxiliarBDZMatrix[d] = sum / _axisLengths[d]; /* D^(-1) * B^(T) * _meanUpdate */
 }

 _conjugateEvolutionPathL2Norm = 0.0;

 /* cumulation for _sigma (ps) using B*z */
 for (size_t d = 0; d < N; ++d) {
    double sum = 0.0;
    if (_isDiagonal) sum = _auxiliarBDZMatrix[d];
    else for (size_t e = 0; e < N; ++e) sum += _covarianceEigenvectorMatrix[d*N+e] * _auxiliarBDZMatrix[e];

    _conjugateEvolutionPath[d] = (1. - _sigmaCumulationFactor) * _conjugateEvolutionPath[d] + sqrt(_sigmaCumulationFactor * (2. - _sigmaCumulationFactor) * _effectiveMu) * sum;

    /* calculate norm(ps)^2 */
    _conjugateEvolutionPathL2Norm += std::pow(_conjugateEvolutionPath[d], 2.0);
 }
 _conjugateEvolutionPathL2Norm = std::sqrt(_conjugateEvolutionPathL2Norm);

 int hsig = (1.4 + 2.0/(N+1) > _conjugateEvolutionPathL2Norm / sqrt(1. - pow(1.-_sigmaCumulationFactor, 2.0*(1.0+_currentGeneration))) / _chiSquareNumber);

 /* cumulation for covariance matrix (pc) using B*D*z~N(0,C) */
 for (size_t d = 0; d < N; ++d)
    _evolutionPath[d] = (1. - _cumulativeCovariance) * _evolutionPath[d] + hsig * sqrt( _cumulativeCovariance * (2. - _cumulativeCovariance) * _effectiveMu ) * _meanUpdate[d];

 /* update covariance matrix  */
 adaptC(hsig);

 /* update masking matrix */
 if(_hasDiscreteVariables) updateDiscreteMutationMatrix();

 /* update viability bounds */
 if( _areConstraintsDefined && (_isViabilityRegime == true) ) updateViabilityBoundaries();

 /* update sigma */
 updateSigma();

 /* numerical error management */
 numericalErrorTreatment();

 _currentMinStandardDeviation = std::numeric_limits<double>::infinity();
 _currentMaxStandardDeviation = -std::numeric_limits<double>::infinity();

 // Calculating current Minimum and Maximum STD Devs
 for(size_t i = 0; i <N; ++i )
 {
  _currentMinStandardDeviation = std::min(_currentMinStandardDeviation, _sigma * sqrt(_covarianceMatrix[i*N+i]));
  _currentMaxStandardDeviation = std::max(_currentMaxStandardDeviation, _sigma * sqrt(_covarianceMatrix[i*N+i]));
 }

}

void korali::solver::optimizer::CMAES::adaptC(int hsig)
{
  /* definitions for speeding up inner-most loop */
  //double ccov1  = std::min(_covarianceMatrixLearningRate * (1./_muCovariance) * (_isDiagonal ? (N+1.5) / 3. : 1.), 1.); (orig, alternative)
  //double ccovmu = std::min(_covarianceMatrixLearningRate * (1-1./_muCovariance) * (_isDiagonal ? (N+1.5) / 3. : 1.), 1.-ccov1); (orig, alternative)
  double ccov1  = 2.0 / (std::pow(N+1.3,2)+_effectiveMu);
  double ccovmu = std::min(1.0-ccov1,  2.0 * (_effectiveMu-2+1/_effectiveMu) / (std::pow(N+2.0,2)+_effectiveMu));
  double sigmasquare = _sigma * _sigma;

  /* update covariance matrix */
  for (size_t d = 0; d < N; ++d)
   for (size_t e = _isDiagonal ? d : 0; e <= d; ++e)
   {
     _covarianceMatrix[d*N+e] = (1 - ccov1 - ccovmu) * _covarianceMatrix[d*N+e]
                        + ccov1 * (_evolutionPath[d] * _evolutionPath[e]
                        + (1-hsig)*ccov1*_cumulativeCovariance*(2.-_cumulativeCovariance) * _covarianceMatrix[d*N+e]);

     for (size_t k = 0; k < _currentMuValue; ++k)
         _covarianceMatrix[d*N+e] += ccovmu * _muWeights[k] * (_samplePopulation[_sortingIndex[k]][d]
                            - _previousMean[d]) * (_samplePopulation[_sortingIndex[k]][e] - _previousMean[e]) / sigmasquare;

     if (e < d) _covarianceMatrix[e*N+d] = _covarianceMatrix[d*N+e];
   }

  /* update maximal and minimal diagonal value */
  _maximumDiagonalCovarianceMatrixElement = _minimumDiagonalCovarianceMatrixElement = _covarianceMatrix[0];
  for (size_t d = 1; d < N; ++d) {
  if (_maximumDiagonalCovarianceMatrixElement < _covarianceMatrix[d*N+d]) _maximumDiagonalCovarianceMatrixElement = _covarianceMatrix[d*N+d];
  else if (_minimumDiagonalCovarianceMatrixElement > _covarianceMatrix[d*N+d])  _minimumDiagonalCovarianceMatrixElement = _covarianceMatrix[d*N+d];
  }
}


void korali::solver::optimizer::CMAES::updateSigma()
{
 /* update for non-viable region */
 if( _areConstraintsDefined && (_isViabilityRegime == true) )
 {
   _globalSuccessRate = (1-_globalSuccessLearningRate)*_globalSuccessRate;
   if ( _previousBestEverValue != _bestEverValue ) _globalSuccessRate += _globalSuccessLearningRate;

   _sigma *= exp((_globalSuccessRate-(_targetSuccessRate/(1.0-_targetSuccessRate))*(1-_globalSuccessRate))/_dampFactor);
 }
 /* update for discrte variables */
 else if(_hasDiscreteVariables)
 {
   double pathL2 = 0.0;
   for(size_t d = 0; d < N; ++d) pathL2 += _maskingMatrixSigma[d]*_conjugateEvolutionPath[d]*_conjugateEvolutionPath[d];
   _sigma *= exp(_sigmaCumulationFactor/_dampFactor*(sqrt(pathL2)/_chiSquareNumberDiscreteMutations-1.));
 }
 /* standard update */
 else
 {
   // _sigma *= exp(min(1.0, _sigmaCumulationFactor/_dampFactor*((_conjugateEvolutionPathL2Norm/_chiSquareNumber)-1.))); (alternative)
   _sigma *= exp(_sigmaCumulationFactor/_dampFactor*(_conjugateEvolutionPathL2Norm/_chiSquareNumber-1.));
 }

 /* escape flat evaluation */
 if (_currentBestValue == _valueVector[_sortingIndex[(int)_currentMuValue]]) {
   _sigma *= exp(0.2+_sigmaCumulationFactor/_dampFactor);
   korali::logWarning("Detailed", "Sigma increased due to equal function values.\n");
 }

 /* upper bound check for _sigma */
 double _upperBound = sqrt(_trace/N);

 if(_sigma > _upperBound)
 {
  korali::logInfo("Detailed", "Sigma exceeding inital value of _sigma (%f > %f), increase Initial Standard Deviation of variables.\n", _sigma, _upperBound);
  if( _isSigmaBounded )
  {
    _sigma = _upperBound;
    korali::logInfo("Detailed", "Sigma set to upper bound (%f) due to solver configuration 'Is Sigma Bounded' = 'true'.\n", _sigma);
  }
 }

}


void korali::solver::optimizer::CMAES::numericalErrorTreatment()
{
 //treat maximal standard deviations
 //TODO

 //treat minimal standard deviations
 for (size_t d = 0; d < N; ++d) if (_sigma * sqrt(_covarianceMatrix[d*N+d]) < _k->_variables[d]->_minimumStandardDeviationUpdate)
 {
   _sigma = (_k->_variables[d]->_minimumStandardDeviationUpdate)/sqrt(_covarianceMatrix[d*N+d]) * exp(0.05+_sigmaCumulationFactor/_dampFactor);
   korali::logWarning("Detailed", "Sigma increased due to minimal standard deviation.\n");
 }

 //too low coordinate axis deviations
 //TODO

 //treat numerical precision provblems
 //TODO
}


void korali::solver::optimizer::CMAES::handleConstraints()
{
 size_t initial_resampled = _resampledParameterCount;
 size_t initial_corrections = _covarianceMatrixAdaptationCount;

 while( _maxConstraintViolationCount > 0 )
 {
  _auxiliarCovarianceMatrix = _covarianceMatrix;

  for(size_t i = 0; i < _currentPopulationSize; ++i) if (_sampleConstraintViolationCounts[i] > 0)
  {
    //update constraint normal
    for( size_t c = 0; c < _directProblem->_constraints.size(); c++ ) if ( _viabilityIndicator[c][i] == true )
    {
        _covarianceMatrixAdaptationCount++;

        double v2 = 0;
        for( size_t d = 0; d < N; ++d)
        {
            _normalConstraintApproximation[c][d] = (1.0-_normalVectorLearningRate)*_normalConstraintApproximation[c][d]+_normalVectorLearningRate*_bDZMatrix[i*N+d];
            v2 += _normalConstraintApproximation[c][d]*_normalConstraintApproximation[c][d];
        }
        for( size_t d = 0; d < N; ++d)
          for( size_t e = 0; e < N; ++e)
            _auxiliarCovarianceMatrix[d*N+e] = _auxiliarCovarianceMatrix[d*N+e] - ((_covarianceMatrixAdaptionFactor * _covarianceMatrixAdaptionFactor * _normalConstraintApproximation[c][d]*_normalConstraintApproximation[c][e])/(v2*_sampleConstraintViolationCounts[i]*_sampleConstraintViolationCounts[i]));
    }
   }

  updateEigensystem(_auxiliarCovarianceMatrix);

  /* in original some stopping criterion (TOLX) */
  // TODO

  //resample invalid points
  for(size_t i = 0; i < _currentPopulationSize; ++i) if(_sampleConstraintViolationCounts[i] > 0)
  {
    korali::Sample sample;

    do
    {
     _resampledParameterCount++;
     sampleSingle(i);

     if(_resampledParameterCount - initial_resampled > _maxInfeasibleResamplings)
     {
        korali::logWarning("Detailed", "Exiting resampling loop, max resamplings (%zu) reached.\n", _maxInfeasibleResamplings);
        reEvaluateConstraints();
        return;
     }

     sample["Parameters"] = _samplePopulation[i];
    }
    while( _evaluationProblem->isSampleFeasible(sample) == false );
  }

  reEvaluateConstraints();

  if(_covarianceMatrixAdaptationCount - initial_corrections > _maxCovarianceMatrixCorrections)
  {
    korali::logWarning("Detailed", "Exiting adaption loop, max adaptions (%zu) reached.\n", _maxCovarianceMatrixCorrections);
    return;
  }

 }//while _maxConstraintViolationCount > 0

}


void korali::solver::optimizer::CMAES::updateDiscreteMutationMatrix()
{
  // implemented based on 'A CMA-ES for Mixed-Integer Nonlinear Optimization' by
  // Hansen2011

  size_t entries = N + 1; // +1 to prevent 0-ness
  std::fill( std::begin(_maskingMatrixSigma), std::end(_maskingMatrixSigma), 1.0);
  for(size_t d = 0; d < N; ++d) if(_sigma*std::sqrt(_covarianceMatrix[d*N+d])/std::sqrt(_sigmaCumulationFactor) < 0.2*_k->_variables[d]->_granularity) { _maskingMatrixSigma[d] = 0.0; entries--; }
  _chiSquareNumberDiscreteMutations = sqrt((double) entries) * (1. - 1./(4.*entries) + 1./(21.*entries*entries));

  _numberMaskingMatrixEntries = 0;
  std::fill( std::begin(_maskingMatrix), std::end(_maskingMatrix), 0.0);
  for(size_t d = 0; d < N; ++d) if(2.0*_sigma*std::sqrt(_covarianceMatrix[d*N+d]) < _k->_variables[d]->_granularity) { _maskingMatrix[d] = 1.0; _numberMaskingMatrixEntries++; }

  _numberOfDiscreteMutations = std::min( std::round(_populationSize/10.0 + _numberMaskingMatrixEntries + 1) , std::floor(_populationSize/2.0) - 1);
  std::fill( std::begin(_discreteMutations), std::end(_discreteMutations), 0.0);

}

void korali::solver::optimizer::CMAES::updateEigensystem(std::vector<double>& M)
{
 eigen(N, M, _auxiliarAxisLengths, _auxiliarCovarianceEigenvectorMatrix);

 /* find largest and smallest eigenvalue, they are supposed to be sorted anyway */
 double minEWtmp = *std::min_element(std::begin(_auxiliarAxisLengths), std::end(_auxiliarAxisLengths));
 double maxEWtmp = *std::max_element(std::begin(_auxiliarAxisLengths), std::end(_auxiliarAxisLengths));

 if (minEWtmp <= 0.0)
 { korali::logWarning("Detailed", "Min Eigenvalue smaller or equal 0.0 (%+6.3e) after Eigen decomp (no update possible).\n", minEWtmp ); return; }

 for (size_t d = 0; d < N; ++d)
 {
     _auxiliarAxisLengths[d] = sqrt(_auxiliarAxisLengths[d]);
     if (std::isfinite(_auxiliarAxisLengths[d]) == false)
     {
       korali::logWarning("Detailed", "Could not calculate root of Eigenvalue (%+6.3e) after Eigen decomp (no update possible).\n", _auxiliarAxisLengths[d] );
       return;
     }
    for (size_t e = 0; e < N; ++e) if (std::isfinite(_covarianceEigenvectorMatrix[d*N+e]) == false)
    {
      korali::logWarning("Detailed", "Non finite value detected in B (no update possible).\n");
       return;
    }
 }

 /* write back */
 for (size_t d = 0; d < N; ++d) _axisLengths[d] = _auxiliarAxisLengths[d];
 _covarianceEigenvectorMatrix.assign(std::begin(_auxiliarCovarianceEigenvectorMatrix), std::end(_auxiliarCovarianceEigenvectorMatrix));

 _minimumCovarianceEigenvalue = minEWtmp;
 _maximumCovarianceEigenvalue = maxEWtmp;
}


/************************************************************************/
/*                    Additional Methods                                */
/************************************************************************/


void korali::solver::optimizer::CMAES::eigen(size_t size, std::vector<double>& M,  std::vector<double>& diag, std::vector<double>& Q) const
{
 std::vector<double> data(size * size);

 for (size_t i = 0; i <  size; i++)
 for (size_t j = 0; j <= i; j++)
 {
  data[i*size + j] = M[i*N+j];
  data[j*size + i] = M[i*N+j];
 }

 // GSL Workspace
 gsl_vector* gsl_eval = gsl_vector_alloc(N);
 gsl_matrix* gsl_evec = gsl_matrix_alloc(N, N);
 gsl_eigen_symmv_workspace* gsl_work =  gsl_eigen_symmv_alloc(N);

 gsl_matrix_view m = gsl_matrix_view_array (data.data(), size, size);

 gsl_eigen_symmv (&m.matrix, gsl_eval, gsl_evec, gsl_work);
 gsl_eigen_symmv_sort (gsl_eval, gsl_evec, GSL_EIGEN_SORT_ABS_ASC);

 for (size_t i = 0; i < size; i++)
 {
  gsl_vector_view gsl_evec_i = gsl_matrix_column (gsl_evec, i);
  for (size_t j = 0; j < size; j++) Q[j*N+i] = gsl_vector_get (&gsl_evec_i.vector, j);
 }

 for (size_t i = 0; i < size; i++) diag[i] = gsl_vector_get (gsl_eval, i);

 gsl_vector_free(gsl_eval);
 gsl_matrix_free(gsl_evec);
 gsl_eigen_symmv_free(gsl_work);
}


void korali::solver::optimizer::CMAES::sort_index(const std::vector<double>& vec, std::vector<size_t>& sortingIndex, size_t n) const
{
  // initialize original sortingIndex locations
  std::iota(std::begin(sortingIndex), std::begin(sortingIndex)+n, (size_t) 0);

  // sort indexes based on comparing values in vec
  std::sort(std::begin(sortingIndex), std::begin(sortingIndex)+n, [vec](size_t i1, size_t i2) { return vec[i1] > vec[i2]; } );

}


void korali::solver::optimizer::CMAES::printGenerationBefore() { return; }

void korali::solver::optimizer::CMAES::printGenerationAfter()
{

 if ( _areConstraintsDefined && _isViabilityRegime )
 {
   korali::logInfo("Normal", "Searching start (MeanX violates constraints) .. \n");
   korali::logInfo("Normal", "Viability Bounds:\n");
   for (size_t c = 0; c < _directProblem->_constraints.size(); c++) korali::logData("Normal", "         (%+6.3e)\n", _viabilityBoundaries[c]);
   korali::logInfo("Normal", "\n");
 }

 korali::logInfo("Normal", "Sigma:                        %+6.3e\n", _sigma);
 korali::logInfo("Normal", "Current Function Value: Max = %+6.3e - Best = %+6.3e\n", _currentBestValue, _bestEverValue);
 korali::logInfo("Normal", "Diagonal Covariance:    Min = %+6.3e -  Max = %+6.3e\n", _minimumDiagonalCovarianceMatrixElement, _maximumDiagonalCovarianceMatrixElement);
 korali::logInfo("Normal", "Covariance Eigenvalues: Min = %+6.3e -  Max = %+6.3e\n", _minimumCovarianceEigenvalue, _maximumCovarianceEigenvalue);

  korali::logInfo("Detailed", "Variable = (MeanX, BestX):\n");
  for (size_t d = 0; d < N; d++) korali::logData("Detailed", "         %s = (%+6.3e, %+6.3e)\n", _k->_variables[d]->_name.c_str(), _currentMean[d], _bestEverVariables[d]);

  korali::logInfo("Detailed", "Constraint Evaluation at Current Function Value:\n");
  if ( _areConstraintsDefined )
  {
   if ( _bestValidSample >= 0 )
      for (size_t c = 0; c < _directProblem->_constraints.size(); c++) korali::logData("Detailed", "         ( %+6.3e )\n", _constraintEvaluations[c][_bestValidSample]);
   else
      for (size_t c = 0; c < _directProblem->_constraints.size(); c++) korali::logData("Detailed", "         ( %+6.3e )\n", _constraintEvaluations[c][0]);
  }

  korali::logInfo("Detailed", "Covariance Matrix:\n");
  for (size_t d = 0; d < N; d++)
  {
   for (size_t e = 0; e <= d; e++) korali::logData("Detailed", "   %+6.3e  ",_covarianceMatrix[d*N+e]);
   korali::logInfo("Detailed", "\n");
  }

  korali::logInfo("Detailed", "Number of Infeasible Samples: %zu\n", _infeasibleSampleCount);
  if ( _areConstraintsDefined )
  {
    korali::logInfo("Detailed", "Number of Constraint Evaluations: %zu\n", _constraintEvaluationCount);
    korali::logInfo("Detailed", "Number of Matrix Corrections: %zu\n", _covarianceMatrixAdaptationCount );
  }
}

void korali::solver::optimizer::CMAES::finalize()
{
  korali::logInfo("Minimal", "Optimum found: %e\n", _bestEverValue);
  korali::logInfo("Minimal", "Optimum found at:\n");
  for (size_t d = 0; d < N; ++d) korali::logData("Minimal", "         %s = %+6.3e\n", _k->_variables[d]->_name.c_str(), _bestEverVariables[d]);
  if ( _areConstraintsDefined )
  {
    korali::logInfo("Minimal", "Constraint Evaluation at Optimum:\n");
    for (size_t c = 0; c < _directProblem->_constraints.size(); c++)
      korali::logData("Minimal", "         ( %+6.3e )\n", _bestConstraintEvaluations[c]);
  }
  korali::logInfo("Minimal", "Number of Infeasible Samples: %zu\n", _infeasibleSampleCount);
}
