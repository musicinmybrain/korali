#include "solver/optimizer/DEA/DEA.hpp"
#include "problem/problem.hpp"
#include "engine/engine.hpp"
#include "conduit/conduit.hpp"

#include <stdio.h>
#include <unistd.h>
#include <chrono>
#include <numeric>   // std::iota
#include <algorithm> // std::sort

constexpr size_t __korali__str2int(const char* str, int h = 0) { return !str[h] ? 5381 : (__korali__str2int(str, h+1) * 33) ^ str[h]; }

void korali::solver::optimizer::DEA::initialize()
{
 korali::solver::Optimizer::initialize();

 // Initializing RNGs
 auto jsNormal = nlohmann::json();
 jsNormal["Name"] = "Normal Generator";
 jsNormal["Type"] = "Univariate/Normal";
 jsNormal["Mean"] = 0.0;
 jsNormal["Standard Deviation"] = 1.0;
 _normalGenerator = dynamic_cast<korali::distribution::univariate::Normal*>(korali::Module::getModule(jsNormal));
 _normalGenerator->initialize();

 auto jsUniform = nlohmann::json();
 jsUniform["Name"] = "Uniform Generator";
 jsUniform["Type"] = "Univariate/Uniform";
 jsUniform["Minimum"] = 0.0;
 jsUniform["Maximum"] = 1.0;
 _uniformGenerator = dynamic_cast<korali::distribution::univariate::Uniform*>(korali::Module::getModule(jsUniform));
 _uniformGenerator->initialize();

 N = _k->_variables.size();

 for(size_t d = 0; d < N; ++d)
  if(_k->_variables[d]->_upperBound < _k->_variables[d]->_lowerBound)
    korali::logError("Lower Bound (%.4f) of variable \'%s\'  exceeds Upper Bound (%.4f).\n", _k->_variables[d]->_lowerBound, _k->_variables[d]->_name.c_str(), _k->_variables[d]->_upperBound);

 _evaluationProblem = dynamic_cast<korali::problem::Evaluation*>(_k->_problem);
 bool isEvaluationProblem = _evaluationProblem != NULL;

 if (isEvaluationProblem == false)
  korali::logError("CMAES can only optimize problems of type 'Evaluation' or derived.\n");

 // Allocating Memory

 _samplePopulation.resize(_populationSize);
 for(size_t i = 0; i < _populationSize; i++) _samplePopulation[i].resize(N);

 _candidatePopulation.resize(_populationSize);
 for(size_t i = 0; i < _populationSize; i++) _candidatePopulation[i].resize(N);

 _previousMean.resize(N);
 _currentMean.resize(N);
 _bestEverVariables.resize(N);
 _currentBestVariables.resize(N);
 _maxDistances.resize(N);

 _valueVector.resize(_populationSize);
 for(size_t i = 0; i < _populationSize; i++) _valueVector[i] = -korali::Inf;

 _valueVector.resize(_populationSize);

 if (_k->_currentGeneration > 1) return;

 _infeasibleSampleCount = 0;
 _bestSampleIndex = 0;

 _previousBestValue     = -korali::Inf;
 _currentBestValue      = -korali::Inf;
 _previousBestEverValue = -korali::Inf;
 _bestEverValue         = -korali::Inf;
 _currentMinimumStepSize = +korali::Inf;

 initSamples();

 for(size_t d = 0; d < N; ++d) { _previousMean[d] = 0.0; _currentMean[d] = 0.0; }

 for(size_t i = 0; i < _populationSize; ++i) for(size_t d = 0; d < N; ++d)
   _currentMean[d] += _samplePopulation[i][d]/((double)_populationSize);
}


void korali::solver::optimizer::DEA::runGeneration()
{
 prepareGeneration();

 // Initializing Sample Evaluation
 std::vector<korali::Sample> samples(_populationSize);
 for (size_t i = 0; i < _populationSize; i++)
 {
  samples[i]["Operation"] = "Basic Evaluation";
  samples[i]["Parameters"] = _candidatePopulation[i];
  samples[i]["Sample Id"] = i;
  _k->_conduit->start(samples[i]);
 }

 // Waiting for samples to finish
 _k->_conduit->waitAll(samples);

 // Processing results
 for (size_t i = 0; i < _populationSize; i++)
  _valueVector[i] = samples[i]["Evaluation"];

 updateSolver();
}


void korali::solver::optimizer::DEA::initSamples()
{
  /* skip sampling in gen 1 */
  for(size_t i = 0; i < _populationSize; ++i) for(size_t d = 0; d < N; ++d)
  {
    double width = _k->_variables[d]->_upperBound - _k->_variables[d]->_lowerBound;
    _candidatePopulation[i][d] = _k->_variables[d]->_lowerBound + width * _uniformGenerator->getRandomNumber();
    _samplePopulation[i][d] = _candidatePopulation[i][d];
  }
}


void korali::solver::optimizer::DEA::prepareGeneration()
{
 /* at gen 1 candidates initialized in initialize() */
 if(_k->_currentGeneration > 1)
 for (size_t i = 0; i < _populationSize; ++i)
 {
  mutateSingle(i);

  korali::Sample sample;
  sample["Parameters"] = _candidatePopulation[i];
  while(_evaluationProblem->isSampleFeasible(sample) == false)
  {
   _infeasibleSampleCount++;
   if (_fixInfeasible) fixInfeasible(i);
   else  mutateSingle(i);
   sample["Parameters"] = _candidatePopulation[i];
  }

 }
 _previousValueVector = _valueVector;
}


void korali::solver::optimizer::DEA::mutateSingle(size_t sampleIdx)
{
    size_t a, b;
    do{ a = _uniformGenerator->getRandomNumber()*_populationSize; } while(a == sampleIdx);
    do{ b = _uniformGenerator->getRandomNumber()*_populationSize; } while(b == sampleIdx || b == a);

    if (_mutationRule == "Self Adaptive")
    {
        // Brest [2006]
        double tau1 = 0.1;
        double tau2 = 0.1;
        double Fl = 0.1;
        double Fu = 0.9;

        double rd2 = _uniformGenerator->getRandomNumber();
        double rd3 = _uniformGenerator->getRandomNumber();
        
        if(rd2 < tau1) 
        {
           double rd1 = _uniformGenerator->getRandomNumber();
            _mutationRate = Fl+rd1*Fu;
        } 
        if(rd3 < tau2)
        {
           double rd4 = _uniformGenerator->getRandomNumber();
           _crossoverRate = rd4;
        }
    }

    double* parent;
    if(_parentSelectionRule == "Random")
    {
        size_t c;
        do { c = _uniformGenerator->getRandomNumber()*_populationSize; } while(c == sampleIdx || c == a || c == b);
        parent = &_samplePopulation[c][0];
    }
    else /* _parentSelectionRule == "Best" */
    {
        parent = &_samplePopulation[_bestSampleIndex][0];
    }

    size_t rn = _uniformGenerator->getRandomNumber()*N;
    for(size_t d = 0; d < N; ++d)
    {
      if( (_uniformGenerator->getRandomNumber() < _crossoverRate) || (d == rn) )
          _candidatePopulation[sampleIdx][d] = parent[d]+_mutationRate*(_samplePopulation[a][d]-_samplePopulation[b][d]);
      else
          _candidatePopulation[sampleIdx][d] = _samplePopulation[sampleIdx][d];
    }
}

void korali::solver::optimizer::DEA::fixInfeasible(size_t sampleIdx)
{
  for(size_t d = 0; d < N; ++d)
  {
    double len = 0.0;
    if ( _candidatePopulation[sampleIdx][d] < _k->_variables[d]->_lowerBound )
      len = _candidatePopulation[sampleIdx][d] - _k->_variables[d]->_lowerBound;
    if ( _candidatePopulation[sampleIdx][d] > _k->_variables[d]->_upperBound )
      len = _candidatePopulation[sampleIdx][d] - _k->_variables[d]->_upperBound;

    _candidatePopulation[sampleIdx][d] = _samplePopulation[sampleIdx][d] - len * _uniformGenerator->getRandomNumber();
  }
}


void korali::solver::optimizer::DEA::updateSolver()
{
    _bestSampleIndex = std::distance( std::begin(_valueVector), std::max_element(std::begin(_valueVector), std::end(_valueVector)) );
    _previousBestEverValue = _bestEverValue;
    _previousBestValue     = _currentBestValue;
    _currentBestValue      = _valueVector[_bestSampleIndex];

    for(size_t d = 0; d < N; ++d) _currentBestVariables[d] = _candidatePopulation[_bestSampleIndex][d];
    
    _previousMean = _currentMean;
    std::fill(std::begin(_currentMean), std::end(_currentMean), 0.0);

    if(_currentBestValue > _bestEverValue) _bestEverVariables = _currentBestVariables;

    switch (__korali__str2int(_acceptRule.c_str()))
    {
        case __korali__str2int("Best") : // only update best sample
            if(_currentBestValue > _bestEverValue)
            {
              for(size_t d = 0; d < N; ++d) _samplePopulation[_bestSampleIndex][d] = _candidatePopulation[_bestSampleIndex][d];
              _bestEverValue = _currentBestValue;
            }
            break;

        case __korali__str2int("Greedy") : // accept all mutations better than parent
            for(size_t i = 0; i < _populationSize; ++i) if(_valueVector[i] > _previousValueVector[i])
                _samplePopulation[i] = _candidatePopulation[i];
            if(_currentBestValue > _bestEverValue) _bestEverValue = _currentBestValue;
            break;

        case __korali__str2int("Improved") : // update all samples better than _bestEverValue
            for(size_t i = 0; i < _populationSize; ++i) if(_valueVector[i] > _bestEverValue)
                for(size_t d = 0; d < N; ++d) _samplePopulation[i][d] = _candidatePopulation[i][d];
            if(_currentBestValue > _bestEverValue) _bestEverValue = _currentBestValue;
            break;

        case __korali__str2int("Iterative") : // iteratively update _bestEverValue and accept samples
            for(size_t i = 0; i < _populationSize; ++i) if(_valueVector[i] > _bestEverValue)
             { for(size_t d = 0; d < N; ++d) _samplePopulation[i][d] = _candidatePopulation[i][d]; _bestEverValue = _valueVector[i]; }
            break;

        default :
            korali::logError("Accept Rule (%s) not recognized.\n",  _acceptRule.c_str());
    }

    for(size_t i = 0; i < _populationSize; ++i) for(size_t d = 0; d < N; ++d)
        _currentMean[d] += _samplePopulation[i][d]/((double)_populationSize);

    for(size_t d = 0; d < N; ++d)
    {
        double max = -korali::Inf;
        double min = +korali::Inf;
        for(size_t i = 0; i < _populationSize; ++i)
        {
            if (_samplePopulation[i][d] > max) max = _samplePopulation[i][d];
            if (_samplePopulation[i][d] < min) min = _samplePopulation[i][d];
        }
        _maxDistances[d] = max-min;
    }

    _currentMinimumStepSize = +korali::Inf;
    for(size_t d = 0; d < N; ++d)  std::min(_currentMinimumStepSize, fabs(_currentMean[d] - _previousMean[d]));
}


/************************************************************************/
/*                    Additional Methods                                */
/************************************************************************/


void korali::solver::optimizer::DEA::printGenerationBefore() { return; }

void korali::solver::optimizer::DEA::printGenerationAfter()
{
 korali::logInfo("Normal", "Current Function Value: Max = %+6.3e - Best = %+6.3e\n", _currentBestValue, _bestEverValue);
 korali::logInfo("Detailed", "Variable = (MeanX, BestX):\n");
 for (size_t d = 0; d < N; d++) korali::logData("Detailed", "         %s = (%+6.3e, %+6.3e)\n", _k->_variables[d]->_name.c_str(), _currentMean[d], _bestEverVariables[d]);
 korali::logInfo("Detailed", "Max Width:\n");
 for (size_t d = 0; d < N; d++) korali::logData("Detailed", "         %s = %+6.3e\n", _k->_variables[d]->_name.c_str(), _maxDistances[d]);
 korali::logInfo("Detailed", "Number of Infeasible Samples: %zu\n", _infeasibleSampleCount);
}

void korali::solver::optimizer::DEA::finalize()
{
 korali::logInfo("Minimal", "Optimum found: %e\n", _bestEverValue);
 korali::logInfo("Minimal", "Optimum found at:\n");
 for (size_t d = 0; d < N; ++d) korali::logData("Minimal", "         %s = %+6.3e\n", _k->_variables[d]->_name.c_str(), _bestEverVariables[d]);
 korali::logInfo("Minimal", "Number of Infeasible Samples: %zu\n", _infeasibleSampleCount);
}
