#include "modules/problem/reinforcementLearning/discrete/discrete.hpp"
#include "sample/sample.hpp"

namespace korali
{
namespace problem
{
namespace reinforcementLearning
{

void Discrete::initialize()
{
  ReinforcementLearning::initialize();

  /*********************************************************************
    * Verifying Discrete Action Space
    *********************************************************************/

  if (_possibleActions.empty())
    KORALI_LOG_ERROR("No possible actions have been defined for the discrete RL problem (empty set detected).\n");

  for (size_t i = 0; i < _possibleActions.size(); i++)
    if (_possibleActions[i].size() != _actionVectorSize)
      KORALI_LOG_ERROR("For possible action %lu, incorrect vector size provided. Expected: %lu, Provided: %lu.\n", i, _actionVectorSize, _possibleActions[i].size());
}

void Discrete::getRandomAction(Sample &sample)
{
  // Producing random (uniform) number to obtain a value index
  double x = _randomActionGenerator->getRandomNumber();

  // Getting possible action count
  size_t possibleActionCount = _possibleActions.size();

  // Randomly select one of the actions provided in the possible actions
  size_t actionIdx = floor(x * possibleActionCount);

  // Probability Densities is uniform for all possible actions
  for (size_t i = 0; i < possibleActionCount; i++)
   sample["Metadata"]["Probability Densities"][i] = 1.0 / (double) possibleActionCount;

  // Storing action index
  sample["Metadata"]["Action Index"] = actionIdx;

  // Storing action itself
  sample["Action"] = _possibleActions[actionIdx];
}

size_t Discrete::getRandomActionIndex()
{
  // Producing random (uniform) number to obtain a value index
  double x = _randomActionGenerator->getRandomNumber();

  // Randomly select one of the actions provided in the value vector
  size_t actionIdx = floor(x * _possibleActions.size());

  return actionIdx;
}

} // namespace reinforcementLearning

} // namespace problem

} // namespace korali
