#include "modules/problem/reinforcementLearning/reinforcementLearning.hpp"
#include "modules/solver/DQN/DQN.hpp"

namespace korali
{
namespace problem
{
void ReinforcementLearning::initialize()
{
  // Processing state/action variable configuration

  for (size_t i = 0; i < _k->_variables.size(); i++)
  {
    if (_k->_variables[i]->_type == "State") _stateVectorIndexes.push_back(i);
    if (_k->_variables[i]->_type == "Action") _actionVectorIndexes.push_back(i);
  }

  _actionVectorSize = _actionVectorIndexes.size();
  _stateVectorSize = _stateVectorIndexes.size();

  if (_actionVectorSize == 0) KORALI_LOG_ERROR("No action variables have been defined.\n");
  if (_stateVectorSize == 0) KORALI_LOG_ERROR("No state variables have been defined.\n");

  // Verifying initial states
  _initialStateCount = _initialStates.size();

  if (_initialStateCount == 0) KORALI_LOG_ERROR("No initial states have been provided.\n");

  for (size_t i = 0; i < _initialStates.size(); i++)
   if (_initialStates[i].size() != _stateVectorSize)
    KORALI_LOG_ERROR("Incorrect number of values (%lu) for initial state %lu. Expected: %lu (the number of state variables).\n", _initialStates[i].size(), i, _stateVectorSize);
}

Sample* __currentSample;
size_t __envFunctionId;

void __environmentWrapper()
{
 Sample* sample = __currentSample;

 sample->run(__envFunctionId);

 (*sample)["Finished"] = true;

 co_switch(sample->_workerThread);

 KORALI_LOG_ERROR("Resuming a finished sample\n");
}

void ReinforcementLearning::runEnvironment(Sample &sample)
{
 // Getting RL-compatible solver
 auto solver = dynamic_cast<solver::DQN *>(_k->_solver);

 sample["Finished"] = false;

 // Creating sample coroutine
 __currentSample = &sample;
 __envFunctionId = _environmentFunction;
 sample._workerThread = co_active();
 auto envThread = co_create(1 << 28, __environmentWrapper);

 size_t expId = 0;

 while (sample["Finished"] == false)
 {
  solver->getAction(sample);
  sample["Experience"]["States"][expId] = sample["State"];
  sample["Experience"]["Actions"][expId] = sample["Action"];

  // Jumping back into the agent's environment
  co_switch(envThread);
  // Returning from the agent's environment with the reward

  sample["Experience"]["Rewards"][expId] = sample["Reward"];
  expId++;
 }

 co_delete(envThread);
}

} // namespace problem

} // namespace korali
