#include "modules/problem/reinforcementLearning/reinforcementLearning.hpp"
#include "modules/solver/agent/agent.hpp"
#include "sample/sample.hpp"

namespace korali
{
namespace problem
{
void ReinforcementLearning::initialize()
{
  // Processing state/action variable configuration

  _stateVectorIndexes.clear();
  _actionVectorIndexes.clear();
  for (size_t i = 0; i < _k->_variables.size(); i++)
  {
    if (_k->_variables[i]->_type == "State") _stateVectorIndexes.push_back(i);
    if (_k->_variables[i]->_type == "Action") _actionVectorIndexes.push_back(i);
  }

  _actionVectorSize = _actionVectorIndexes.size();
  _stateVectorSize = _stateVectorIndexes.size();

  if (_actionVectorSize == 0) KORALI_LOG_ERROR("No action variables have been defined.\n");
  if (_stateVectorSize == 0) KORALI_LOG_ERROR("No state variables have been defined.\n");

  if (_actionRepeat == 0) KORALI_LOG_ERROR("Action repeat cannot be zero.\n");
}

/**
 * @brief Pointer to the current sample, it is immediately copied as to avoid concurrency problems
 */
Sample *__currentSample;

/**
 * @brief Identifier of the current environment function Id.
 */
size_t __envFunctionId;

/**
 * @brief Thread wrapper to run an environment
 */
void __environmentWrapper()
{
  Sample *sample = __currentSample;

  sample->run(__envFunctionId);

  (*sample)["Finished"] = true;

  co_switch(sample->_workerThread);

  KORALI_LOG_ERROR("Resuming a finished sample\n");
}

void ReinforcementLearning::runEpisode(Sample &sample)
{
  // Getting RL-compatible solver
  auto agent = dynamic_cast<solver::Agent *>(_k->_solver);

  // First, we update the policy's hyperparameters
  agent->updateHyperparameters(sample.globals()["Hyperparameters"]);

  sample["Finished"] = false;

  // Creating sample coroutine
  __currentSample = &sample;
  __envFunctionId = _environmentFunction;
  sample._workerThread = co_active();
  auto envThread = co_create(1 << 28, __environmentWrapper);

  // Getting first state
  co_switch(envThread);

  // Action Repeat Counter
  size_t actionLastUpdated = 0;

  // Initializing episode's experience counter
  size_t expId = 0;

  // Storage for the action
  std::vector<double> action(_actionVectorSize);

  // Saving experiences
  while (sample["Finished"] == false)
  {
    // Requesting new action, if enough steps have passed, given by the action repeat parameter
    if (actionLastUpdated == 0)
    {
      agent->getAction(sample);
      actionLastUpdated = _actionRepeat;
    }
    actionLastUpdated--;

    // Storing whether this experience was terminal or not
    sample["Experiences"][expId]["Is Terminal"] = false;

    // Storing the current state
    sample["Experiences"][expId]["State"] = sample["State"];

    // Storing the current action
    sample["Experiences"][expId]["Action"] = sample["Action"];

    // Storing metadata, for methods that require more information
    if (isDefined(sample._js.getJson(), "Metadata")) sample["Experiences"][expId]["Metadata"] = sample["Metadata"];

    // Jumping back into the agent's environment
    co_switch(envThread);

    // Returning from the agent's environment with the reward
    sample["Experiences"][expId]["Reward"] = sample["Reward"];

    // Advancing to next experience
    expId++;
  }

  // Last experience is always terminal
  sample["Experiences"][expId-1]["Is Terminal"] = true;

  co_delete(envThread);
}

} // namespace problem

} // namespace korali
