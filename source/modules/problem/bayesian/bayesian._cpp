#include "modules/problem/bayesian/bayesian.hpp"
#include "sample/sample.hpp"

@startNamespace

void @className::initialize()
{
  for (size_t i = 0; i < _k->_variables.size(); i++)
  {
    bool foundDistribution = false;

    for (size_t j = 0; j < _k->_distributions.size(); j++)
      if (_k->_variables[i]->_priorDistribution == _k->_distributions[j]->_name)
      {
        foundDistribution = true;
        _k->_variables[i]->_distributionIndex = j;
      }

    if (foundDistribution == false)
      KORALI_LOG_ERROR("Did not find distribution %s, specified by variable %s\n", _k->_variables[i]->_priorDistribution.c_str(), _k->_variables[i]->_name.c_str());
  }
}

void @className::evaluateLogPrior(Sample &sample)
{
  double logPrior = 0.0;

  for (size_t i = 0; i < sample["Parameters"].size(); i++)
    logPrior += _k->_distributions[_k->_variables[i]->_distributionIndex]->getLogDensity(sample["Parameters"][i]);

  sample["logPrior"] = logPrior;
}

void @className::evaluateLogPriorGradient(Sample &sample)
{
  size_t numParam = sample["Parameters"].size();
  std::vector<double> logPriorGradient(numParam, 0.);

  for (size_t i = 0; i < numParam; i++)
    logPriorGradient[i] = _k->_distributions[_k->_variables[i]->_distributionIndex]->getLogDensityGradient(sample["Parameters"][i]);

  sample["logPrior Gradient"] = logPriorGradient;
}

void @className::evaluateLogPriorHessian(Sample &sample)
{
  size_t numParam = sample["Parameters"].size();
  std::vector<double> logPriorHessian(numParam * numParam, 0.);

  for (size_t i = 0; i < numParam; i++)
    logPriorHessian[i * numParam + i] = _k->_distributions[_k->_variables[i]->_distributionIndex]->getLogDensityHessian(sample["Parameters"][i]);

  sample["logPrior Hessian"] = logPriorHessian;
}

void @className::evaluateLogPosterior(Sample &sample)
{
  int sampleId = sample["Sample Id"];
  evaluateLogPrior(sample);

  if (sample["logPrior"] == -Inf)
  {
    sample["logLikelihood"] = -Inf;
    sample["logPosterior"] = -Inf;
  }
  else
  {
    evaluateLoglikelihood(sample);
    double logPrior = sample["logPrior"];
    double logLikelihood = sample["logLikelihood"];
    double logPosterior = logPrior + logLikelihood;

    if (std::isnan(logLikelihood) == true) KORALI_LOG_ERROR("Sample %d returned NaN logLikelihood evaluation.\n", sampleId);

    sample["logPosterior"] = logPosterior;
  }
}

void @className::evaluate(Sample &sample)
{
  evaluateLogPosterior(sample);
  sample["F(x)"] = sample["logPosterior"];
  sample["logP(x)"] = sample["logPosterior"];
}

void @className::evaluateGradient(Sample &sample)
{
  evaluateLogPriorGradient(sample);
  evaluateLoglikelihoodGradient(sample);
  auto logPriorGrad = sample["logPrior Gradient"].get<std::vector<double>>();
  auto logLikGrad = sample["logLikelihood Gradient"].get<std::vector<double>>();
  for (size_t i = 0; i < logPriorGrad.size(); ++i)
    logLikGrad[i] += logPriorGrad[i];
  sample["grad(logP(x))"] = logLikGrad;
}

void @className::evaluateHessian(Sample &sample)
{
  evaluateLogPriorHessian(sample);
  evaluateLogLikelihoodHessian(sample);
  auto logPriorHessian = sample["logPrior Hessian"].get<std::vector<double>>();
  auto logLikHessian = sample["logLikelihood Hessian"].get<std::vector<double>>();
  size_t numElement = logPriorHessian.size();
  for (size_t i = 0; i < numElement; i++)
    logLikHessian[i] += logPriorHessian[i];

  sample["H(logP(x))"] = logLikHessian;
}

@moduleAutoCode

@endNamespace
