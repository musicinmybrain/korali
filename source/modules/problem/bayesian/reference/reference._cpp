#include "modules/problem/bayesian/reference/reference.hpp"
#include "modules/conduit/conduit.hpp"
#include "modules/experiment/experiment.hpp"

void korali::problem::bayesian::Reference::initialize()
{
  korali::problem::Bayesian::initialize();

  if (_referenceData.size() == 0) korali::logError("Bayesian (%s) problems require defining reference data.\n", _likelihoodModel.c_str());

  if( _likelihoodModel != "Additive Normal General"){
    bool foundSigma = false;
    for (size_t i = 0; i < _k->_variables.size(); i++){
      std::string varName = _k->_variables[i]->_name;
      if (varName == "[Sigma]") { sigmaVariableIndex = i; foundSigma = true; }
    }
    if (foundSigma == false) korali::logError("Bayesian (%s) problems require defining a variable named: '[Sigma]'.\n", _likelihoodModel.c_str());
  }

  if (_k->_variables.size() < 2) korali::logError("Bayesian (%s) inference problems require at least one model variable.\n", _likelihoodModel.c_str());
}


void korali::problem::bayesian::Reference::evaluateLogLikelihood(korali::Sample& sample)
{
  sample.run(_computationalModel);

  if (sample["Reference Evaluations"].size() != _referenceData.size())
    korali::logError("This Bayesian (%s) problem requires a %lu-sized result array. Provided: %lu.\n", _likelihoodModel.c_str(), _referenceData.size(), sample["Reference Evaluations"].size());

  if (_likelihoodModel == "Additive Normal")            loglikelihoodNormalAdditive(sample);
  if (_likelihoodModel == "Additive Normal Variance")   loglikelihoodNormalAdditiveVariance(sample);
  if (_likelihoodModel == "Multiplicative Normal")      loglikelihoodNormalMultiplicative(sample);
  if (_likelihoodModel == "Multiplicative Normal Data") loglikelihoodNormalMultiplicativeData(sample);

  if (_likelihoodModel == "Additive Normal General"){
    if( sample["Reference Evaluations"].size() != sample["Standard Deviation Model"].size() )
      korali::logError("This Bayesian (%s) problem requires two %lu-sized result arrays. Provided: %lu and %lu.\n", _likelihoodModel.c_str(), _referenceData.size(), sample["Reference Evaluations"].size(), sample["Standard Deviation Model"].size() );
    loglikelihoodNormalGeneral(sample);
  }

}


double korali::problem::bayesian::Reference::compute_sse( std::vector<double> x, std::vector<double> y ){
  double sse = 0.;
  for(size_t i = 0; i < y.size(); i++)
  {
    if( !isfinite(x[i]) )
    {
      korali::logWarning("Normal","Non-finite value detected in the results passed in the log-likelihood function.\n");
      return korali::Inf;
    }
    double diff = y[i] - x[i];
    sse += diff*diff;
  }
  return sse;
}


double korali::problem::bayesian::Reference::compute_normalized_sse( std::vector<double> f, std::vector<double> g, std::vector<double> y ){
  double sse = 0.;
  for(size_t i = 0; i < y.size(); i++)
  {

    if( !isfinite(f[i]) || !isfinite(g[i]) ){
      korali::logWarning("Normal","Non-finite value detected in the results passed in the log-likelihood function.\n");
      return korali::Inf;
    }
    if( g[i]<=0 ){
      korali::logError("Negative or zero value detected in the standard deviation results passed in the log-likelihood function.\n");
      return korali::Inf;
    }
    double diff = ( y[i] - f[i] ) / g[i];
    sse += diff*diff;
  }
  return sse;
}


void korali::problem::bayesian::Reference::loglikelihoodNormalAdditive(korali::Sample& sample)
{
  double sigma   = sample["Parameters"][sigmaVariableIndex];
  double sigma2  = sigma*sigma;

  double sse = compute_sse( sample["Reference Evaluations"], _referenceData );

  if( isinf(sse) )
    sample["logLikelihood"] = -korali::Inf;
  else
    sample["logLikelihood"] = -0.5*( _referenceData.size()*log(2*M_PI*sigma2) + sse/sigma2);
}


void korali::problem::bayesian::Reference::loglikelihoodNormalAdditiveVariance(korali::Sample& sample)
{
  double sigma2 = sample["Parameters"][sigmaVariableIndex];

  double sse = compute_sse( sample["Reference Evaluations"], _referenceData );

  if( isinf(sse) )
    sample["logLikelihood"] = -korali::Inf;
  else
    sample["logLikelihood"] = -0.5*( _referenceData.size()*log(2*M_PI*sigma2) + sse/sigma2);
}


void korali::problem::bayesian::Reference::loglikelihoodNormalMultiplicative(korali::Sample& sample)
{
  double sigma    = sample["Parameters"][sigmaVariableIndex];
  double ssn      = 0.0;
  double logSigma = 0.0;

  for(size_t i = 0; i < _referenceData.size(); i++)
  {
    double eval = sample["Reference Evaluations"][i];

    if( !isfinite(eval) )
    {
      korali::logWarning("Normal","Non-finite value detected in the results passed in the log-likelihood function.\n");
      sample["logLikelihood"] = -korali::Inf;
      return;
    }

    double diff   = _referenceData[i] - eval;
    double denom  = sigma*eval;
    ssn += diff*diff / (denom*denom);
    logSigma += log(denom);
  }

  sample["logLikelihood"] = -0.5*( _referenceData.size()*log(2*M_PI) + ssn) - _referenceData.size()*logSigma;
}


void korali::problem::bayesian::Reference::loglikelihoodNormalMultiplicativeData(korali::Sample& sample)
{
  double sigma    = sample["Parameters"][sigmaVariableIndex];
  double ssn      = 0.0;
  double logSigma = 0.0;
  for(size_t i = 0; i < _referenceData.size(); i++)
  {
    double eval = sample["Reference Evaluations"][i];

    if( !isfinite(eval) )
    {
      korali::logWarning("Normal","Non-finite value detected in the results passed in the log-likelihood function.\n");
      sample["logLikelihood"] = -korali::Inf;
      return;
    }

    double diff   = _referenceData[i] - eval;
    double denom  = sigma*_referenceData[i];
    ssn += diff*diff / (denom*denom);
    logSigma += log(denom);
  }

  sample["logLikelihood"] = -0.5*( _referenceData.size()*log(2*M_PI) + ssn) - _referenceData.size()*logSigma;
}


void korali::problem::bayesian::Reference::loglikelihoodNormalGeneral(korali::Sample& sample)
{
  double sse = compute_normalized_sse( sample["Reference Evaluations"], sample["Standard Deviation Model"], _referenceData );

  if( isinf(sse) )
    sample["logLikelihood"] = -korali::Inf;
  else{
     double loglike = 0.;
    for(size_t i=0; i<sample["Standard Deviation Model"].size(); i++)
      loglike -= log( (double) sample["Standard Deviation Model"][i] );
    loglike +=  -0.5*( _referenceData.size() + sse );

    sample["logLikelihood"] = loglike;
  }
}
