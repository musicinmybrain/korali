#include "engine.hpp"
#include "modules/conduit/concurrent/concurrent.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/problem/problem.hpp"
#include "modules/solver/solver.hpp"
#include <fcntl.h>
#include <sched.h>
#include <sys/types.h>
#include <sys/wait.h>

#define BUFFERSIZE 4096

void korali::conduit::Concurrent::initialize()
{
  // Instantiating Engine logger.
  _logger = new korali::Logger();

  if (_concurrentJobs < 1) _logger->logError("You need to define at least 1 concurrent job(s) for external models \n");
  _resultPipe.clear();
  _inputsPipe.clear();
  while (!_launcherQueue.empty()) _launcherQueue.pop();

  for (int i = 0; i < _concurrentJobs; i++) _resultPipe.push_back(std::vector<int>(2));
  for (int i = 0; i < _concurrentJobs; i++) _inputsPipe.push_back(std::vector<int>(2));
  for (int i = 0; i < _concurrentJobs; i++) _launcherQueue.push(i);

  // Opening Inter-process communicator pipes
  for (int i = 0; i < _concurrentJobs; i++)
  {
    if (pipe(_inputsPipe[i].data()) == -1) _logger->logError("Unable to create inter-process pipe. \n");
    if (pipe(_resultPipe[i].data()) == -1) _logger->logError("Unable to create inter-process pipe. \n");
    fcntl(_resultPipe[i][0], F_SETFL, fcntl(_resultPipe[i][0], F_GETFL) | O_NONBLOCK);
    fcntl(_resultPipe[i][1], F_SETFL, fcntl(_resultPipe[i][1], F_GETFL) | O_NONBLOCK);
  }
}

void korali::conduit::Concurrent::finalize()
{
  auto terminationJs = knlohmann::json();
  terminationJs["Conduit Action"] = "Terminate";

  std::string terminationString = terminationJs.dump();
  size_t terminationStringSize = terminationString.size();

  for (int i = 0; i < _concurrentJobs; i++)
  {
    write(_inputsPipe[i][1], &terminationStringSize, sizeof(size_t));
    write(_inputsPipe[i][1], terminationString.c_str(), terminationStringSize * sizeof(char));
  }

  for (int i = 0; i < _concurrentJobs; i++)
  {
    int status;
    pid_t processId;
    processId = ::wait(&status);
  }

  for (int i = 0; i < _concurrentJobs; i++)
  {
    close(_resultPipe[i][1]); // Closing pipes
    close(_resultPipe[i][0]); // Closing pipes
    close(_inputsPipe[i][1]); // Closing pipes
    close(_inputsPipe[i][0]); // Closing pipes
  }

  korali::Conduit::finalize();
}

void korali::conduit::Concurrent::initServer()
{
  for (int i = 0; i < _concurrentJobs; i++)
  {
    pid_t processId = fork();
    if (processId == 0) worker(i);
    _workerPids.push_back(processId);
  }
}

void korali::conduit::Concurrent::update(korali::Sample &sample)
{
  std::string resultString = sample._js.getJson().dump();
  size_t resultStringSize = resultString.size();

  write(_resultPipe[_workerId][1], &resultStringSize, sizeof(size_t));
  write(_resultPipe[_workerId][1], resultString.c_str(), resultStringSize * sizeof(char));
}

void korali::conduit::Concurrent::worker(int workerId)
{
  _workerId = workerId;

  while (true)
  {
    size_t inputStringSize;
    read(_inputsPipe[workerId][0], &inputStringSize, sizeof(size_t));

    char inputString[inputStringSize + BUFFERSIZE];

    size_t curPos = 0;
    while (curPos < inputStringSize)
    {
      size_t bufSize = BUFFERSIZE;
      if (curPos + bufSize > inputStringSize) bufSize = inputStringSize - curPos;
      read(_inputsPipe[workerId][0], inputString + curPos, bufSize * sizeof(char));
      curPos += bufSize;
      sched_yield(); // Guarantees MacOs finishes the pipe reading
    }
    inputString[inputStringSize] = '\0';

    auto actionJs = knlohmann::json::parse(inputString);

    if (actionJs["Conduit Action"] == "Terminate") exit(0);

    if (actionJs["Conduit Action"] == "Process Sample") initiateSample(actionJs);

    if (actionJs["Conduit Action"] == "Stack Engines")
      for (size_t i = 0; i < actionJs["Engines"].size(); i++)
        _engineStack.push(korali::Engine::deserialize(actionJs["Engines"][i]));

    if (actionJs["Conduit Action"] == "Pop Engine") _engineStack.pop();
  }
}

void korali::conduit::Concurrent::processSample(korali::Sample &sample)
{
  korali::Engine *engine = _engineStack.top();

  int launcherId = -1;
  if (JsonInterface::isDefined(sample._js.getJson(), "['Worker']"))
  {
    launcherId = sample["Worker"];
  }
  else
  {
    while (_launcherQueue.empty())
    {
      sample._state = SampleState::waiting;
      co_switch(engine->_currentExperiment->_thread);
    }
    launcherId = _launcherQueue.front();
    _launcherQueue.pop();
  }

  auto js = knlohmann::json();
  js["Start Time"] = std::chrono::duration<double>(std::chrono::high_resolution_clock::now() - _startTime).count() + _cumulativeTime;

  auto sampleJs = sample._js.getJson();
  sampleJs["Conduit Action"] = "Process Sample";

  std::string inputString = sampleJs.dump();
  size_t inputStringSize = inputString.size();

  write(_inputsPipe[launcherId][1], &inputStringSize, sizeof(size_t));
  write(_inputsPipe[launcherId][1], inputString.c_str(), inputStringSize * sizeof(char));

  int readBytes = -1;
  while (readBytes < 0)
  {
    // Check for child defunction
    for (int i = 0; i < _workerPids.size(); i++)
    {
      int status;
      pid_t result = waitpid(_workerPids[i], &status, WNOHANG);
      if (result != 0) _logger->logError("Worker %i (Pid: %d) exited unexpectedly.\n", i, _workerPids[i]);
    }

    size_t resultStringSize;
    readBytes = read(_resultPipe[launcherId][0], &resultStringSize, sizeof(size_t));

    if (readBytes > 0)
    {
      char resultString[resultStringSize + 1];
      while (read(_resultPipe[launcherId][0], resultString, resultStringSize * sizeof(char)) < 0)
        ;

      resultString[resultStringSize] = '\0';
      sample._js.getJson() = knlohmann::json::parse(resultString);

      _launcherQueue.push(launcherId);
    }
    else
    {
      sample._state = SampleState::waiting;
      co_switch(engine->_currentExperiment->_thread);
    }
  }

  js["End Time"] = std::chrono::duration<double>(std::chrono::high_resolution_clock::now() - _startTime).count() + _cumulativeTime;
  js["Solver Id"] = engine->_currentExperiment->_experimentId;
  js["Current Generation"] = engine->_currentExperiment->_currentGeneration;
  __profiler["Timelines"]["Worker " + std::to_string(launcherId)] += js;
}

void korali::conduit::Concurrent::stackEngine(korali::Engine *engine)
{
  auto newStack = _engineStack;
  newStack.push(engine);

  for (size_t i = 0; i < newStack.size() - 1; i++) popEngine();

  _engineStack = newStack;

  size_t stackSize = newStack.size();
  std::vector<korali::Engine *> engineList;
  for (size_t i = 0; i < stackSize; i++)
  {
    engineList.push_back(newStack.top());
    newStack.pop();
  }

  auto stackJs = knlohmann::json();
  stackJs["Conduit Action"] = "Stack Engines";

  for (int i = 0; i < stackSize; i++)
    engineList[stackSize - i - 1]->serialize(stackJs["Engines"][i]);

  std::string stackString = stackJs.dump();
  size_t stackStringSize = stackString.size();

  for (int i = 0; i < _concurrentJobs; i++)
  {
    write(_inputsPipe[i][1], &stackStringSize, sizeof(size_t));

    size_t curPos = 0;
    while (curPos < stackStringSize)
    {
      size_t bufSize = BUFFERSIZE;
      if (curPos + bufSize > stackStringSize) bufSize = stackStringSize - curPos;
      write(_inputsPipe[i][1], stackString.c_str() + curPos, bufSize * sizeof(char));
      curPos += bufSize;
    }
  }
}

void korali::conduit::Concurrent::popEngine()
{
  _engineStack.pop();

  auto engineJs = knlohmann::json();
  engineJs["Conduit Action"] = "Pop Engine";

  std::string engineString = engineJs.dump();
  size_t engineStringSize = engineString.size();

  for (int i = 0; i < _concurrentJobs; i++)
  {
    write(_inputsPipe[i][1], &engineStringSize, sizeof(size_t));
    write(_inputsPipe[i][1], engineString.c_str(), engineStringSize * sizeof(char));
  }
}

size_t korali::conduit::Concurrent::maxConcurrency()
{
  return _concurrentJobs;
}
