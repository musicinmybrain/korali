#include "engine.hpp"
#include "modules/conduit/concurrent/concurrent.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/problem/problem.hpp"
#include "modules/solver/solver.hpp"
#include <sys/wait.h>
#include <sys/types.h>
#include <fcntl.h>

void korali::conduit::Concurrent::initialize()
{
 // Instantiating Engine logger.
 _logger = new korali::Logger();

 if (_concurrentJobs < 1) _logger->logError("You need to define at least 1 concurrent job(s) for external models \n");
 _resultPipe.clear();
 _inputsPipe.clear();
 while(!_launcherQueue.empty()) _launcherQueue.pop();

 for (int i = 0; i < _concurrentJobs; i++) _resultPipe.push_back(std::vector<int>(2));
 for (int i = 0; i < _concurrentJobs; i++) _inputsPipe.push_back(std::vector<int>(2));
 for (int i = 0; i < _concurrentJobs; i++) _launcherQueue.push(i);

 // Opening Inter-process communicator pipes
 for (int i = 0; i < _concurrentJobs; i++)
 {
  if (pipe(_inputsPipe[i].data()) == -1) _logger->logError("Unable to create inter-process pipe. \n");
  if (pipe(_resultPipe[i].data()) == -1) _logger->logError("Unable to create inter-process pipe. \n");
  fcntl(_resultPipe[i][0], F_SETFL, fcntl(_resultPipe[i][0], F_GETFL) | O_NONBLOCK);
  fcntl(_resultPipe[i][1], F_SETFL, fcntl(_resultPipe[i][1], F_GETFL) | O_NONBLOCK);
 }

 for(int i = 0; i < _concurrentJobs; i++)
 {
  pid_t processId = fork();
  if (processId == 0) worker(i);
  _workerPids.push_back(processId);
 }
}

void korali::conduit::Concurrent::finalize()
{
 korali::Engine* engine = _engineStack.top();

 if (engine->_isDryRun == true) return;

 auto terminationJs = knlohmann::json();
 terminationJs["Conduit Action"] = "Terminate";

 std::string terminationString = terminationJs.dump();
 size_t terminationStringSize = terminationString.size();

 for(int i = 0; i < _concurrentJobs; i++)
 {
  write(_inputsPipe[i][1], &terminationStringSize, sizeof(size_t));
  write(_inputsPipe[i][1], terminationString.c_str(), terminationStringSize * sizeof(char));
 }

 for(int i = 0; i < _concurrentJobs; i++)
 {
  int status;
  pid_t processId;
  processId = ::wait(&status);
 }

 for (int i = 0; i < _concurrentJobs; i++)
 {
  close(_resultPipe[i][1]); // Closing pipes
  close(_resultPipe[i][0]); // Closing pipes
  close(_inputsPipe[i][1]); // Closing pipes
  close(_inputsPipe[i][0]); // Closing pipes
 }

 korali::Conduit::finalize();
}

void korali::conduit::Concurrent::worker(int workerId)
{
 korali::Engine* engine = _engineStack.top();

 while(true)
 {
  size_t inputStringSize;
  read(_inputsPipe[workerId][0], &inputStringSize, sizeof(size_t));

  char inputString[inputStringSize + 1];
  read(_inputsPipe[workerId][0], inputString, inputStringSize * sizeof(char));
  inputString[inputStringSize] = '\0';

  auto actionJs = knlohmann::json::parse(inputString);

  if (actionJs["Conduit Action"] == "Terminate") exit(0);

  if (actionJs["Conduit Action"] == "Process Sample");
  {
   korali::Sample sample;
   sample._js.getJson() = actionJs;

   size_t experimentId = sample["Experiment Id"];
   std::string operation = sample["Operation"];

   engine->_experimentVector[experimentId]->_problem->runOperation(operation, sample);
   std::string resultString = sample._js.getJson().dump();
   size_t resultStringSize = resultString.size();

   write(_resultPipe[workerId][1], &resultStringSize, sizeof(size_t));
   write(_resultPipe[workerId][1], resultString.c_str(), resultStringSize * sizeof(char));
  }
 }
}

void korali::conduit::Concurrent::processSample(korali::Sample& sample)
{
 korali::Engine* engine = _engineStack.top();

 while (_launcherQueue.empty())
 {
  sample._state = SampleState::waiting;
  co_switch(engine->_currentExperiment->_thread);
 }

 int launcherId = _launcherQueue.front(); _launcherQueue.pop();

 auto js = knlohmann::json();
 js["Start Time"] = std::chrono::duration<double>(std::chrono::high_resolution_clock::now()-_startTime).count() + _cumulativeTime;

 auto sampleJs = sample._js.getJson();
 sampleJs["Conduit Action"] = "Process Sample";

 std::string inputString = sampleJs.dump();
 size_t inputStringSize = inputString.size();

 write(_inputsPipe[launcherId][1], &inputStringSize, sizeof(size_t));
 write(_inputsPipe[launcherId][1], inputString.c_str(), inputStringSize * sizeof(char));

 int readBytes = -1;
 while(readBytes < 0)
 {
  // Check for child defunction
  for (int i = 0; i < _workerPids.size(); i++)
  {
   int status;
   pid_t result = waitpid(_workerPids[i], &status, WNOHANG);
   if (result != 0) _logger->logError("Worker %d (Pid: %d) exited unexpectedly.\n");
  }

  size_t resultStringSize;
  readBytes = read(_resultPipe[launcherId][0], &resultStringSize, sizeof(size_t));

  if(readBytes > 0)
  {
   char resultString[resultStringSize + 1];
   while(read(_resultPipe[launcherId][0], resultString, resultStringSize * sizeof(char)) < 0);

   resultString[resultStringSize] = '\0';
   sample._js.getJson() = knlohmann::json::parse(resultString);

   _launcherQueue.push(launcherId);
  }
  else
  {
   sample._state = SampleState::waiting;
   co_switch(engine->_currentExperiment->_thread);
  }
 }

 js["End Time"] = std::chrono::duration<double>(std::chrono::high_resolution_clock::now()-_startTime).count() + _cumulativeTime;
 js["Solver Id"] = engine->_currentExperiment->_experimentId;
 js["Current Generation"] = engine->_currentExperiment->_currentGeneration;
 __profiler["Timelines"]["Worker " + std::to_string(launcherId)] += js;

}
//
//void korali::conduit::Concurrent::stackEngine(korali::Engine* engine)
//{
// if (engine->_isDryRun == true) return;
//
//  auto terminationJs = knlohmann::json();
//  terminationJs["Conduit Action"] = "Terminate";
//
//  std::string terminationString = terminationJs.dump();
//  size_t terminationStringSize = terminationString.size();
//
//  for(int i = 0; i < _concurrentJobs; i++)
//  {
//   write(_inputsPipe[i][1], &terminationStringSize, sizeof(size_t));
//   write(_inputsPipe[i][1], terminationString.c_str(), terminationStringSize * sizeof(char));
//  }
//
//  for(int i = 0; i < _concurrentJobs; i++)
//  {
//   int status;
//   pid_t processId;
//   processId = ::wait(&status);
//  }
//
//  for (int i = 0; i < _concurrentJobs; i++)
//  {
//   close(_resultPipe[i][1]); // Closing pipes
//   close(_resultPipe[i][0]); // Closing pipes
//   close(_inputsPipe[i][1]); // Closing pipes
//   close(_inputsPipe[i][0]); // Closing pipes
//  }
//
//
//}
