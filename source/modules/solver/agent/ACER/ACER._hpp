#ifndef _KORALI_AGENT_ACER_HPP_
#define _KORALI_AGENT_ACER_HPP_

#include "modules/problem/reinforcementLearning/discrete/discrete.hpp"
#include "modules/solver/agent/agent.hpp"

namespace korali
{
namespace solver
{
namespace agent
{
class ACER : public Agent
{
  public:
  /**
  * @brief Storage for the pointer to the (discrete) learning problem
  */
  problem::reinforcementLearning::Discrete *_discreteProblem;

  /**
   * @brief Pointer to training experiment's problem
   */
  problem::SupervisedLearning *_criticProblem;

  /**
  * @brief Pointer to training experiment's learner
  */
  learner::DeepGD *_criticLearner;

  /**
   * @brief Korali experiment for the training of the Q(s,a)
   */
  korali::Experiment _criticExperiment;

  /**
  * @brief Korali experiment for P(a | s) for all actions
  */
  korali::Experiment _policyExperiment;

  /**
   * @brief Pointer to training the actor network
   */
  learner::DeepGD *_policyLearner;

  /**
   * @brief Pointer to actor's experiment problem
   */
  problem::SupervisedLearning *_policyProblem;

  /**
   * @brief Storage for statistical data of the policy gradients
   */
  std::vector<double> _avgGradients;

  /**
   * @brief Variable to calculate the total number of actions in the action space
   */
  size_t _actionCount;

  /**
   * @brief Calculates the state value function V(s) = Expectation_a [ Q(s,a) | s ] of a given experience using the latest critic
   * @param state state to evaluate
   * @return The value of the V(s)
   */
  double stateValueFunction(const std::vector<double> &state);

  /**
   * @brief Calculates the state+action value function Q(s,a) = Expectation_s,a [ R | s,a ] of a given experience using the latest critic
   * @param state state to evaluate
   * @param actionIdx action to evaluate
   * @return The value of Q(s,a)
   */
  double stateActionValueFunction(const std::vector<double> &state, const size_t &actionIdx);

  /**
   * @brief Calculates (recursively) the Qretrace value of a given (state/action) experience
   * @param expId Position within the experience replay history that locates the given experience
   * @return The value of the retrace function for the given experience
   */
  double qRetrace(size_t expId);

  /**
   * @brief Gets a random action index
   * @return Index of the action selected
   */
  size_t getRandomActionIndex();

  /**
   * @brief Produces a probability function value vector from a set of input logits.
   * @param intput The input values to forward propagate
   * @return The generated probability function values
   */
  std::vector<double> forwardProbabilityFunction(const std::vector<double> &logits);

  /**
   * @brief Calculates the gradient of the probability function
   * @param output The output values to backpropagate
   * @return The gradient of the inputs wrt the output values given
   */
  std::vector<double> backwardProbabilityFunction(const std::vector<double> &gradients);

  std::vector<double> queryPolicy(const std::vector<double> &state) override;
  void getAction(korali::Sample &sample) override;
  void updateHyperparameters(const knlohmann::json &hyperparameters) override;
  void trainAgent() override;
  void printAgentInformation() override;
  void initializeAgent() override;
};

} // namespace agent
} // namespace solver
} // namespace korali

#endif // _KORALI_AGENT_ACER_HPP_
