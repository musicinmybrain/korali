{
 "Configuration Settings":
 [
  {
   "Name": [ "Discount Factor" ],
   "Type": "double",
   "Description": "Discount Factor for future states."
  },
  {
    "Name": [ "Neural Network" ],
    "Type": "korali::NeuralNetwork*",
    "Description": "Indicates the configuration of the underlying neural network to use."
  },
  {
   "Name": [ "Epsilon", "Initial Value" ],
   "Type": "double",
   "Description": "Specifies the initial value for epsilon, the probability of not choosing the best possible action (exploitation) and using a random selection instead (exploration). e = 0 represents a pure greedy strategy, 0 < e < 1 represents the epsilon-greedy strategy, and e = 1 represents a purely random strategy."
  },
  {
   "Name": [ "Epsilon", "Decrease Rate" ],
   "Type": "double",
   "Description": "Specifies the how much the value of epsilon should be decreased as generations progress. A rate d(e) > 0.0 represents the Epsilon-decreasing strategy."
  },
  {
   "Name": [ "Epsilon", "Target Value" ],
   "Type": "double",
   "Description": "Specifies the last value of epsilon after which it will not be reduced any further."
  },
  {
    "Name": [ "Action Optimizer" ],
    "Type": "knlohmann::json",
    "Description": "Represents the state and configuration of the solver algorithm for argmax_action(Q)."
  },
  {
    "Name": [ "Weight Optimizer" ],
    "Type": "knlohmann::json",
    "Description": "Represents the state and configuration of the solver algorithm for the weights and biases of the NN."
  },
  {
    "Name": [ "Mini Batch Size" ],
    "Type": "size_t",
    "Description": "The number of experiences to randomly select to train the neural network with."
  },
  {
    "Name": [ "Optimization Steps Per Update" ],
    "Type": "size_t",
    "Description": "The number of optimization steps on the training Q estimator before updating the actual Q estimator."
  },
  {
   "Name": [ "Batch Normalization", "Enabled" ],
   "Type": "bool",
   "Description": "Uses batch normalization on all of the layers of the NN to reduce the detrimental effects of divergence in number magnitudes."
  },
  {
   "Name": [ "Batch Normalization", "Correction Steps" ],
   "Type": "size_t",
   "Description": "How many mini-batches will be used to correct mean/variance bias."
  }
 ],
 
 "Results":
 [
 
 ],
 
  "Termination Criteria":
 [
  {
    "Name": [ "Max Optimization Steps" ],
    "Type": "size_t",
    "Criteria": "(_maxOptimizationSteps > 0) && (_optimizationStepCount >= _maxOptimizationSteps)",
    "Description": "The solver will stop when the given number of optimizations have been made to the learner."
  }
 ],

 "Variables Configuration":
 [

 ],

 "Internal Settings":
 [
  {
   "Name": [ "Epsilon", "Current Value" ],
   "Type": "double",
   "Description": "Specifies the current value of epsilon."
  },
  {
   "Name": [ "Cumulative Q Star" ],
   "Type": "double",
   "Description": "Sum of E(Q) among the experiences from all minibatches in this generation."
  },
  {
   "Name": [ "Average Q Star" ],
   "Type": "double",
   "Description": "Average E(Q) among the experiences from all minibatches in this generation."
  },
  {
   "Name": [ "Optimization Step Count" ],
   "Type": "size_t",
   "Description": "Keeps track of the number of optimization steps performed by the learner."
  }
 ],
 
 "Module Defaults":
 {
  "Neural Network":   { "Type": "Neural Network" },
  
  "Discount Factor": 0.9,
  "Epsilon":
  {
   "Initial Value": 0.9,
   "Decrease Rate": 0.001,
   "Target Value": 0.1
  },
  
  "Batch Normalization":
  {
   "Enabled": false,
   "Correction Steps": 128
  },
  
  "Mini Batch Size": 32,
  "Optimization Steps Per Update": 10
 },
 
 "Variable Defaults":
 {

 }
}
