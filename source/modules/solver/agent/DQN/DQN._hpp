#ifndef _KORALI_AGENT_DQN_HPP_
#define _KORALI_AGENT_DQN_HPP_

#include "modules/solver/agent/agent.hpp"

namespace korali
{
namespace solver
{
namespace agent
{
class DQN : public Agent
{
  public:

  /**
   * @brief Pointer to training experiment's problem
   */
  problem::SupervisedLearning *_criticProblem;

  /**
  * @brief Pointer to training experiment's learner
  */
  learner::DeepGD *_criticLearner;

  /**
   * @brief Korali experiment for the training of the Qvalue-estimator
   */
  korali::Experiment _criticExperiment;

  /**
  * @brief Korali experiment for argmax_action(Q) based on a trained Q-Network
  */
  korali::Experiment _policyExperiment;

  /**
   * @brief Function to evaluate the Q* of a given action
   * @param sample Sample containing the action to evaluate
   * @param getGradients Indicates whether the gradients are required
   */
  void evaluateAction(Sample &sample, bool getGradients);

  /**
   * @brief Calculates the state+action value function Q(s,a) = Expectation_s,a [ R | s,a ] of a given experience using the latest critic
   * @param state state to evaluate
   * @param action action to evaluate
   * @return The value of Q(s,a)
   */
  double stateActionValueFunction(const std::vector<double> &state, const std::vector<double> &action);

  /**
   * @brief Gets a random action
   * @return A vector containing the random action
   */
  std::vector<double> getRandomAction();

  void getAction(korali::Sample& sample) override;
  std::vector<double> queryPolicy(const std::vector<double> &state) override;
  void updateHyperparameters(const knlohmann::json &hyperparameters) override;
  void trainAgent() override;
  void printAgentInformation() override;
  void initializeAgent() override;
};

} // namespace agent
} // namespace solver
} // namespace korali

#endif // _KORALI_AGENT_DQN_HPP_
