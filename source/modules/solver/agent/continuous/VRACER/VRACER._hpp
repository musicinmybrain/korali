#ifndef _KORALI_AGENT_CONTINUOUS_VRACER_HPP_
#define _KORALI_AGENT_CONTINUOUS_VRACER_HPP_

#include "modules/distribution/univariate/normal/normal.hpp"
#include "modules/problem/reinforcementLearning/continuous/continuous.hpp"
#include "modules/solver/agent/continuous/continuous.hpp"

namespace korali
{
namespace solver
{
namespace agent
{
namespace continuous
{
class VRACER : public Continuous
{
  public:
  /**
  * @brief Stores experience replay importance weight.
  */
  cBuffer<float> _experienceReplayImportanceWeight;

  /**
  * @brief Stores experience replay action probability gaussian standard deviations.
  */
  cBuffer<float> _experienceReplayActionProbability;

  /**
   * @brief Pointer to training the actor network
   */
  learner::DeepSupervisor *_criticPolicyLearner;

  /**
  * @brief Korali experiment for obtaining the agent's action
  */
  korali::Experiment _criticPolicyExperiment;

  /**
   * @brief Pointer to actor's experiment problem
   */
  problem::SupervisedLearning *_criticPolicyProblem;

  /**
   * @brief Variable to calculate the total number of actions in the action space
   */
  size_t _actionCount;

  /**
  * @brief Variable with state value
  */
  float _stateValue;


  /**
   * @brief Compute Qret using all experiences after
   * @param startId ID to current experience
   * @return The value of Qret
   */
  // float computeQret(size_t startId);

  float retraceFunction(size_t expId);
  void forwardPolicy(const std::vector<float> &state) override;
  float stateValueFunction(const std::vector<float> &state);
  void trainAgent() override;

  void getAction(korali::Sample &sample) override;
  
  void updateAgentPolicy(const knlohmann::json &hyperparameters) override;
  void printAgentInformation() override;
  void initializeAgent() override;
};

} // namespace continuous
} // namespace agent
} // namespace solver
} // namespace korali

#endif // _KORALI_AGENT_CONTINUOUS_VRACER_HPP_
