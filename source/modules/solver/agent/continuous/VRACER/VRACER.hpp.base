#pragma once

#include "modules/distribution/univariate/normal/normal.hpp"
#include "modules/problem/reinforcementLearning/continuous/continuous.hpp"
#include "modules/solver/agent/continuous/continuous.hpp"

__startNamespace__;

class __className__ : public __parentClassName__
{
  public:
  /**
   * @brief Update the V-target or current and previous experiences in the episode
   * @param expId Current Experience Id
   */
  void updateVtbc(size_t expId);

  /**
   * @brief Calculates the gradients for the policy/critic neural network
   * @param miniBatch The indexes of the experience mini batch
   * @param policyIdx The indexes of the policy to compute the gradient for
   */
  void calculatePolicyGradients(const std::vector<std::pair<size_t, size_t>> &miniBatch, const size_t policyIdx);

  /**
   * @brief [Statistics] Keeps track of the mu of the current minibatch for each action variable
   */
  std::vector<float> _miniBatchPolicyMean;

  /**
   * @brief [Statistics] Keeps track of the sigma of the current minibatch for each action variable
   */
  std::vector<float> _miniBatchPolicyStdDev;

  /**
   * @brief [Statistics] Keeps track of the mu of the current minibatch for each action variable
   */
  std::vector<float> _miniBatchCurrentPolicyMean;

  /**
   * @brief [Statistics] Keeps track of the sigma of the individual policies in Bayesian learning current minibatch for each action variable
   */
  std::vector<float> _miniBatchCurrentPolicyStdDev;

  /**
   * @brief [Statistics] Keeps track of the mean of the policy gradients
   */
  std::vector<float> _miniBatchPolicyGradientMean;

  /**
   * @brief [Statistics] Keeps track of the sigma of the policy gradients
   */
  std::vector<float> _miniBatchPolicyGradientStdDev;

  /**
   * @brief [Statistics] Keeps track of the mean of the policy gradients
   */
  std::vector<float> _miniBatchKLGradientMean;

  /**
   * @brief [Statistics] Keeps track of the sigma of the policy gradients
   */
  std::vector<float> _miniBatchKLGradientStdDev;


  knlohmann::json getPolicy() override;
  void setPolicy(const knlohmann::json &hyperparameters) override;
  float calculateStateValue(const std::vector<std::vector<float>> &stateSequence, const size_t policyIdx = 0) override;
  void runPolicy(const std::vector<std::vector<std::vector<float>>> &stateSequenceBatch, std::vector<policy_t> &policy, const size_t policyIdx = 0) override;
  void computePredictivePosteriorDistribution(const std::vector<std::vector<std::vector<float>>> &stateSequenceBatch, std::vector<policy_t> &curPolicy) override;
  void finalizePredictivePosterior(const std::vector<std::vector<std::vector<float>>> &stateSequenceBatch, std::vector<policy_t> &predictivePosteriorDistribution, const size_t policyIdx) override;
  void trainPolicy() override;
  void printInformation() override;
  void initializeAgent() override;
};

__endNamespace__;
