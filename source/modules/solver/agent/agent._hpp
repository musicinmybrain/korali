#ifndef _KORALI_AGENT_HPP_
#define _KORALI_AGENT_HPP_

#include "engine.hpp"
#include "modules/problem/reinforcementLearning/reinforcementLearning.hpp"
#include "modules/solver/solver.hpp"
#include "modules/neuralNetwork/neuralNetwork.hpp"
#include <algorithm> // std::shuffle
#include <random>

namespace korali
{
namespace solver
{
class Agent : public Solver
{
  public:
  /**
  * @brief Storage for the pointer to the learning problem
  */
  problem::ReinforcementLearning *_problem;

  /**
   * @brief Random device for the generation of shuffling numbers
   */
  std::random_device rd;

  /**
  * @brief Mersenne twister for the generation of shuffling numbers
  */
  std::mt19937 *mt;

  /**
   * @brief Gets the next action for the actor, based on a sample containing a state, from inside Korali
   * @param sample the sample containing the state and other required information
   */
  virtual void getAction(Sample &sample) = 0;

  /**
   * @brief Gets the next action for the actor, based on the state, as requested by the user
   * @param state The vector containing the state and other required information
   * @return A vector containing the action
   */
  virtual std::vector<double> getAction(const std::vector<double> &state) = 0;

  /**
  * @brief Updates the algorithm's policy, based on the new experiences
  */
  virtual void updatePolicy() = 0;

  /**
  * @brief Updates the underlying learner's hyperparameters to calculate the next action of the agent
  */
  virtual void updateHyperparmeters(Sample& sample) = 0;

  /**
  * @brief Normalizes neural network batch normalization mean and variances
  * @param The neural network to normalize
  */
  void normalizeNeuralNetwork(korali::NeuralNetwork* nn);

  /**
 * @brief Runs a generation of the environment(s), running an action on each episode, and updating the policy.
 */
  void runGeneration() override;

  void printGenerationAfter() override;
  void initialize() override;
};

} // namespace solver
} // namespace korali

#endif // _KORALI_AGENT_HPP_
