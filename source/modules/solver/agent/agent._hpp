#ifndef _KORALI_AGENT_HPP_
#define _KORALI_AGENT_HPP_

#include "auxiliar/cbuffer.hpp"
#include "modules/problem/reinforcementLearning/reinforcementLearning.hpp"
#include "modules/problem/supervisedLearning/supervisedLearning.hpp"
#include "modules/solver/learner/deepSupervisor/deepSupervisor.hpp"
#include <algorithm> // std::shuffle
#include <random>

namespace korali
{
namespace solver
{

struct experience_t
{
 std::vector<float> state;
 std::vector<float> action;
 float reward;
 float priority;
 float probability;
 bool isTerminal;

 knlohmann::json metadata;
 knlohmann::json cache;
};

class Agent : public Solver
{
  public:

 /**
 * @brief Stores experience replay states.
 */
  cBuffer<experience_t> _experienceReplay;

  /**
  * @brief Stores the priority annealing rate.
  */
  float _priorityAnnealingRate;

  /**
  * @brief Stores the importance weight annealing factor.
  */
  float _importanceWeightAnnealingRate;

  /**
  * @brief Storage for the pointer to the learning problem
  */
  problem::ReinforcementLearning *_problem;

  /**
   * @brief Random device for the generation of shuffling numbers
   */
  std::random_device rd;

  /**
  * @brief Mersenne twister for the generation of shuffling numbers
  */
  std::mt19937 *mt;

  /**
  * @brief The value to use for probability of random actions.
  */
  float _randomActionProbabilityEffectiveValue;

  /**
  * @brief Storage for the cache for the qRet value of the next experience
  */
  std::vector<float> _qRetNextCache;

  /**
   * @brief Storage for the cache for the qOpc value of the next experience
   */
  std::vector<float> _qOpcNextCache;

  /**
   * @brief Storage for the cache for the vTbc value of the next experience
   */
  std::vector<float> _vTbcNextCache;

  /**
   * @brief Storage for the age of each element of the retrace cache
   */
  std::vector<ssize_t> _qCacheAge;

  /**
  * @brief Trains the Agent's critic/policy, based on the new experiences
  */
  virtual void trainAgent() = 0;

  /**
  * @brief Updates the agent's hyperparameters
  * @param hyperparameters The hyperparameters to update the agent.
  */
  virtual void updateAgentPolicy(const knlohmann::json &hyperparameters) = 0;

  /**
    * @brief Initializes the internal state of the policy
    */
  virtual void initializeAgent() = 0;

  /**
 * @brief Runs a generation of the environment(s), running an action on each episode, and updating the policy.
 */
  void runGeneration() override;

  /**
   * @brief Prints information about the training policy
   */
  virtual void printAgentInformation() = 0;

  /**
   * @brief Gathers the next action either from the policy or randomly
   * @param sample Sample on which the action and metadata will be stored
   */
  virtual void getAction(korali::Sample &sample) = 0;

  /**
   * @brief Mini-batch based normalization routine for Neural Networks with state and action inputs (typically critics)
   * @param neuralNetwork Neural Network to normalize
   * @param miniBatchSize Number of entries in the normalization minibatch
   * @param normalizationSteps How many normalization steps to perform (and grab the average)
   */
  void normalizeStateActionNeuralNetwork(NeuralNetwork *neuralNetwork, size_t miniBatchSize, size_t normalizationSteps);

  /**
   * @brief Mini-batch based normalization routine for Neural Networks with state inputs only (typically policy)
   * @param neuralNetwork Neural Network to normalize
   * @param miniBatchSize Number of entries in the normalization minibatch
   * @param normalizationSteps How many normalization steps to perform (and grab the average)
   */
  void normalizeStateNeuralNetwork(NeuralNetwork *neuralNetwork, size_t miniBatchSize, size_t normalizationSteps);

  /**
  * @brief Handles the addition of experience information to the replay memory and other management operations
  * @param experience The experience to process
  */
  void processExperience(knlohmann::json &experience);

  /**
  * @brief Updates priority of experience.
  * @param expId The experience to update
  * @param priority New value for experience expId
  */
  void updateExperienceReplayPriority(size_t expId, float priority);

  /**
  * @brief Updates probabilities of experiences stored based on their priority.
  */
  void updateExperienceReplayProbabilities();

  /**
  * @brief Update random action probability.
  */
  void updateRandomActionProbability();

  /**
  * @brief Generates an experience mini batch from the replay memory
  * @param size Size of the mini batch to create
  * @return A vector with the indexes to the experiences in the mini batch
  */
  std::vector<size_t> generateMiniBatch(size_t size);

  /**
  * @brief Calculates importance weights of experiences.
  * @param miniBatch vector of experience indices.
  * @return A vector with the importance weights corresponding to the experience indices.
  */
  std::vector<float> calculateImportanceWeights(std::vector<size_t> miniBatch);

  void printGenerationAfter() override;
  void initialize() override;
};

} // namespace solver
} // namespace korali

#endif // _KORALI_AGENT_HPP_
