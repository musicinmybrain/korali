{

 "Configuration Settings":
 [
   {
    "Name": [ "Learning Rate" ],
    "Type": "double",
    "Description": "Learning rate for Q adapations."
   },
   {
    "Name": [ "Discount Factor" ],
    "Type": "double",
    "Description": "Discount Factor for future states."
   },
   {
    "Name": [ "Initial Q Value" ],
    "Type": "double",
    "Description": "Defines the initial value for all entries of the Q table. It is recommended to set this value equal to the maximum model reward."
   },  
   {
    "Name": [ "Q Update Algorithm" ],
    "Type": "std::string",
    "Options": [
                { "Value": "Q-Learning", "Description": "Off Policy, selects always the best action for the next state." },
                { "Value": "SARSA", "Description": "On Policy, uses the exploration algorithm to select the action of the next state." }
               ],
    "Description": "Specifies whether updates to the QTable should be done off-policy or on-policy to use in the updates of the Q-table."
   },
   {
    "Name": [ "Epsilon" ],
    "Type": "double",
    "Description": "Specifies the probability of not choosing the best possible action (exploitation) and using a random selection instead (exploration). e = 0 represents a pure greedy strategy, 0 < e < 1 represents the epsilon-greedy strategy, and e = 1 represents a purely random strategy."
   },
   {
    "Name": [ "Epsilon Decrease Rate" ],
    "Type": "double",
    "Description": "Specifies the how much the value of epsilon should be decreased as generations progress. A rate d(e) > 0.0 represents the Epsilon-decreasing strategy."
   }
 ],

 "Termination Criteria":
 [
  {
    "Name": [ "Convergence Tolerance" ],
    "Type": "double",
    "Criteria": "_convergenceRate < _convergenceTolerance",
    "Description": "The solver will stop when convergence rate falls below this threshold."
  }
 ],

 "Variables Configuration":
 [
 ],
 
 "Internal Settings":
 [
   {
    "Name": [ "Q" ],
    "Type": "std::vector<double>",
    "Description": "Table containing Q values."
   },
   {
    "Name": [ "Convergence Rate" ],
    "Type": "double",
    "Description": "The rate at which the Q table has changed during this generation."
   },
   {
    "Name": [ "Uniform Generator" ],
    "Type": "korali::distribution::univariate::Uniform*",
    "Description": "Uniform random number generator for the epsilon-greedy strategy."
   }
 ],
 
 "Module Defaults":
 {
  "Learning Rate": 0.1,
  "Discount Factor": 0.1,
  "Epsilon": 0.0,
  "Epsilon Decrease Rate": 0.0,
  
  "Termination Criteria":
  {
   "Convergence Tolerance": 0.01
  },
  
  "Convergence Rate": Infinity,
  
  "Uniform Generator":
  {
   "Type": "Univariate/Uniform",
   "Minimum": 0.0,
   "Maximum": 1.0
  }
 },
 
 "Variable Defaults":
 {
 }
}
