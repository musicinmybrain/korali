#include "engine.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/solver/learner/gaussianProcess/gaussianProcess.hpp"
#include "sample/sample.hpp"

#ifdef _KORALI_USE_EIGEN
  #include <Eigen/Dense>
#endif

namespace korali
{
namespace solver
{
namespace learner
{
#ifdef _KORALI_USE_EIGEN
/**
  * @brief Converts a vector of floats to Eigen format
  * @param v the vector to convert
  * @return An Eigen vector type
 */
static Eigen::VectorXd toEigen(const std::vector<float> &v)
{
  Eigen::VectorXd ev(v.size());
  for (size_t i = 0; i < v.size(); ++i)
    ev[i] = v[i];
  return ev;
}
#endif

GaussianProcess::~GaussianProcess() = default;

void GaussianProcess::initialize()
{
#ifdef _KORALI_USE_LIBGP

  #ifdef _KORALI_USE_EIGEN

  _problem = dynamic_cast<problem::SupervisedLearning *>(_k->_problem);

  if (_problem->_inputTimestepCount > 1) KORALI_LOG_ERROR("Training data cannot be time-dependent.");
  if (_problem->_batchSize == 0) KORALI_LOG_ERROR("Training data has not been provided for variable 0.");
  if (_problem->_solutionVectorSize > 1) KORALI_LOG_ERROR("The solution space should be one dimensional.");

  _gpInputDimension = _problem->_inputVectorSize;
  _gp = std::make_unique<libgp::GaussianProcess>(_gpInputDimension, _covarianceFunction);

  _gpParameterDimension = _gp->covf().get_param_dim();

  // Creating evaluation lambda function for optimization
  auto evaluateProposal = [gp = _gp.get()](Sample &sample) { runSample(sample, gp); };

  _koraliExperiment["Problem"]["Type"] = "Optimization";
  _koraliExperiment["Problem"]["Objective Function"] = evaluateProposal;

  Eigen::VectorXd eParameters(_gpParameterDimension);

  for (size_t i = 0; i < _gpParameterDimension; i++)
  {
    _koraliExperiment["Variables"][i]["Name"] = "X" + std::to_string(i);
    eParameters[i] = _defaultHyperparameter;
    _koraliExperiment["Variables"][i]["Initial Value"] = eParameters[i];
  }
  _gp->covf().set_loghyper(eParameters);

  _koraliExperiment["Solver"] = _optimizer;
  _koraliExperiment["Solver"]["Termination Criteria"]["Max Generations"] = 1;

  _koraliExperiment["File Output"]["Frequency"] = 0;
  _koraliExperiment["File Output"]["Enabled"] = false;
  _koraliExperiment["Console Output"]["Frequency"] = 0;
  _koraliExperiment["Console Output"]["Verbosity"] = "Silent";
  _koraliExperiment["Random Seed"] = _k->_randomSeed++;

  // Pass the training data from korali to the GP library
  double inData[_gpInputDimension];
  double outData;

  // Running initialization to verify that the configuration is correct
  _koraliExperiment.initialize();

  for (size_t i = 0; i < _problem->_batchSize; ++i)
  {
    for (size_t j = 0; j < _gpInputDimension; j++)
      inData[j] = _problem->_inputData[0][i][j];

    outData = _problem->_solutionData[0][i][0];
    _gp->add_pattern(inData, outData);
  }

  #else
  KORALI_LOG_ERROR("Korali requires the Eigen library to be installed to use the Gaussian Process learner.\n");
  #endif

#else
  KORALI_LOG_ERROR("Korali requires the LibGP library to be installed to use the Gaussian Process learner.\n");
#endif
}

#ifdef _KORALI_USE_LIBGP
void GaussianProcess::runSample(Sample &sample, libgp::GaussianProcess *gp)
{
  #ifdef _KORALI_USE_EIGEN

  size_t gpParameterDimension = gp->covf().get_param_dim();
  const Eigen::VectorXd p = toEigen(sample["Parameters"].get<std::vector<float>>());

  gp->covf().set_loghyper(p);

  sample["F(x)"] = gp->log_likelihood();
  sample["P(x)"] = sample["F(x)"];

  Eigen::VectorXd eigenGrad = gp->log_likelihood_gradient();
  for (size_t i = 0; i < gpParameterDimension; i++)
    sample["Gradient"][i] = eigenGrad[i];

  #endif
}
#endif

void GaussianProcess::runGeneration()
{
  _koraliExperiment["Solver"]["Termination Criteria"]["Max Generations"] = _koraliExperiment._currentGeneration + 1;
  korali::Engine engine;
  engine.run(_koraliExperiment);
  _gpHyperparameters = _koraliExperiment["Results"]["Best Sample"]["Parameters"].get<std::vector<float>>();
}

void GaussianProcess::printGenerationAfter()
{
  return;
}

std::vector<std::vector<std::vector<float>>> GaussianProcess::getEvaluation(const std::vector<std::vector<std::vector<float>>> &input)
{
  std::vector<float> output(2);

  if (input.size() > 1) KORALI_LOG_ERROR("Gaussian Process does not support multi-timestep evaluation.\n");
  if (input[0].size() > 1) KORALI_LOG_ERROR("Gaussian Process does not support minibatch evaluation.\n");

#ifdef _KORALI_USE_LIBGP

  _gp->covf().set_loghyper(toEigen(_gpHyperparameters));

  std::vector<double> inputData(input[0][0].begin(), input[0][0].end());

  output[0] = _gp->f(inputData.data());
  output[1] = _gp->var(inputData.data());

#endif

  return {{output}};
}

std::vector<float> GaussianProcess::getInferenceHyperparameters()
{
  return _gpHyperparameters;
}

void GaussianProcess::setInferenceHyperparameters(const std::vector<float> &hyperparameters)
{
  _gpHyperparameters = hyperparameters;
}

std::vector<float> GaussianProcess::getTrainingHyperparameters()
{
  return _gpHyperparameters;
}

void GaussianProcess::setTrainingHyperparameters(const std::vector<float> &hyperparameters)
{
  _gpHyperparameters = hyperparameters;
}

} // namespace learner

} // namespace solver

} // namespace korali
