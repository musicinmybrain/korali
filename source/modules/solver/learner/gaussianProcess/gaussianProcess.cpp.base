#include "engine.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/solver/learner/gaussianProcess/gaussianProcess.hpp"
#include "sample/sample.hpp"

#include <Eigen/Dense>

@startNamespace

/**
  * @brief Converts a vector of floats to Eigen format
  * @param v the vector to convert
  * @return An Eigen vector type
 */
static Eigen::VectorXd toEigen(const std::vector<float> &v)
{
  Eigen::VectorXd ev(v.size());
  for (size_t i = 0; i < v.size(); ++i)
    ev[i] = v[i];
  return ev;
}

@className::~GaussianProcess() = default;

void @className::initialize()
{

  _problem = dynamic_cast<problem::SupervisedLearning *>(_k->_problem);

  if (_problem->_maxTimesteps > 1) KORALI_LOG_ERROR("Training data cannot be time-dependent.");
  if (_problem->_trainingBatchSize == 0) KORALI_LOG_ERROR("Training data has not been provided for variable 0.");
  if (_problem->_solutionSize > 1) KORALI_LOG_ERROR("The solution space should be one dimensional.");

  // Checking that incoming data has a correct format
  _problem->verifyData();

  _gpInputDimension = _problem->_inputSize;
  _gp = std::make_unique<libgp::GaussianProcess>(_gpInputDimension, _covarianceFunction);

  _gpParameterDimension = _gp->covf().get_param_dim();

  // Creating evaluation lambda function for optimization
  auto evaluateProposal = [gp = _gp.get()](Sample &sample) { runSample(sample, gp); };

  _koraliExperiment["Problem"]["Type"] = "Optimization";
  _koraliExperiment["Problem"]["Objective Function"] = evaluateProposal;

  Eigen::VectorXd eParameters(_gpParameterDimension);

  for (size_t i = 0; i < _gpParameterDimension; i++)
  {
    _koraliExperiment["Variables"][i]["Name"] = "X" + std::to_string(i);
    eParameters[i] = _defaultHyperparameter;
    _koraliExperiment["Variables"][i]["Initial Value"] = eParameters[i];
  }
  _gp->covf().set_loghyper(eParameters);

  _koraliExperiment["Solver"] = _optimizer;
  _koraliExperiment["Solver"]["Termination Criteria"]["Max Generations"] = 1;

  _koraliExperiment["File Output"]["Frequency"] = 0;
  _koraliExperiment["File Output"]["Enabled"] = false;
  _koraliExperiment["Console Output"]["Frequency"] = 0;
  _koraliExperiment["Console Output"]["Verbosity"] = "Silent";
  _koraliExperiment["Random Seed"] = _k->_randomSeed++;

  // Pass the training data from korali to the GP library
  double inData[_gpInputDimension];
  double outData;

  // Running initialization to verify that the configuration is correct
  _koraliExperiment.initialize();

  for (size_t i = 0; i < _problem->_trainingBatchSize; i++)
  {
    for (size_t j = 0; j < _gpInputDimension; j++)
      inData[j] = _problem->_inputData[i][0][j];

    outData = _problem->_solutionData[i][0];
    _gp->add_pattern(inData, outData);
  }

}

void @className::runSample(Sample &sample, libgp::GaussianProcess *gp)
{
  size_t gpParameterDimension = gp->covf().get_param_dim();
  const Eigen::VectorXd p = toEigen(sample["Parameters"].get<std::vector<float>>());

  gp->covf().set_loghyper(p);

  sample["F(x)"] = gp->log_likelihood();
  sample["logP(x)"] = sample["F(x)"];

  Eigen::VectorXd eigenGrad = gp->log_likelihood_gradient();
  for (size_t i = 0; i < gpParameterDimension; i++)
    sample["Gradient"][i] = eigenGrad[i];
}

void @className::runGeneration()
{
  _koraliExperiment["Solver"]["Termination Criteria"]["Max Generations"] = _koraliExperiment._currentGeneration + 1;
  korali::Engine engine;
  engine.run(_koraliExperiment);
  _gpHyperparameters = _koraliExperiment["Results"]["Best Sample"]["Parameters"].get<std::vector<float>>();
}

void @className::printGenerationAfter()
{
  return;
}

std::vector<std::vector<float>>& @className::getEvaluation(const std::vector<std::vector<std::vector<float>>> &input)
{
  _outputValues.resize(1);
  _outputValues[0].resize(2);

  if (input.size() > 1) KORALI_LOG_ERROR("Gaussian Process does not support multi-timestep evaluation.\n");
  if (input[0].size() > 1) KORALI_LOG_ERROR("Gaussian Process does not support minibatch evaluation.\n");

  _gp->covf().set_loghyper(toEigen(_gpHyperparameters));

  std::vector<double> inputData(input[0][0].begin(), input[0][0].end());

  _outputValues[0][0] = _gp->f(inputData.data());
  _outputValues[0][1] = _gp->var(inputData.data());

  return _outputValues;
}

std::vector<float> @className::getHyperparameters()
{
  return _gpHyperparameters;
}

void @className::setHyperparameters(const std::vector<float> &hyperparameters)
{
  _gpHyperparameters = hyperparameters;
}

@moduleAutoCode

@endNamespace
