@startIncludeGuard

#include "modules/solver/learner/deepSupervisor/optimizers/fAdaBelief.hpp"
#include "modules/solver/learner/deepSupervisor/optimizers/fAdagrad.hpp"
#include "modules/solver/learner/deepSupervisor/optimizers/fAdam.hpp"
#include "modules/solver/learner/deepSupervisor/optimizers/fGradientBasedOptimizer.hpp"
#include "modules/solver/learner/deepSupervisor/optimizers/fMadGrad.hpp"
#include "modules/solver/learner/deepSupervisor/optimizers/fRMSProp.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/neuralNetwork/neuralNetwork.hpp"
#include "modules/problem/supervisedLearning/supervisedLearning.hpp"
#include "modules/solver/learner/learner.hpp"

@startNamespace

class @className : public @parentClassName
{
  public:
  /**
 * @brief Korali Problem for optimizing NN weights and biases
 */
  problem::SupervisedLearning *_problem;

  /**
 * @brief Korali Experiment for optimizing the NN's weights and biases
 */
  korali::Experiment _optExperiment;

  /**
 * @brief Gradient-based solver pointer to access directly (for performance)
 */
  korali::fGradientBasedOptimizer *_optimizer;

  /**
   * @brief A neural network to be trained based on inputs and solutions
   */
  NeuralNetwork *_neuralNetwork;

  /**
    * @brief Calculates the gradients with respect to the inputs (data), given an input and output gradients
    * @param input The inputs from which to infer outputs. Format: BxTxIC (B: Batch Size, T: Time steps, IC: Input channels)
    * @param outputGradients The output gradients. Format: BxOC (B: Batch Size, OC: Input channels)
    * @return The inferred batch input gradients Format: BxIC (B: Batch Size, IC: Output channels)
   */
  std::vector<std::vector<float>> &getDataGradients(const std::vector<std::vector<std::vector<float>>> &input, const std::vector<std::vector<float>> &outputGradients);

  /**
   * @brief Resets the optimizer after passing new hyperparameters
   */
  void resetOptimizer();

  std::vector<std::vector<float>> &getEvaluation(const std::vector<std::vector<std::vector<float>>> &input) override;
  std::vector<float> getHyperparameters() override;
  void setHyperparameters(const std::vector<float> &hyperparameters) override;

  void initialize() override;
  void runGeneration() override;
  void printGenerationAfter() override;
};

@endNamespace

@endIncludeGuard
