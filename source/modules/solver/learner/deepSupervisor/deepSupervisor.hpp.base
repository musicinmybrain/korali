#pragma once

#include <random>
#include "modules/experiment/experiment.hpp"
#include "modules/neuralNetwork/neuralNetwork.hpp"
#include "modules/problem/supervisedLearning/supervisedLearning.hpp"
#include "modules/solver/learner/learner.hpp"
// Optimizer ===================================================================
#include "modules/solver/learner/deepSupervisor/optimizers/fGradientBasedOptimizers.hpp"
// Reward Functions ============================================================
#include "modules/solver/learner/deepSupervisor/reward_functions/reward.hpp"
#include "modules/solver/learner/deepSupervisor/reward_functions/mse.hpp"
#include "modules/solver/learner/deepSupervisor/reward_functions/cross_entropy.hpp"
#include "modules/solver/learner/deepSupervisor/reward_functions/negative_log_likelihood.hpp"
#include "modules/solver/learner/deepSupervisor/regularizers/regularizer.hpp"
// Regularizer =================================================================
#include "modules/solver/learner/deepSupervisor/regularizers/l2.hpp"
#include "modules/solver/learner/deepSupervisor/regularizers/l1.hpp"
// Learning Rates ==============================================================
#include "modules/solver/learner/deepSupervisor/learning_rate/learning_rate.hpp"
#include "modules/solver/learner/deepSupervisor/learning_rate/decay.hpp"
#include "modules/solver/learner/deepSupervisor/learning_rate/step_based_decay.hpp"
#include "modules/solver/learner/deepSupervisor/learning_rate/time_based_decay.hpp"
// Metrics =====================================================================
#include "modules/solver/learner/deepSupervisor/metrics/metrics.hpp"
#include "modules/solver/learner/deepSupervisor/metrics/accuracy.hpp"

__startNamespace__;

class __className__ : public __parentClassName__
{
  public:
    /**
     * @brief Korali Problem for optimizing NN weights and biases
     */
    korali::problem::SupervisedLearning *_problem;
    /**
     * @brief Korali Experiment for optimizing the NN's weights and biases
     */
    korali::Experiment _optExperiment;
    /**
     * @brief Gradient-based solver pointer to access directly (for performance)
     */
    /**
     * @brief reward function object [Korali maximizes].
     */
    korali::reward::Reward *_reward{};
    /**
     * @brief regularizer function object.
     */
    korali::regularizer::Regularizer *_regularizer{};
    /**
     * @brief learning rate function object.
     */
    korali::learning_rate::LearningRate *_learning_rate{};
    /**
     * @brief reward function object.
     */
    std::unordered_map<std::string, std::unique_ptr<korali::metrics::Metrics> > _metrics;
    /**
     * @brief A neural network to be trained based on inputs and solutions
     */
    korali::NeuralNetwork *_neuralNetwork;
    // INTERNAL USE VARIABLES ===================================================================
    /**
     * @brief [Internal Use] if validation set is given.
     */
    bool _hasValidationSet{false};
    /**
     * @brief [Internal Use] training loss of the current iterration.
     */
    float _currentTrainingLoss{0};
    /**
     * @brief [Internal Use] validation loss of the current iterration.
     */
    float _currentValidationLoss{0};
    /**
     * @brief [Internal Use] current metrics.
     */
    std::unordered_map<std::string, float> _currentMetrics;
    /**
     * @brief [Internal Use] current regularizer penalty
     */
    float _currentPenalty{0};
    // /**
    //  * @brief [Internal Use] training loss of the current all epochs.
    //  */
    // std::vector<float> _trainingLoss;
    // /**
    //  * @brief [Internal Use] validation loss of the current all epochs.
    //  */
    // std::vector<float> _validationLoss;
    // /**
    //  * @brief [Internal Use] testing loss of the current iterration.
    //  */
    // float _testingLoss{0};
    // /**
    //  * @brief [Internal Use] vector that stores the total learning rate if desired.
    //  */
    // std::vector<float> _totalLearningRate;
    // /**
    //  * @brief [Internal Use] vector that stores the metrics for all generations.
    //  */
    // std::vector<float> _totalMetrics;
    // /**
    //  * @brief [Internal Use] vector that stores the metrics for all generations.
    //  */
    // std::vector<float> _totalPenalty;
    /**
     * @brief [Internal Use] number of total training/testing samples.
     */
    size_t N{};
    /**
     * @brief [Internal Use] number of timesteps.
     */
    size_t T{};
    /**
     * @brief [Internal Use] number of input channels.
     */
    size_t IC{};
    /**
     * @brief [Internal Use] number training/testing set batch size.
     */
    size_t BS{};
    /**
     * @brief [Internal Use] total work size per worker.
     */
    size_t NW{};
    /**
     * @brief [Internal Use] mini-batch size per worker.
     */
    size_t BW{};
    /**
     * @brief [Internal Use] number of output channels.
     */
    size_t OC{};
    /**
     * @brief [Internal Use] number of validation samples.
     */
    size_t NV{};
    /**
     * @brief [Internal Use] random number engine for input data.
     */
    std::mt19937 input_reng;
    /**
     * @brief [Internal Use] random number engine for solution data.
     */
    std::mt19937 solution_reng;
    /**
    * @brief nn wrapper function.
    * @details
    * 1. Forwards input through neural network.
    * 2. Obtains output values of the nn.
    * @param input 3D vector of size [N, T, IC]
    * @return returns 2D output vector of size [N, OC]
    */
    std::vector<std::vector<float>> &getEvaluation(const std::vector<std::vector<std::vector<float>>> &input) override;
    std::vector<std::vector<float>> &getEvaluation(std::vector<std::vector<std::vector<float>>> &&input);
    std::vector<float> getHyperparameters() override;
    void setHyperparameters(const std::vector<float> &hyperparameters) override;

    void initialize() override;
    void runGeneration() override;
    /**
    * @brief runs an epoch
    * @details Runs samples/batch_size iterations of forward/backward pass
    */
    void runEpoch();
    /**
    * @brief runs an epoch
    * @details Runs samples/batch_size iterations of forward/backward pass
    */
    void runPrediction();
    /**
    * @brief splits up the training input - a minibatch further into superminibatches and runs a forward/backward pass.
    * @details
    * 1. Runs the forward pass of the neural network to get the output
    * 2. Calculates the derivative of the output loss function given its input value
    * 3. Runs the backward pass of the neural network
    * 4. Runs the given optimizer to optimize the hyperparameters of the neural network
    * 5. Updates the hyperparameters of the neural network
    */
    void runTrainingGeneration();
    /**
    * @brief splits up the test input - further into minibatches and runs just the forward pass.
    */
    void runTestingGeneration();
    /**
    * @brief backpropagates the jaccobian of the reward function
    * @param input 2D vector of size [BS, OC]
    */
    void updateWeights(std::vector<float> &negativeGradientWeights);
    /**
    * @brief run optimization setp and update the weights.
    */
    /**
    * @brief performs weight decay if a regularizer is given.
    */
    void performWeightDecay(std::vector<float> &negativeGradientWeights);
    /**
    * @brief run optimization setp and update the weights.
    */
    std::vector<float> backwardGradients(const std::vector<std::vector<float>> &dreward);
    /**
    * @brief flattens 2d solution vector
    * @param 2d vector
    * @return flattend vector.
    */
    std::vector<float> flatten(const std::vector<std::vector<float>> &vec) const;
    /**
    * @brief flattens 3d input vector
    * @param 3d vector
    * @return flattend vector.
    */
    std::vector<float> flatten(const std::vector<std::vector<std::vector<float>>> &vec) const;
    /**
    * @brief de-flattens 1d input vector into a 2d vector.
    * @param 2d vector
    * @return flattend vector.
    */
    std::vector<std::vector<float>> deflatten(const std::vector<float> &vec_flat, size_t BS, size_t OC) const;
    /**
    * @brief de-flattens 1d input vector into a 3d vector.
    * @param 3d vector
    * @return flattend vector.
    */
    std::vector<std::vector<std::vector<float>>> deflatten(const std::vector<float> &vec_flat, size_t BS, size_t T, size_t IC) const;
    /**
    * @brief Run one iteration of forward backward loop on a worker
    * @param sample A sample containing the NN's input BxTxIC (B: Batch Size, T: Time steps, IC: Input channels)
    */
    void runTrainingOnWorker(korali::Sample &sample);
    /**
    * @brief Run one iteration of forward backward pass.
    * @param sample A sample containing the NN's input BxTxIC (B: Batch Size, T: Time steps, IC: Input channels)
    */
    void runForwardData(korali::Sample &sample);
    /**
    * @brief function to check whether to run more generations.
    */
    void finalize() override;
    /**
    *
    * @brief function that can be used to print after a generation.
    */
    void printGenerationBefore() override;
    /**
    * @brief function that can be used to print after a generation.
    */
    void printGenerationAfter() override;
    /**
    * @brief function that can be used to print after a run.
    */
    void printRunAfter() override;
};

__endNamespace__;
