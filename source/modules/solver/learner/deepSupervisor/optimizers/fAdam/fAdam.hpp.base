#pragma once

#include <string>
#include <vector>
#include "modules/solver/learner/deepSupervisor/optimizers/fGradientBasedOptimizers.hpp"

__startNamespace__;

class __className__ : public __parentClassName__
{
  public:
  // VARIABLES =================================================
  /**
  * @brief Beta for momentum update
  */
  float _beta1{0.9f};
  /**
  * @brief Beta for gradient update
  */
  float _beta2{0.999f};
  // FUNCTIONS =================================================
  // OVERRIDEN FUNCTIONS =======================================
  virtual void initialize() override;
  virtual void processResult(std::vector<float> &gradient) override;
  virtual void reset() override;
};

__endNamespace__;
