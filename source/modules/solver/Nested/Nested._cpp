#include "modules/solver/Nested/Nested.hpp"
#include "modules/engine/engine.hpp"
#include "modules/conduit/conduit.hpp"
#include "modules/experiment/experiment.hpp"

#include <algorithm> //sort
#include <numeric>
#include <limits>
#include <chrono>

void korali::solver::Nested::setInitialConfiguration()
{
 if(_covarianceScaling <= 0.0) korali::logError("Covariance Scaling must be larger 0.0 (is %lf).\n", _covarianceScaling);
 if(_maxGainFactor < 0.0) korali::logError("Max Gain Factor must be larger equal 0.0 (is %lf).\n", _maxGainFactor);
 
 if(_resamplingMethod.compare("Mutation") == false) korali::logError("Only accepted Resampling Method is 'Mutation'");


 _logDomainSize = 0.0;
 for(size_t d = 0; d < _k->_variables.size(); ++d)
 {
    if (_k->_distributions[_k->_variables[d]->_distributionIndex]->_name != "Uniform") korali::logError("Only Uniform priors allowed.");
    double tmp = _k->_distributions[_k->_variables[d]->_distributionIndex]->getRandomNumber();
    _logDomainSize -= _k->_distributions[_k->_variables[d]->_distributionIndex]->getLogDensity(tmp);
 }
 
 _candidateLogLikelihoods.resize(_batchSize);
 _candidateLogPriors.resize(_batchSize);
 _candidateEvaluations.resize(_batchSize);
 _candidates.resize(_batchSize);
 for(size_t i = 0; i < _batchSize; i++) _candidates[i].resize(_k->_variables.size());
 
 _liveLogLikelihoods.resize(_populationSize);
 _liveLogPriors.resize(_populationSize);
 _liveEvaluations.resize(_populationSize);
 _liveSamplesRank.resize(_populationSize);
 _liveSamples.resize(_populationSize);
 for(size_t i = 0; i < _populationSize; i++) _liveSamples.resize(_k->_variables.size());
  
 _sampleLogLikelihoodDatabase.resize(0);
 _sampleLogPriorDatabase.resize(0);
 _sampleLogWidthDatabase.resize(0);
 _sampleDatabase.resize(0);
 
 _covarianceMatrix.resize(_k->_variables.size()*_k->_variables.size());
 _domainMean.resize(_k->_variables.size());

 // Init Generation
 _logWidth               = 0.0;
 _information            = 0.0;
 _acceptedSamples        = 0;
 _generatedSamples       = 0;
 _worstSample            = 0;
 _evaluationConstraint   = std::numeric_limits<double>::infinity();
 _maxEvaluation          = -std::numeric_limits<double>::infinity();
 _accumulatedLogEvidence = -std::numeric_limits<double>::infinity();

 (*_k)["Results"]["Sample Database"]  = {};
}

void korali::solver::Nested::runGeneration()
{
  if (_k->_currentGeneration == 1) 
  { 
    setInitialConfiguration(); 
    runFirstGeneration(); 
    return; 
  };

  // Generation > 1
  prepareGeneration();

  std::vector<korali::Sample> samples(_batchSize);

  for (size_t c = 0; c < _batchSize; c++)
  {
   samples[c]["Operation"]    = "Evaluate";
   samples[c]["Parameters"]   = _candidates[c];
   samples[c]["Sample Id"]    = c;
   _engine->_conduit->start(samples[c]);
   _modelEvaluationCount++;
   _generatedSamples++;
  }


  size_t finishedCandidatesCount = 0;
  while (finishedCandidatesCount < _batchSize)
  {
   size_t finishedId = _engine->_conduit->waitAny(samples);

   _candidateLogLikelihoods[finishedId] = samples[finishedId]["logLikelihood"];
   _candidateLogPriors[finishedId]      = samples[finishedId]["logPrior"];
   _candidateEvaluations[finishedId]    = _candidateLogPriors[finishedId] + _candidateLogLikelihoods[finishedId];
   finishedCandidatesCount++;

  }

  processGeneration();

  (*_k)["Results"]["Sample Database"] = _sampleDatabase;

  return;
}


void korali::solver::Nested::runFirstGeneration()
{
  for(size_t i = 0; i < _populationSize; i++)
     for (size_t d = 0; d < _k->_variables.size(); d++) 
       _liveSamples[i][d] = _k->_distributions[_k->_variables[d]->_distributionIndex]->getRandomNumber();
 
  std::vector<korali::Sample> samples(_populationSize);

  for (size_t c = 0; c < _populationSize; c++)
  {
    samples[c]["Operation"]    = "Evaluate";
    samples[c]["Parameters"]   = _liveSamples[c];
    samples[c]["Sample Id"]    = c;
    _engine->_conduit->start(samples[c]);
    _modelEvaluationCount++;
  }

  size_t finishedCandidatesCount = 0;
  while (finishedCandidatesCount < _populationSize)
  {
   size_t finishedId = _engine->_conduit->waitAny(samples);

   _liveLogLikelihoods[finishedId] = samples[finishedId]["logLikelihood"];
   _liveLogPriors[finishedId]      = samples[finishedId]["logPrior"];
   _liveEvaluations[finishedId]    = _liveLogPriors[finishedId] + _liveLogLikelihoods[finishedId];
   
   finishedCandidatesCount++;
  }

  sortLiveSamplesDescending();
  _maxEvaluation        = _liveEvaluations[_liveSamplesRank[0]];
  _evaluationConstraint = _liveEvaluations[_liveSamplesRank[_populationSize-1]];
  return;
}


void korali::solver::Nested::prepareGeneration()
{

  if      (_resamplingMethod.compare("Mutation")) generateCandidatesFromMutation();
  else if (_resamplingMethod.compare("Box"))      generateCandidatesFromBox();
  else /* _resamplingMethod.compare("Ellipse") */ generateCandidatesFromEllipse();
  return;
}


void korali::solver::Nested::processGeneration()
{
  size_t sampleIdx;

  for (size_t c = 0; c < _batchSize ; ++c)
  {
    if(_candidateEvaluations[c] < _evaluationConstraint) continue;
    
    sampleIdx = _liveSamplesRank[_populationSize-1];
    updateSampleDatabase(sampleIdx);

    _liveEvaluations[sampleIdx]    = _candidateEvaluations[c];
    _liveLogPriors[sampleIdx]      = _candidateLogPriors[c];
    _liveLogLikelihoods[sampleIdx] = _candidateLogLikelihoods[c];

    sortLiveSamplesDescending();
    _evaluationConstraint = _liveEvaluations[_populationSize-1];

  }
    
  for (size_t d = 0; d < _k->_variables.size(); d++) _domainMean[d] = 0.0;
  
  for (size_t i = 0; i < _populationSize; i++) 
    for (size_t d = 0; d < _k->_variables.size(); d++)
      _domainMean[i] += _liveSamples[i][d];

  for (size_t i = 0; i < _k->_variables.size(); i++){
    for (size_t j = i; j < _k->_variables.size(); ++j){
      double s = 0.0;
      for (size_t k = 0; k < _populationSize; ++k) s += (_liveSamples[k][i] - _domainMean[i])*( _liveSamples[k][j]-_domainMean[j] );
      _covarianceMatrix[i*_k->_variables.size() + j] = _covarianceMatrix[j*_k->_variables.size() + i] = _covarianceScaling * s;
    }
  }

  return;
}

void korali::solver::Nested::generateCandidatesFromMutation() 
{ 
  std::vector<double> zeroMean(_k->_variables.size(), 0.0);
  _multivariateGenerator->_meanVector       = zeroMean;
  _multivariateGenerator->_covarianceMatrix = _covarianceMatrix;
  _multivariateGenerator->updateDistribution();

  for(size_t i = 0; i < _batchSize; i++)
  {
   size_t cpyIdx = (size_t) (_uniformGenerator->getRandomNumber()*_populationSize);
   for(size_t d = 0; d < _k->_variables.size(); d++) _candidates[i][d] +=  _liveSamples[cpyIdx][d];
  }
}

void korali::solver::Nested::generateCandidatesFromBox() { return; }
 
void korali::solver::Nested::generateCandidatesFromEllipse() { return; }

void korali::solver::Nested::sortLiveSamplesDescending() 
{
    //TODO: speed up
    std::iota (std::begin(_liveSamplesRank), std::end(_liveSamplesRank), 0);
    sort(_liveSamplesRank.begin(), _liveSamplesRank.end(), [this](const size_t & idx1, const size_t & idx2) -> bool { return this->_liveEvaluations[idx1] > this->_liveEvaluations[idx2]; });
}

void korali::solver::Nested::updateSampleDatabase(size_t sampleIdx) 
{
  _sampleDatabase.push_back(_liveSamples[sampleIdx]);
  _sampleLogPriorDatabase.push_back(_liveLogPriors[sampleIdx]);
  _sampleLogLikelihoodDatabase.push_back(_liveLogLikelihoods[sampleIdx]);
  
  if(_sampleLogWidthDatabase.size() > 1) _sampleLogWidthDatabase.push_back(_sampleLogWidthDatabase.back() + log(_populationSize/(_populationSize+1.0)));
  else                                   _sampleLogWidthDatabase.push_back(_logDomainSize - log(_populationSize+1.0)); // init
}

void korali::solver::Nested::printGenerationBefore() { return; }

void korali::solver::Nested::printGenerationAfter() { return; }

void korali::solver::Nested::finalize() { return; }
