#include "modules/conduit/conduit.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/problem/problem.hpp"
#include "modules/solver/sampler/HMC/HMC.hpp"

#include <chrono>
#include <limits>
#include <numeric>

#include <gsl/gsl_linalg.h>
#include <gsl/gsl_matrix.h>
#include <gsl/gsl_multimin.h>
#include <gsl/gsl_sort_vector.h>
#include <gsl/gsl_statistics.h>

namespace korali
{
namespace solver
{
namespace sampler
{
void HMC::setInitialConfiguration()
{
  // TODO: Check exact intervals (i.e. inclusion and exclusion)
  if (!(_burnIn >= 0)) KORALI_LOG_ERROR("Burn In must be larger equal 0 (is %zu).\n", _burnIn);
  if (!(_metricEstimateQuotient > 0.0 && _metricEstimateQuotient <= 1.0)) KORALI_LOG_ERROR("Metric Estimate Quotient must be in interval (0.0, 1.0] (is %lf).\n", _metricEstimateQuotient);
  if (!(_maxDepth >= 0)) KORALI_LOG_ERROR("Max Depth must be non-negative. (is %zu).\n", _maxDepth);

  // Check Adaptive Step Size settings
  if (!(_desiredAverageAcceptanceRate > 0.0 && _desiredAverageAcceptanceRate <= 1.0)) KORALI_LOG_ERROR("Desired Average Acceptance Rate must be in interval (0.0, 1.0] (is %lf).\n", _desiredAverageAcceptanceRate);
  if (!(_targetIntegrationTime >= 0.0)) KORALI_LOG_ERROR("Target Integration Time must be non-negative (is %lf).\n", _targetIntegrationTime);
  if (!(_numIntegrationSteps > 0)) KORALI_LOG_ERROR("Num Integration Steps must be larger equal 1 (is %zu).\n", _numIntegrationSteps);
  if (!(_adaptiveStepSizeSpeedConstant > 0.0)) KORALI_LOG_ERROR("Adaptive Step Size Speed Constant must be positive (is %lf).\n", _adaptiveStepSizeSpeedConstant);
  if (!(_adaptiveStepSizeStabilizationConstant >= 0.0)) KORALI_LOG_ERROR("Adaptive Step Size Stabilization Constant must be non-negative (is %lf).\n", _adaptiveStepSizeStabilizationConstant);
  if (!(_adaptiveStepSizeScheduleConstant > 0.5 && _adaptiveStepSizeScheduleConstant <= 1.0)) KORALI_LOG_ERROR("Adaptive Step Size Schedule Constant must be in the interval (0.5, 1.0] (is %lf).\n", _adaptiveStepSizeScheduleConstant);

  _stateSpaceDim = _k->_variables.size();

  // Resizing vectors of internal settings to correct dimensions
  _positionLeader.resize(_stateSpaceDim);
  _positionCandidate.resize(_stateSpaceDim);
  _momentumLeader.resize(_stateSpaceDim);
  _momentumCandidate.resize(_stateSpaceDim);
  _positionMean.resize(_stateSpaceDim);

  switch (_useDiagonalMetric == false && _useEuclideanMetric == true)
  {
  case false:
    _hamiltonian = new HamiltonianDiag{_stateSpaceDim};

    _metric.resize(_stateSpaceDim);
    _inverseMetric.resize(_stateSpaceDim);

    // Setting position to inital mean
    for (size_t i = 0; i < _stateSpaceDim; ++i)
    {
      _positionLeader[i] = _k->_variables[i]->_initialMean;
      _metric[i] = _k->_variables[i]->_initialStandardDeviation * _k->_variables[i]->_initialStandardDeviation;
      _inverseMetric[i] = 1.0 / _metric[i];
    }

    break;

  case true:
    _hamiltonian = new HamiltonianDense{_stateSpaceDim};
    _metric.resize(_stateSpaceDim * _stateSpaceDim);
    _inverseMetric.resize(_stateSpaceDim * _stateSpaceDim);

    // Filling vectors of internal settings to 0.0
    std::fill(std::begin(_metric), std::end(_metric), 0.0);
    std::fill(std::begin(_inverseMetric), std::end(_inverseMetric), 0.0);

    // Setting position to inital mean
    for (size_t i = 0; i < _stateSpaceDim; ++i)
    {
      _positionLeader[i] = _k->_variables[i]->_initialMean;
      _metric[i * _stateSpaceDim + i] = _k->_variables[i]->_initialStandardDeviation * _k->_variables[i]->_initialStandardDeviation;
      _inverseMetric[i * _stateSpaceDim + i] = 1.0 / _metric[i * _stateSpaceDim + i];
    }

    // Initialize multivariate normal distribution
    std::vector<double> zeroMean(_stateSpaceDim, 0.0);
    _multivariateGenerator->_meanVector = zeroMean;
    _multivariateGenerator->_sigma = _metric;

    // Cholesky Decomposition
    gsl_matrix_view sigma = gsl_matrix_view_array(&_multivariateGenerator->_sigma[0], _stateSpaceDim, _stateSpaceDim);
    gsl_linalg_cholesky_decomp(&sigma.matrix);

    _multivariateGenerator->updateDistribution();

    break;
    // default:
    //   KORALI_LOG_ERROR("Use Diagonal Metric must be set to True or False.\n");
  }

  _integrator = new LeapfrogExplicit;

  if (_useAdaptiveStepSize == true)
  {
    _stepSize = findReasonableStepSize(_positionLeader);
    _mu = std::log(10.0 * _stepSize);
    _hBar = 0.0;
  }

  // Initialize Generation
  _acceptanceCount = 0;
  _proposedSampleCount = 0;
  _chainLength = 0;
  _acceptanceRate = 1.0;

  return;
}

void HMC::runGeneration()
{
  if (_k->_currentGeneration == 1) setInitialConfiguration();

  // Samples Momentum Candidate from N(0.0, metric)

  _momentumCandidate = generateCandidate();

  _positionCandidate = _positionLeader;
  _momentumLeader = _momentumCandidate;

  const double logUniSample = std::log(_uniformGenerator->getRandomNumber());

  switch (_useNUTS)
  {
  case false:
    runGenerationHMC(logUniSample);
    break;
  case true:
    runGenerationNUTS(logUniSample);
    break;

  default:
    KORALI_LOG_ERROR("Use NUTS must be set to True or False.\n");
  }

  saveSample();

  updateState();

  ++_chainLength;

  return;
}

void HMC::runGenerationHMC(const double logUniSample)
{
  const double oldK = _hamiltonian->K(_positionLeader, _momentumLeader, _inverseMetric);
  const double oldU = _hamiltonian->U(_positionLeader, _modelEvaluationCount, _sampleDatabase.size());

  if (_useAdaptiveStepSize == true && _chainLength <= _burnIn)
  {
    _numIntegrationSteps = std::max((size_t)1, (size_t)std::round(_targetIntegrationTime / _stepSize));
  }

  // Perform Num Integration Steps of Leapfrog scheme to Momentum Candidate and Position Candidate
  for (size_t i = 0; i < _numIntegrationSteps; ++i)
  {
    _integrator->step(_positionCandidate, _momentumCandidate, _stepSize, _hamiltonian, _modelEvaluationCount, _sampleDatabase.size(), _inverseMetric);
  }

  // Negate proposed momentum to make proposal symmetric
  std::transform(std::cbegin(_momentumCandidate), std::cend(_momentumCandidate), std::begin(_momentumCandidate), std::negate<double>());

  // Save new Energies
  const double newK = _hamiltonian->K(_positionCandidate, _momentumCandidate, _inverseMetric);
  const double newU = _hamiltonian->U(_positionCandidate, _modelEvaluationCount, _sampleDatabase.size());

  const double logAlpha = std::min(0.0, -(newK - oldK + newU - oldU));
  _acceptanceProbability = std::exp(logAlpha);

  if (logUniSample <= logAlpha)
  {
    ++_acceptanceCount;
    _positionLeader = _positionCandidate;
  }

  return;
}

void HMC::runGenerationNUTS(const double logUniSample)
{
  const double oldK = _hamiltonian->K(_positionLeader, _momentumLeader, _inverseMetric);
  const double oldU = _hamiltonian->U(_positionLeader, _modelEvaluationCount, _sampleDatabase.size());

  std::vector<double> nullPointOne(_stateSpaceDim);
  std::vector<double> nullPointTwo(_stateSpaceDim);
  std::vector<double> tmpVector(_stateSpaceDim, 0.0);

  // std::vector<double> rhoInit = _momentumLeader;
  std::vector<double> rhoPlus(_stateSpaceDim, 0.0);
  std::vector<double> rhoMinus(_stateSpaceDim, 0.0);

  std::vector<double> qLeft = _positionLeader;
  std::vector<double> qRight = _positionLeader;
  std::vector<double> pLeft = _momentumLeader;
  std::vector<double> pRight = _momentumLeader;

  int depth = 0;
  int numLeavesSubtree;
  bool buildCriterion = true;
  bool buildCriterionSubtree;
  double numValidLeaves = 1.0;
  double numValidLeavesSubtree;
  double dotProductLeft, dotProductRight;
  const double oldH = oldU + oldK;

  while (buildCriterion == true && depth <= _maxDepth)
  {
    // std::vector<double> rho(_stateSpaceDim, 0.0);
    if (_uniformGenerator->getRandomNumber() < 0.5)
    {
      buildTree(qLeft, pLeft, logUniSample, -1, depth, _stepSize, oldH, qLeft, pLeft, nullPointOne, nullPointTwo, _positionCandidate, numValidLeavesSubtree, buildCriterionSubtree, _acceptanceProbability, numLeavesSubtree);
    }
    else
    {
      buildTree(qRight, pRight, logUniSample, 1, depth, _stepSize, oldH, nullPointOne, nullPointTwo, qRight, pRight, _positionCandidate, numValidLeavesSubtree, buildCriterionSubtree, _acceptanceProbability, numLeavesSubtree);
    }

    if (buildCriterionSubtree == true)
    {
      if (numValidLeaves == 0)
      {
        KORALI_LOG_ERROR("Division by zero encountered in NUTS (numValidLeaves is %lf).\n", numValidLeaves);
      }
      if (_uniformGenerator->getRandomNumber() < numValidLeavesSubtree / numValidLeaves)
      {
        _positionLeader = _positionCandidate;
      }
    }

    numValidLeaves += numValidLeavesSubtree;

    std::transform(std::cbegin(qRight), std::cend(qRight), std::cbegin(qLeft), std::begin(tmpVector), std::minus<double>());
    dotProductLeft = std::inner_product(std::cbegin(tmpVector), std::cend(tmpVector), std::cbegin(pLeft), 0.0);
    dotProductRight = std::inner_product(std::cbegin(tmpVector), std::cend(tmpVector), std::cbegin(pRight), 0.0);

    buildCriterion = buildCriterionSubtree && (dotProductLeft > 0) && (dotProductRight > 0);

    // std::cout << "depth = " << depth << std::endl;
    // std::cout << "Normal difference: " << std::endl;
    // std::cout << "dotProductLeft = " << dotProductLeft << std::endl;
    // std::cout << "dotProductRight = " << dotProductRight << std::endl;

    // std::vector<double> deltaRho(_stateSpaceDim, 0.0);

    // std::transform(std::cbegin(rhoMinus), std::cend(rhoMinus), std::cbegin(deltaRho), std::begin(deltaRho), std::plus<double>());
    // std::transform(cbegin(rhoInit), std::cend(rhoInit), std::cbegin(deltaRho), std::begin(deltaRho), std::plus<double>());
    // std::transform(std::cbegin(rhoPlus), std::cend(rhoPlus), std::cbegin(deltaRho), std::begin(deltaRho), std::plus<double>());

    // for (size_t i = 0; i < _stateSpaceDim; ++i)
    // {
    //   deltaRho[i] = _stepSize * rhoInit[i] + rhoMinus[i] + rhoPlus[i];
    //   deltaRho[i] = rhoMinus[i] + rhoPlus[i];
    // }

    // buildCriterion = buildCriterionSubtree && computeNoUTurnCriterion(pLeft, pRight, deltaRho);

    ++depth;
  }

  _acceptanceProbability /= (double)numLeavesSubtree;
  _acceptanceCountNUTS += _acceptanceProbability;

  return;
}

void HMC::saveSample()
{
  if (_chainLength >= _burnIn)
  {
    _sampleDatabase.push_back(_positionLeader);
  }
  else if (_useEuclideanMetric == true)
  {
    _warmupSampleDatabase.push_back(_positionLeader);
  }

  return;
}

void HMC::updateStepSize()
{
  if (_chainLength + 1 < _burnIn)
  {
    _hBar = (1.0 - 1.0 / (_chainLength + 1 + _adaptiveStepSizeStabilizationConstant)) * _hBar + (_desiredAverageAcceptanceRate - _acceptanceProbability) / (_chainLength + 1 + _adaptiveStepSizeStabilizationConstant);
    _stepSize = std::exp((_mu - std::sqrt(_chainLength + 1) / _adaptiveStepSizeSpeedConstant * _hBar));
    _dualStepSize = std::pow((_stepSize / _dualStepSize), std::pow(_chainLength + 1, -_adaptiveStepSizeScheduleConstant)) * _dualStepSize;
  }
  else if (_chainLength + 1 == _burnIn)
  {
    _stepSize = _dualStepSize;
  }

  return;
}

std::vector<double> HMC::generateCandidate()
{
  ++_proposedSampleCount;
  // saple momentum p from p ~ N(0.0, metric)
  std::vector<double> result(_stateSpaceDim, 0.0);

  switch (_useDiagonalMetric == false && _useEuclideanMetric == true)
  {
  case true:
    _multivariateGenerator->getRandomVector(&result[0], _stateSpaceDim);
    break;
  case false:
    for (size_t i = 0; i < _stateSpaceDim; ++i)
    {
      result[i] = std::sqrt(_metric[i]) * _normalGenerator->getRandomNumber();
    }
    break;
  }

  return result;
}

void HMC::updateState()
{
  _acceptanceRate = _useNUTS == true ? (double)_acceptanceCountNUTS / ((double)_chainLength + 1) : (double)_acceptanceCount / ((double)(_chainLength + 1));

  _chainLength < _burnIn ? updateStateWarmup() : updateStateSampling();

  return;
}

void HMC::updateStateWarmup()
{
  // Update Step Size, Dual Step Size, H Bar for Adaptive Step Size option
  if (_useAdaptiveStepSize == true && _chainLength <= _burnIn)
  {
    updateStepSize();
  }

  // return if no samples available
  if (_warmupSampleDatabase.size() == 0)
  {
    return;
  }

  // for one sample simply set average to current value (to avoid dividing by zero)
  if (_warmupSampleDatabase.size() == 1)
  {
    for (size_t d = 0; d < _stateSpaceDim; ++d)
    {
      _positionMean[d] = _positionLeader[d];
    }

    return;
  }

  // calculate chain mean for > 1 sample
  if (_warmupSampleDatabase.size() > 1)
  {
    for (size_t d = 0; d < _stateSpaceDim; ++d)
    {
      _positionMean[d] = (_positionMean[d] * (_warmupSampleDatabase.size() - 1) + _positionLeader[d]) / _warmupSampleDatabase.size();
    }
  }

  // case: Use Adaptive Sampling = True
  //       Approximate Inverse Matrix via Fisher Information
  if (_useEuclideanMetric == true && (int)(_metricEstimateQuotient * (double)_burnIn) == _chainLength + 1)
  {
    // double tmpScalar;
    // size_t numWarmupSamples = _warmupSampleDatabase.size();

    // // calculate covariance matrix of warmup sample via Fisher Infromation
    // for (size_t i = 0; i < _stateSpaceDim; ++i)
    // {
    //   for (size_t k = i; k < _stateSpaceDim; ++k)
    //   {
    //     tmpScalar = 0;
    //     for (size_t j = 0; j < numWarmupSamples; ++j)
    //     {
    //       tmpScalar += (_warmupSampleDatabase[j][i] - _positionMean[i]) * (_warmupSampleDatabase[j][k] - _positionMean[k]);
    //     }
    //     _inverseMetric[i * _stateSpaceDim + k] = tmpScalar / (numWarmupSamples - 1);
    //     _inverseMetric[k * _stateSpaceDim + i] = _inverseMetric[i * _stateSpaceDim + k];
    //   }
    // }

    // // update Metric to be consisitent with Inverse Metric
    // // invertMatrix(_inverseMetric, _metric);

    int err = _hamiltonian->updateInverseMetric(_warmupSampleDatabase, _positionMean, _inverseMetric, _metric);

    if (err == GSL_EDOM)
    {
      // error handling for non s.p.d. matrices
      _k->_logger->logWarning("Normal", "Inverse Metric negative definite (not updating Metric). Try Increasing Burn In.\n");
    }

    if (_useDiagonalMetric == false && _useEuclideanMetric == true)
    {
      _multivariateGenerator->_sigma = _metric;
      // Cholesky Decomp
      gsl_matrix_view sigma = gsl_matrix_view_array(&_multivariateGenerator->_sigma[0], _stateSpaceDim, _stateSpaceDim);

      err = gsl_linalg_cholesky_decomp(&sigma.matrix);
      if (err == GSL_EDOM)
      {
        _k->_logger->logWarning("Normal", "Metric negative definite (not updating Metric used for sampling momentum).\n");
      }
      else
      {
        _multivariateGenerator->updateDistribution();
      }
    }
  }

  return;
}

void HMC::updateStateSampling()
{
  // return if no samples available
  if (_sampleDatabase.size() == 0)
  {
    return;
  }

  // for one sample simply set average to current value (to avoid dividing by zero)
  if (_sampleDatabase.size() == 1)
  {
    for (size_t d = 0; d < _stateSpaceDim; ++d)
    {
      _positionMean[d] = _positionLeader[d];
    }

    return;
  }

  // calculate chain mean for > 1 sample
  if (_sampleDatabase.size() > 1)
  {
    for (size_t d = 0; d < _stateSpaceDim; ++d)
    {
      _positionMean[d] = (_positionMean[d] * (_sampleDatabase.size() - 1) + _positionLeader[d]) / _sampleDatabase.size();
    }
  }

  return;
}

void HMC::printGenerationBefore()
{
  return;
}

void HMC::printGenerationAfter()
{
  // Number of Samples
  _k->_logger->logInfo("Minimal", "Database Entries %ld\n", _sampleDatabase.size());

  _useNUTS == true ? _k->_logger->logInfo("Detailed", "Accepted Samples Indicator (NUTS): %lf\n", _acceptanceCountNUTS) : _k->_logger->logInfo("Normal", "Accepted Samples: %zu\n", _acceptanceCount);

  _k->_logger->logInfo("Normal", "Acceptance Rate Proposals: %.2f%%\n", 100 * _acceptanceRate);

  // Current Sample
  _k->_logger->logInfo("Detailed", "Current Sample:\n");
  for (size_t d = 0; d < _k->_variables.size(); ++d) _k->_logger->logData("Detailed", "         %s = %+6.3e\n", _k->_variables[d]->_name.c_str(), _positionLeader[d]);

  // TODO: Give better name
  // Current Sample/Position Mean
  _k->_logger->logInfo("Detailed", "Current Position Mean:\n");
  for (size_t d = 0; d < _k->_variables.size(); ++d) _k->_logger->logData("Detailed", "         %s = %+6.3e\n", _k->_variables[d]->_name.c_str(), _positionMean[d]);
  _k->_logger->logInfo("Detailed", "Current Metric:\n");

  switch (_useDiagonalMetric)
  {
  case false:
    for (size_t e = 0; e < _k->_variables.size(); ++e)
    {
      for (size_t d = 0; d < _k->_variables.size(); ++d)
      {
        _k->_logger->logData("Detailed", "         %+6.3e  ", _metric[d * _k->_variables.size() + e]);
      }
      _k->_logger->logInfo("Detailed", "\n");
    }
    break;

  case true:
    for (size_t e = 0; e < _k->_variables.size(); ++e)
    {
      _k->_logger->logData("Detailed", "         %+6.3e  ", _metric[e]);
      _k->_logger->logInfo("Detailed", "\n");
    }
    break;
  }

  // Inverse Metric
  _k->_logger->logInfo("Detailed", "Current Inverse Metric:\n");

  switch (_useDiagonalMetric)
  {
  case false:
    for (size_t e = 0; e < _k->_variables.size(); ++e)
    {
      for (size_t d = 0; d < _k->_variables.size(); ++d)
      {
        _k->_logger->logData("Detailed", "         %+6.3e  ", _inverseMetric[d * _k->_variables.size() + e]);
      }
      _k->_logger->logInfo("Detailed", "\n");
    }
    break;

  case true:
    for (size_t e = 0; e < _k->_variables.size(); ++e)
    {
      _k->_logger->logData("Detailed", "         %+6.3e  ", _inverseMetric[e]);
      _k->_logger->logInfo("Detailed", "\n");
    }
    break;
  }

  // Chain Length + 1 = m in Algorithm
  _k->_logger->logInfo("Detailed", "Chain Length: %ld\n", _chainLength);

  if (_useAdaptiveStepSize == true)
  {
    // Step Size
    _k->_logger->logInfo("Detailed", "Step Size: %lf\n", _stepSize);
    // Dual Step Size
    _k->_logger->logInfo("Detailed", "Dual Step Size: %lf\n", _dualStepSize);

    if (_useNUTS == false)
    {
      // Num Integration Steps
      _k->_logger->logInfo("Detailed", "Num Integration Steps: %ld\n", _numIntegrationSteps);
    }

    // Dual Step Size
    _k->_logger->logInfo("Detailed", "H Bar: %lf\n", _hBar);
  }

  return;
}

void HMC::finalize()
{
  _k->_logger->logInfo("Minimal", "Number of Generated Samples: %zu\n", _proposedSampleCount);
  _k->_logger->logInfo("Minimal", "Acceptance Rate: %.2f%%\n", 100 * _acceptanceRate);
  if (_sampleDatabase.size() == _maxSamples) _k->_logger->logInfo("Minimal", "Max Samples Reached.\n");
  (*_k)["Results"]["Sample Database"] = _sampleDatabase;

  delete _hamiltonian;
  delete _integrator;

  return;
}

double HMC::dotProduct(const std::vector<double> &pLeft, const std::vector<double> &pRight) const
{
  double tmpScalar = 0.0;

  for (size_t i = 0; i < _stateSpaceDim; ++i)
  {
    for (size_t j = 0; j < _stateSpaceDim; ++j)
    {
      tmpScalar += pLeft[i] * _inverseMetric[i * _stateSpaceDim + j] * pRight[j];
    }
  }

  return tmpScalar;
}

// // inverts mat via cholesky decomposition and writes inverted Matrix to inverseMat
// // TODO: Avoid calculating cholesky decompisition twice
// void HMC::invertMatrix(std::vector<double> &mat, std::vector<double> &inverseMat)
// {
//   gsl_matrix *A = gsl_matrix_alloc(_stateSpaceDim, _stateSpaceDim);

//   // copy mat to gsl matrix
//   for (size_t d = 0; d < _stateSpaceDim; ++d)
//   {
//     for (size_t e = 0; e < d; ++e)
//     {
//       gsl_matrix_set(A, d, e, mat[d * _stateSpaceDim + e]);
//       gsl_matrix_set(A, e, d, mat[e * _stateSpaceDim + d]);
//     }
//     gsl_matrix_set(A, d, d, mat[d * _stateSpaceDim + d]);
//   }

//   // calculate cholesky decomposition
//   int err = gsl_linalg_cholesky_decomp(A);
//   if (err == GSL_EDOM)
//   {
//     // error handling for non s.p.d. matrices
//     _k->_logger->logWarning("Normal", "Inverse Metric negative definite (not updating Metric). Try Increasing Burn In.\n");
//   }
//   else
//   {
//     // Invert matrix
//     gsl_linalg_cholesky_invert(A);

//     // copy gsl matrix to inverseMat
//     // TODO: Find out if there is a better way to do this
//     for (size_t d = 0; d < _stateSpaceDim; ++d)
//     {
//       for (size_t e = 0; e < d; ++e)
//       {
//         inverseMat[d * _stateSpaceDim + e] = gsl_matrix_get(A, d, e);
//         inverseMat[e * _stateSpaceDim + d] = gsl_matrix_get(A, d, e);
//       }
//       inverseMat[d * _stateSpaceDim + d] = gsl_matrix_get(A, d, d);
//     }
//   }

//   // free up memory of gsl matrix
//   gsl_matrix_free(A);

//   return;
// }

double HMC::findReasonableStepSize(std::vector<double> q)
{
  double stepSize = 1.0;
  double oldLogP, newLogP;

  std::vector<double> p(_stateSpaceDim, 0.0);

  // TODO: decide on sampling with metric as covariance metric or identity

  // Sampling from Normal distribution with metric as covariance matrix
  // WARNING: MY INTERPRETATION
  // _multivariateGenerator->getRandomVector(&p[0], _stateSpaceDim);

  p = generateCandidate();

  // Sampling from Standard Normal Distributoin (Identity as covariance matrix)
  // for (size_t i = 0; i < _stateSpaceDim; ++i)
  // {
  //   p[i] = _normalGenerator->getRandomNumber();
  // }

  oldLogP = -_hamiltonian->H(q, p, _modelEvaluationCount, _sampleDatabase.size(), _inverseMetric);

  _integrator->step(q, p, stepSize, _hamiltonian, _modelEvaluationCount, _sampleDatabase.size(), _inverseMetric);
  newLogP = -_hamiltonian->H(q, p, _modelEvaluationCount, _sampleDatabase.size(), _inverseMetric);

  int a = (newLogP - oldLogP > std::log(0.5)) ? 1 : -1;

  // TODO: Ask why Tobias updates oldLogP as this is not what Algorithm 5 says
  while (std::pow(std::exp(newLogP - oldLogP), a) > std::pow(2, -a))
  {
    stepSize = std::pow(2, a) * stepSize;

    oldLogP = newLogP;

    // Here leapfrog uses Kinetic Energy with metric instead of Identity
    _integrator->step(q, p, stepSize, _hamiltonian, _modelEvaluationCount, _sampleDatabase.size(), _inverseMetric);
    newLogP = -_hamiltonian->H(q, p, _modelEvaluationCount, _sampleDatabase.size(), _inverseMetric);
  }

  // Catch Step Size = 0.0 -> No traversal of phase space
  if (stepSize <= 0.0)
  {
    KORALI_LOG_ERROR("Failed to find reasonable Step Size. Step Size is %+6.3e.\n", _stepSize);
  }

  return stepSize;
}

bool HMC::computeNoUTurnCriterion(const std::vector<double> &pLeft, const std::vector<double> &pRight, const std::vector<double> &rho) const
{
  double dotProductLeft, dotProductRight;
  std::vector<double> tmpVectorOne(_stateSpaceDim, 0.0);
  std::vector<double> tmpVectorTwo(_stateSpaceDim, 0.0);

  std::vector<double> pLeftAdjusted = pLeft;
  std::vector<double> pRightAdjusted = pRight;

  for (size_t i = 0; i < _stateSpaceDim; ++i)
  {
    pLeftAdjusted[i] *= _stepSize;
    pRightAdjusted[i] *= _stepSize;
  }

  std::transform(std::cbegin(rho), std::cend(rho), std::cbegin(pLeftAdjusted), std::begin(tmpVectorOne), std::minus<double>());
  std::transform(std::cbegin(rho), std::cend(rho), std::cbegin(pRightAdjusted), std::begin(tmpVectorTwo), std::minus<double>());
  dotProductLeft = dotProduct(tmpVectorOne, pLeft);
  dotProductRight = dotProduct(tmpVectorTwo, pRight);

  // dotProductLeft = std::inner_product(std::cbegin(pLeft), std::cend(pLeft), std::cbegin(tmpVectorOne), 0.0);
  // dotProductRight = std::inner_product(std::cbegin(pRight), std::cend(pRight), std::cbegin(tmpVectorTwo), 0.0);

  dotProductLeft = dotProduct(rho, pLeft);
  dotProductRight = dotProduct(rho, pRight);

  // std::cout << "Integral Version: " << std::endl;
  // std::cout << "dotProductLeft = " << dotProductLeft << std::endl;
  // std::cout << "dotProductRight = " << dotProductRight << std::endl;
  // std::cout << "--------------------------" << std::endl;

  return dotProductLeft > 0 && dotProductRight > 0;
}

void HMC::buildTree(const std::vector<double> &q, const std::vector<double> &p, const double logUniSample, const int direction, const int depth, const double stepSize, const double rootH, std::vector<double> &qLeft, std::vector<double> &pLeft, std::vector<double> &qRight, std::vector<double> &pRight, std::vector<double> &qProposed, double &numValidLeaves, bool &buildCriterion, double &alpha, int &numLeaves)
{
  qLeft = q;
  pLeft = p;

  if (depth == 0)
  {
    const double deltaMax = 100;
    _integrator->step(qLeft, pLeft, _stepSize, _hamiltonian, _modelEvaluationCount, _sampleDatabase.size(), _inverseMetric);

    const double leafK = _hamiltonian->K(qLeft, pLeft, _inverseMetric);
    const double leafU = _hamiltonian->U(qLeft, _modelEvaluationCount, _sampleDatabase.size());
    const double leafH = leafU + leafK;

    numValidLeaves = (logUniSample <= rootH - leafH) ? 1.0 : 0.0;

    buildCriterion = (rootH - leafH + deltaMax > logUniSample);
    alpha = std::min(1.0, std::exp(rootH - leafH));
    numLeaves = 1;
    qRight = qLeft;
    qProposed = qLeft;
    pRight = pLeft;
  }
  else
  {
    int numLeavesSubtree;
    bool buildCriterionSubtree;
    double dotProductLeft, dotProductRight, numValidLeavesSubtree, alphaSubtree;

    std::vector<double> nullPointOne(_stateSpaceDim);
    std::vector<double> nullPointTwo(_stateSpaceDim);
    std::vector<double> qProposedSubtree(_stateSpaceDim, 0.0);
    std::vector<double> tmpVector(_stateSpaceDim, 0.0);

    buildTree(q, p, logUniSample, direction, depth - 1, stepSize, rootH, qLeft, pLeft, qRight, pRight, qProposed, numValidLeaves, buildCriterion, alpha, numLeaves);

    if (buildCriterion == true)
    {
      if (direction == -1)
      {
        buildTree(qLeft, pLeft, logUniSample, direction, depth - 1, stepSize, rootH, qLeft, pLeft, nullPointOne, nullPointTwo, qProposedSubtree, numValidLeavesSubtree, buildCriterionSubtree, alphaSubtree, numLeavesSubtree);
      }
      else
      {
        buildTree(qRight, pRight, logUniSample, direction, depth - 1, stepSize, rootH, nullPointOne, nullPointTwo, qRight, pRight, qProposedSubtree, numValidLeavesSubtree, buildCriterionSubtree, alphaSubtree, numLeavesSubtree);
      }

      // First check to avoid divising by zero
      if (numValidLeavesSubtree != 0 && _uniformGenerator->getRandomNumber() < numValidLeavesSubtree / (numValidLeaves + numValidLeavesSubtree))
      {
        qProposed = qProposedSubtree;
      }

      numValidLeaves += numValidLeavesSubtree;
      alpha += alphaSubtree;
      numLeaves += numLeavesSubtree;

      std::transform(std::cbegin(qRight), std::cend(qRight), std::cbegin(qLeft), std::begin(tmpVector), std::minus<double>());
      dotProductLeft = std::inner_product(std::cbegin(tmpVector), std::cend(tmpVector), std::cbegin(pLeft), 0.0);
      dotProductRight = std::inner_product(std::cbegin(tmpVector), std::cend(tmpVector), std::cbegin(pRight), 0.0);

      buildCriterion = buildCriterionSubtree && (dotProductLeft > 0) && (dotProductRight > 0);
    }
  }

  return;
}

void HMC::buildTreeIntegrationCriterion(const std::vector<double> &q, const std::vector<double> &p, const double logUniSample, const int direction, const int depth, const double stepSize, const double rootH, std::vector<double> &qLeft, std::vector<double> &pLeft, std::vector<double> &qRight, std::vector<double> &pRight, std::vector<double> &qProposed, double &numValidLeaves, bool &buildCriterion, double &alpha, int &numLeaves, std::vector<double> &rho)
{
  qLeft = q;
  pLeft = p;

  if (depth == 0)
  {
    const double deltaMax = 100;
    _integrator->step(qLeft, pLeft, _stepSize, _hamiltonian, _modelEvaluationCount, _sampleDatabase.size(), _inverseMetric);

    // std::transform(std::cbegin(rho), std::cend(rho), std::cbegin(pLeft), std::begin(rho), std::plus<double>());

    // for (size_t i = 0; i < _stateSpaceDim; ++i)
    // {
    //   rho[i] += _stepSize * pLeft[i];
    // }

    const double leafK = _hamiltonian->K(qLeft, pLeft, _inverseMetric);
    const double leafU = _hamiltonian->U(qLeft, _modelEvaluationCount, _sampleDatabase.size());
    const double leafH = leafU + leafK;

    numValidLeaves = (logUniSample <= rootH - leafH) ? 1.0 : 0.0;

    buildCriterion = (rootH - leafH + deltaMax > logUniSample);
    alpha = std::min(1.0, std::exp(rootH - leafH));
    numLeaves = 1;
    qRight = qLeft;
    qProposed = qLeft;
    pRight = pLeft;
  }
  else
  {
    int numLeavesSubtree;
    bool buildCriterionSubtree;
    double dotProductLeft, dotProductRight, numValidLeavesSubtree, alphaSubtree;

    std::vector<double> nullPointOne(_stateSpaceDim);
    std::vector<double> nullPointTwo(_stateSpaceDim);
    std::vector<double> qProposedSubtree(_stateSpaceDim, 0.0);
    std::vector<double> tmpVector(_stateSpaceDim, 0.0);
    std::vector<double> rho1(_stateSpaceDim, 0.0);
    std::vector<double> rho2(_stateSpaceDim, 0.0);

    buildTreeIntegrationCriterion(q, p, logUniSample, direction, depth - 1, stepSize, rootH, qLeft, pLeft, qRight, pRight, qProposed, numValidLeaves, buildCriterion, alpha, numLeaves, rho1);

    if (buildCriterion == true)
    {
      if (direction == -1)
      {
        buildTreeIntegrationCriterion(qLeft, pLeft, logUniSample, direction, depth - 1, stepSize, rootH, qLeft, pLeft, nullPointOne, nullPointTwo, qProposedSubtree, numValidLeavesSubtree, buildCriterionSubtree, alphaSubtree, numLeavesSubtree, rho2);
      }
      else
      {
        buildTreeIntegrationCriterion(qRight, pRight, logUniSample, direction, depth - 1, stepSize, rootH, nullPointOne, nullPointTwo, qRight, pRight, qProposedSubtree, numValidLeavesSubtree, buildCriterionSubtree, alphaSubtree, numLeavesSubtree, rho2);
      }

      // First check to avoid divising by zero
      if (numValidLeavesSubtree != 0 && _uniformGenerator->getRandomNumber() < numValidLeavesSubtree / (numValidLeaves + numValidLeavesSubtree))
      {
        qProposed = qProposedSubtree;
      }

      numValidLeaves += numValidLeavesSubtree;
      alpha += alphaSubtree;
      numLeaves += numLeavesSubtree;

      std::transform(std::cbegin(qRight), std::cend(qRight), std::cbegin(qLeft), std::begin(tmpVector), std::minus<double>());
      dotProductLeft = std::inner_product(std::cbegin(tmpVector), std::cend(tmpVector), std::cbegin(pLeft), 0.0);
      dotProductRight = std::inner_product(std::cbegin(tmpVector), std::cend(tmpVector), std::cbegin(pRight), 0.0);

      buildCriterion = buildCriterionSubtree && (dotProductLeft > 0) && (dotProductRight > 0);

      // std::cout << "direction = " << direction << std::endl;
      // std::cout << "depth = " << depth << std::endl;
      // std::cout << "Normal difference: " << std::endl;
      // std::cout << "dotProductLeft = " << dotProductLeft << std::endl;
      // std::cout << "dotProductRight = " << dotProductRight << std::endl;

      // std::vector<double> rhoSubtree = rho1;

      // std::transform(std::cbegin(rhoRightSubtree), std::cend(rhoRightSubtree), std::cbegin(rhoSubtree), std::begin(rhoSubtree), std::plus<double>());
      // std::transform(std::cbegin(rhoSubtree), std::cend(rhoSubtree), std::cbegin(rho), std::begin(rho), std::plus<double>());
      // for (size_t i = 0; i < _stateSpaceDim; ++i)
      // {
      //   rhoSubtree[i] += rho2[i];
      //   rho[i] += rhoSubtree[i];
      // }

      // std::vector<double> p_ = direction == -1 ? pLeft : pRight;
      // buildCriterion = buildCriterionSubtree && computeNoUTurnCriterion(p, p_, rhoSubtree);
    }
  }

  return;
}

} // namespace sampler

} // namespace solver

} // namespace korali
