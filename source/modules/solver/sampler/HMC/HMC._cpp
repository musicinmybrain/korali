#include "auxiliar/math.hpp"
#include "modules/conduit/conduit.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/problem/problem.hpp"
#include "modules/solver/sampler/HMC/HMC.hpp"

#include <chrono>
#include <limits>
#include <numeric>

#include <gsl/gsl_linalg.h>
#include <gsl/gsl_matrix.h>
#include <gsl/gsl_multimin.h>
#include <gsl/gsl_sort_vector.h>
#include <gsl/gsl_statistics.h>

namespace korali
{
namespace solver
{
namespace sampler
{
void HMC::setInitialConfiguration()
{
  if (_version == "Static")
    _eVersion = EVersion::Static;
  else if (_version == "Euclidean")
    _eVersion = EVersion::Euclidean;
  else if (_version == "Remannian")
    _eVersion = EVersion::Riemannian;
  else if (_version == "Remannian Const")
    _eVersion = EVersion::Riemannian_Const;
  else
    KORALI_LOG_ERROR("Version must be either 'Static', 'Euclidean', 'Riemannian' or 'Riemannian Const' (is %s)\n", _version.c_str());

  if (_burnIn < 0) KORALI_LOG_ERROR("Burn In must be larger equal 0 (is %zu).\n", _burnIn);
  if (_stepSize <= 0.0) KORALI_LOG_ERROR("Step Size must be larger 0 (is %lf).\n", _stepSize);
  if (_maxDepth < 0) KORALI_LOG_ERROR("Max Depth must be non-negative (is %zu).\n", _maxDepth);
  if (_inverseRegularizationParameter <= 0.0) KORALI_LOG_ERROR("Inverse Regularization Parameter must be positive (is %lf).\n", _inverseRegularizationParameter);
  if (_targetAcceptanceRate <= 0.0 || _targetAcceptanceRate > 1.0) KORALI_LOG_ERROR("Target Acceptance Rate must be in interval (0.0, 1.0] (is %lf).\n", _targetAcceptanceRate);
  if (_acceptanceRateLearningRate <= 0.0 || _acceptanceRateLearningRate > 1.0) KORALI_LOG_ERROR("Acceptance Rate Learning Rate must be in interval (0.0, 1.0] (is %lf).\n", _acceptanceRateLearningRate);
  if (_targetIntegrationTime <= 0.0) KORALI_LOG_ERROR("Target Integration Time must be greater 0 (is %lf).\n", _targetIntegrationTime);
  if (_numIntegrationSteps <= 0) KORALI_LOG_ERROR("Num Integration Steps must be larger equal 1 (is %zu).\n", _numIntegrationSteps);
  if (_maxIntegrationSteps < _numIntegrationSteps) KORALI_LOG_ERROR("Max Integration Steps must be larger equal 'Num Integrations Steps' (is %zu).\n", _maxIntegrationSteps);
  if (_maxNumFixedPointIteration <= 0) KORALI_LOG_ERROR("Max Num Fixed Point Iterations must be larger equal 1 (is %zu).\n", _maxNumFixedPointIteration);
  if (_adaptiveStepSizeSpeedConstant <= 0.0) KORALI_LOG_ERROR("Adaptive Step Size Speed Constant must be positive (is %lf).\n", _adaptiveStepSizeSpeedConstant);
  if (_adaptiveStepSizeStabilizationConstant <= 0.0) KORALI_LOG_ERROR("Adaptive Step Size Stabilization Constant must be non-negative (is %lf).\n", _adaptiveStepSizeStabilizationConstant);
  if (_adaptiveStepSizeScheduleConstant <= 0.0 || _adaptiveStepSizeScheduleConstant > 1.0) KORALI_LOG_ERROR("Adaptive Step Size Schedule Constant must be in the interval (0.0, 1.0] (is %lf).\n", _adaptiveStepSizeScheduleConstant);
  if (_stepSizeJitter < 0.0 || _stepSizeJitter > 1.0) KORALI_LOG_ERROR("Step Size Jitter has to in [0.0, 1.0] (is %lf).\n", _stepSizeJitter);

  if (_initialFastAdaptionInterval < 0) KORALI_LOG_ERROR("Initial Fast Adaption Interval must be greater equal 0 (is %zu).\n", _initialFastAdaptionInterval);
  if (_initialSlowAdaptionInterval < 0) KORALI_LOG_ERROR("Initial Slow Adaption Interval must be greater equal 0 (is %zu).\n", _initialSlowAdaptionInterval);
  if (_finalFastAdaptionInterval < 0) KORALI_LOG_ERROR("Final Fast Adaption Interval must be greater equal 0 (is %zu).\n", _finalFastAdaptionInterval);

  if (_eVersion == EVersion::Euclidean && _useAdaptiveStepSize)
  {
    if (_burnIn < _initialFastAdaptionInterval + _initialSlowAdaptionInterval + _finalFastAdaptionInterval)
    {
      _k->_logger->logInfo("Minimal", "Burn In (%zu) smaller than adaption length: %zu\n", _initialFastAdaptionInterval + _initialSlowAdaptionInterval + _finalFastAdaptionInterval);
      _k->_logger->logInfo("Minimal", "Reducing adaption window lengths to (15%/75%/10%) of Burn In period\n");
      _initialFastAdaptionInterval = _burnIn * 0.15;
      _finalFastAdaptionInterval = _burnIn * 0.10;
      _initialSlowAdaptionInterval = _burnIn - _initialFastAdaptionInterval - _finalFastAdaptionInterval;
    }

    size_t minBurnInLength = 100;
    if (_burnIn < minBurnInLength)
      KORALI_LOG_ERROR("Burn In too short for adaptive step size, must be larger than %zu (is %zu).", minBurnInLength, _burnIn);
  }

  _dimensions = _k->_variables.size();

  // Resizing vectors of internal settings to correct dimensions
  _positionLeader.resize(_dimensions);
  _positionCandidate.resize(_dimensions);
  _momentumLeader.resize(_dimensions);
  _momentumCandidate.resize(_dimensions);

  // Prepare DBs
  _sampleDatabase.resize(0);
  _euclideanWarmupSampleDatabase.resize(0);
  _sampleEvaluationDatabase.resize(0);

  // initializing variable defaults
  for (size_t i = 0; i < _dimensions; i++)
  {
    if (std::isfinite(_k->_variables[i]->_initialMean) == false)
      KORALI_LOG_ERROR("Initial Mean of variable \'%s\' not defined.\n", _k->_variables[i]->_name.c_str());
    if (std::isfinite(_k->_variables[i]->_initialStandardDeviation) == false)
      KORALI_LOG_ERROR("Initial Standard Deviation of variable \'%s\' not defined.\n", _k->_variables[i]->_name.c_str());
    _positionLeader[i] = _k->_variables[i]->_initialMean;
  }

  // Initializing metric and inverseMetric for diagonal and dense
  std::vector<double> metric;
  std::vector<double> inverseMetric;

  if (_useDiagonalMetric == true || _eVersion == EVersion::Static)
  {
    metric.resize(_dimensions);
    inverseMetric.resize(_dimensions);
    for (size_t i = 0; i < _dimensions; ++i)
    {
      inverseMetric[i] = _k->_variables[i]->_initialStandardDeviation * _k->_variables[i]->_initialStandardDeviation;
      metric[i] = 1.0 / inverseMetric[i];
    }
  }
  else
  {
    metric.resize(_dimensions * _dimensions, 0.0);
    inverseMetric.resize(_dimensions * _dimensions, 0.0);

    for (size_t d = 0; d < _dimensions; ++d)
    {
      metric[d * _dimensions + d] = _k->_variables[d]->_initialStandardDeviation * _k->_variables[d]->_initialStandardDeviation;
      inverseMetric[d * _dimensions + d] = 1.0 / metric[d * _dimensions + d];
    }
  }

  // Initializing Integrator and Hamiltonian
  if (_eVersion == EVersion::Static)
  {
    _hamiltonian = std::make_shared<HamiltonianEuclideanDiag>(_dimensions, _normalGenerator, metric, inverseMetric, _k);
    _integrator = std::make_unique<LeapfrogExplicit>(_hamiltonian);
  }
  else if (_eVersion == EVersion::Euclidean)
  {
    if (_useDiagonalMetric)
      _hamiltonian = std::make_shared<HamiltonianEuclideanDiag>(_dimensions, _normalGenerator, metric, inverseMetric, _k);
    else
      _hamiltonian = std::make_shared<HamiltonianEuclideanDense>(_dimensions, _multivariateGenerator, metric, inverseMetric, _k);
    _integrator = std::make_unique<LeapfrogExplicit>(_hamiltonian);
  }
  else if (_eVersion == EVersion::Riemannian)
  {
    if (_useDiagonalMetric)
      _hamiltonian = std::make_shared<HamiltonianRiemannianDiag>(_dimensions, _normalGenerator, metric, inverseMetric, _inverseRegularizationParameter, _k);
    else
      KORALI_LOG_ERROR("Riemannian Metric only supported with Diagonal Metric");
    _integrator = std::make_unique<LeapfrogImplicit>(_maxNumFixedPointIteration, _hamiltonian);
  }
  else if (_eVersion == EVersion::Riemannian_Const)
  {
    if (_useDiagonalMetric)
      _hamiltonian = std::make_shared<HamiltonianRiemannianConstDiag>(_dimensions, _normalGenerator, metric, inverseMetric, _inverseRegularizationParameter, _k);
    else
      _hamiltonian = std::make_shared<HamiltonianRiemannianConstDense>(_dimensions, _multivariateGenerator, metric, inverseMetric, _inverseRegularizationParameter, _k);
    _integrator = std::make_unique<LeapfrogExplicit>(_hamiltonian);
  }

  if (_useAdaptiveStepSize == true)
  {
    _mu = std::log(10.0 * _stepSize);
    _hBar = 0.0;
  }

  // Initialize Generation
  _acceptanceCount = 0;
  _proposedSampleCount = 0;
  _chainLength = 0;
  _acceptanceRate = 1.0;
  _acceptanceRateError = 0.0;
  _runningAcceptanceRate = 1.0;
  _currentDepth = 0;
  _logDualStepSize = std::log(_stepSize);
}

void HMC::runGeneration()
{
  if (_k->_currentGeneration == 1) setInitialConfiguration();
  _hamiltonian->updateHamiltonian(_positionLeader);

  // Samples Momentum Candidate from N(0.0, metric)
  _momentumCandidate = _hamiltonian->sampleMomentum();
  _proposedSampleCount++;

  _positionCandidate = _positionLeader;
  _momentumLeader = _momentumCandidate;

  if (_eVersion == EVersion::Riemannian_Const)
  {
    int err = _hamiltonian->updateMetricMatricesRiemannian(_positionLeader); // TODO: double check, is this not needed fo Riamannian?
    if (err > 0) _k->_logger->logWarning("Minimal", "Error during metric update.");
  }

  // New uniform sample for accept / reject
  const double logUniSample = std::log(_uniformGenerator->getRandomNumber());

  // Execute version specific generation
  if (_useNUTS)
  {
    if (_eVersion == EVersion::Static || _eVersion == EVersion::Euclidean || _eVersion == EVersion::Riemannian_Const)
    {
      runGenerationNUTS(logUniSample); // TODO: double check, this method also for Riemannian Const?
    }
    else /* _eVersion == EVersion::Riemannian */
    {
      runGenerationNUTSRiemannian(logUniSample);
    }
  }
  else
  {
    runGenerationHMC(logUniSample);
  }

  saveSample();

  updateState();
}

void HMC::runGenerationHMC(const double logUniSample)
{
  // Track energies from leader
  const double oldK = _hamiltonian->K(_momentumLeader);
  const double oldU = _hamiltonian->U();

  for (size_t i = 0; i < _numIntegrationSteps; ++i)
    _integrator->step(_positionCandidate, _momentumCandidate, _stepSize);

  // Negate proposed momentum to make proposal symmetric
  std::transform(std::cbegin(_momentumCandidate), std::cend(_momentumCandidate), std::begin(_momentumCandidate), std::negate<double>());

  // Save energies from candidate
  const double newK = _hamiltonian->K(_momentumCandidate);
  const double newU = _hamiltonian->U();
  const double logAlpha = std::min(0.0, -(newK - oldK + newU - oldU));

  // Accept or reject sample
  bool isNanPositionCandidate = isanynan(_positionCandidate);
  _acceptanceProbability = isNanPositionCandidate ? 0.0 : std::exp(logAlpha);
  _runningAcceptanceRate = _acceptanceRateLearningRate * _runningAcceptanceRate + (1. - _acceptanceRateLearningRate) * _acceptanceProbability;
  if (logUniSample <= logAlpha && !isNanPositionCandidate)
  {
    _acceptanceCount++;
    _positionLeader = _positionCandidate;
    _leaderEvaluation = -newU;
  }
}

void HMC::runGenerationNUTS(const double logUniSample)
{
  const double oldK = _hamiltonian->K(_momentumLeader);
  const double oldU = _hamiltonian->U();

  auto qLeft = _positionLeader;
  auto pLeft = _momentumLeader;
  auto qRight = _positionLeader;
  auto pRight = _momentumLeader;

  _currentDepth = 0;
  size_t numLeavesSubtree;
  bool buildCriterion = true;
  bool buildCriterionSubtree;
  double numValidLeaves = 1.0;
  double numValidLeavesSubtree;
  const double oldH = oldU + oldK;

  auto helper = std::make_shared<TreeHelperEuclidean>();
  helper->logUniSampleIn = logUniSample;
  helper->rootHIn = oldH;
  helper->buildCriterionOut = true;

  while (buildCriterion == true && _currentDepth <= _maxDepth)
  {
    if (_uniformGenerator->getRandomNumber() < 0.5)
    {
      helper->qIn = qLeft;
      helper->pIn = pLeft;
      helper->directionIn = -1;

      buildTreeUtil(helper, _currentDepth);

      qLeft = helper->qLeftOut;
      pLeft = helper->pLeftOut;
      // qRight = --
      // pRight = --

      // Setting for termination criterium
      helper->qRightOut = qRight;
      helper->pRightOut = pRight;
    }
    else
    {
      helper->qIn = qRight;
      helper->pIn = pRight;
      helper->directionIn = 1;

      buildTreeUtil(helper, _currentDepth);

      // qLeft = --
      // pLeft = --
      qRight = helper->qRightOut;
      pRight = helper->pRightOut;

      // setting for termination criterium
      helper->qLeftOut = qLeft;
      helper->pLeftOut = pLeft;
    }
    _positionCandidate = helper->qProposedOut;
    numValidLeavesSubtree = helper->numValidLeavesOut;
    buildCriterionSubtree = helper->buildCriterionOut;
    _acceptanceProbability = helper->alphaOut;
    numLeavesSubtree = helper->numLeavesOut;

    if (buildCriterionSubtree == true)
    {
      if (numValidLeaves == 0)
      {
        KORALI_LOG_ERROR("Division by zero encountered in NUTS (numValidLeaves is %lf).\n", numValidLeaves);
      }
      if (_uniformGenerator->getRandomNumber() < numValidLeavesSubtree / numValidLeaves && isanynan(_positionCandidate) == false)
      {
        _positionLeader = _positionCandidate;
        _leaderEvaluation = -_hamiltonian->U();
      }
    }

    numValidLeaves += numValidLeavesSubtree;

    buildCriterion = buildCriterionSubtree && helper->computeCriterion(*_hamiltonian);

    _currentDepth++;
  }

  _currentDepth--;
  _acceptanceProbability /= (double)numLeavesSubtree;
  _acceptanceCountNUTS += _acceptanceProbability;
  _runningAcceptanceRate = _acceptanceRateLearningRate * _runningAcceptanceRate + (1. - _acceptanceRateLearningRate) * _acceptanceProbability;
}

void HMC::runGenerationNUTSRiemannian(const double logUniSample)
{
  _hamiltonian->updateHamiltonian(_positionLeader);
  const double oldK = _hamiltonian->K(_momentumLeader);
  const double oldU = _hamiltonian->U();

  std::vector<double> qLeft = _positionLeader;
  std::vector<double> pLeft = _momentumLeader;
  std::vector<double> qRight = _positionLeader;
  std::vector<double> pRight = _momentumLeader;

  size_t depth = 0;
  size_t numLeavesSubtree;
  bool buildCriterion = true;
  bool buildCriterionSubtree;
  double numValidLeaves = 1.0;
  double numValidLeavesSubtree;
  const double oldH = oldU + oldK;

  auto helper = std::make_shared<TreeHelperRiemannian>();
  helper->logUniSampleIn = logUniSample;
  helper->rootHIn = oldH;
  helper->buildCriterionOut = true;

  std::vector<double> rhoInit = _momentumLeader;
  std::vector<double> rhoLeft(_dimensions, 0.0);
  std::vector<double> rhoRight(_dimensions, 0.0);
  while (buildCriterion == true && depth <= _maxDepth)
  {
    helper->depthIn = depth;
    if (_uniformGenerator->getRandomNumber() < 0.5)
    {
      helper->qIn = qLeft;
      helper->pIn = pLeft;
      helper->directionIn = -1;

      buildTreeUtilIntegration(helper, rhoLeft, depth);

      qLeft = helper->qLeftOut;
      pLeft = helper->pLeftOut;
      // qRight = --
      // pRight = --

      // Setting for termination criterium
      helper->qRightOut = qRight;
      helper->pRightOut = pRight;
    }
    else
    {
      helper->qIn = qRight;
      helper->pIn = pRight;
      helper->directionIn = 1;

      buildTreeUtilIntegration(helper, rhoRight, depth);

      // qLeft = --
      // pLeft = --
      qRight = helper->qRightOut;
      pRight = helper->pRightOut;

      // setting for termination criterium
      helper->qLeftOut = qLeft;
      helper->pLeftOut = pLeft;
    }
    _positionCandidate = helper->qProposedOut;
    numValidLeavesSubtree = helper->numValidLeavesOut;
    buildCriterionSubtree = helper->buildCriterionOut;
    _acceptanceProbability = helper->alphaOut;
    numLeavesSubtree = helper->numLeavesOut;

    if (buildCriterionSubtree == true)
    {
      if (numValidLeaves == 0)
      {
        KORALI_LOG_ERROR("Division by zero encountered in NUTS (numValidLeaves is %lf).\n", numValidLeaves);
      }
      if (_uniformGenerator->getRandomNumber() < numValidLeavesSubtree / numValidLeaves && isanynan(_positionCandidate) == false)
      {
        _positionLeader = _positionCandidate;
        _leaderEvaluation = -_hamiltonian->U();
      }
    }

    numValidLeaves += numValidLeavesSubtree;

    std::vector<double> deltaRho(_dimensions, 0.0);

    std::transform(std::cbegin(rhoLeft), std::cend(rhoLeft), std::cbegin(deltaRho), std::begin(deltaRho), std::plus<double>());
    std::transform(cbegin(rhoInit), std::cend(rhoInit), std::cbegin(deltaRho), std::begin(deltaRho), std::plus<double>());
    std::transform(std::cbegin(rhoRight), std::cend(rhoRight), std::cbegin(deltaRho), std::begin(deltaRho), std::plus<double>());

    buildCriterion = buildCriterionSubtree && helper->computeCriterion(*_hamiltonian, pLeft, pRight, deltaRho);

    depth++;
  }

  _acceptanceProbability /= (double)numLeavesSubtree;
  _acceptanceCountNUTS += _acceptanceProbability;
  _runningAcceptanceRate = _acceptanceRateLearningRate * _runningAcceptanceRate + (1. - _acceptanceRateLearningRate) * _acceptanceProbability;
}

void HMC::saveSample()
{
  // Store samples after burn in period
  if (_burnIn <= _chainLength)
  {
    _sampleDatabase.push_back(_positionLeader);
    _sampleEvaluationDatabase.push_back(_leaderEvaluation);
  }
  // Keep samples during slow adaption interval for metric calculation
  else if (_eVersion == EVersion::Euclidean && (_initialFastAdaptionInterval <= _chainLength) && (_chainLength < _initialFastAdaptionInterval + _initialSlowAdaptionInterval))
  {
    _euclideanWarmupSampleDatabase.push_back(_positionLeader);
  }
}

void HMC::updateStepSize()
{
  // Adapt step size during burn in period
  if (_chainLength <= _burnIn)
  {
    const size_t terminalFastPeriodStart = _initialFastAdaptionInterval + _initialSlowAdaptionInterval;
    const size_t terminalFastPeriodEnd = terminalFastPeriodStart + _finalFastAdaptionInterval;

    bool isInitalFastPeriod = _chainLength < _initialFastAdaptionInterval;
    bool isTerminalFastPeriod = (_chainLength >= terminalFastPeriodStart) && (_chainLength < terminalFastPeriodEnd);

    if (_useAdaptiveStepSize == true)
    {
      // Reset statistics before starting terminal fast period
      if (_chainLength == terminalFastPeriodStart)
      {
        _acceptanceRateError = 0.0;
        _hBar = 0.0;
        _mu = std::log(10.0 * _stepSize);
      }

      // Update step size and dual step size during fast adaption periods
      if (isInitalFastPeriod || isTerminalFastPeriod)
      {
        const double counter = isInitalFastPeriod ? _chainLength + 1 : _chainLength + 1 - terminalFastPeriodStart;
        _acceptanceProbability = (_acceptanceProbability > 1.0) ? 1.0 : _acceptanceProbability;
        _runningAcceptanceRate = (_runningAcceptanceRate > 1.0) ? 1.0 : _runningAcceptanceRate;
        _acceptanceRateError = _targetAcceptanceRate - _runningAcceptanceRate;
        const double eta = 1.0 / (counter + 10.0);
        _hBar = (1.0 - eta) * _hBar + eta * _acceptanceRateError;

        const double logStep = _mu - _hBar * std::sqrt(counter) / _adaptiveStepSizeSpeedConstant;
        const double dualEta = std::pow(counter, -_adaptiveStepSizeScheduleConstant);
        _logDualStepSize = (1.0 - dualEta) * _logDualStepSize + dualEta * logStep;
        _stepSize = std::exp(logStep);

        if (_useNUTS == false)
        {
          _numIntegrationSteps = std::max((size_t)1, (size_t)std::round(_targetIntegrationTime / _stepSize));
          if (_numIntegrationSteps > _maxIntegrationSteps)
          {
            _k->_logger->logWarning("Minimal", "Num Integration Steps (%zu) exceeding hard limit 'Max Integration Steps' (%zu).\n", _numIntegrationSteps, _maxIntegrationSteps);
            _numIntegrationSteps = _maxIntegrationSteps;
          }
        }
      }
      // Fix step size after terminal fast epriod
      else if (_chainLength == terminalFastPeriodEnd)
      {
        _stepSize = std::exp(_logDualStepSize);
      }
    }
  }
  // Apply Step Size Jitter after burn in period
  else
  {
    _stepSize = std::exp(_logDualStepSize) * (1.0 + _stepSizeJitter * (2.0 * _uniformGenerator->getRandomNumber() - 1.0));
  }
}

void HMC::updateState()
{
  // Update Acceptance Rate
  if (_useNUTS)
    _acceptanceRate = (double)_acceptanceCountNUTS / ((double)_chainLength + 1);
  else
    _acceptanceRate = (double)_acceptanceCount / ((double)(_chainLength + 1));

  // Update Step Size, Dual Step Size, H Bar and apply step size jitter
  updateStepSize();

  // Update metric at the end of slow adaption period
  if (_eVersion == EVersion::Euclidean && _useAdaptiveStepSize && _chainLength == _initialFastAdaptionInterval + _initialSlowAdaptionInterval)
  {
    int err = _hamiltonian->updateMetricMatricesEuclidean(_euclideanWarmupSampleDatabase);
    if (err == GSL_EDOM) KORALI_LOG_ERROR("Inverse Metric negative definite (not updating Metric). Increase 'Initial Slow Adaption Interval' (is %zu).", _initialSlowAdaptionInterval);
    _euclideanWarmupSampleDatabase.clear();
  }

  _chainLength++;
}

void HMC::printGenerationBefore()
{
  return;
}

void HMC::printGenerationAfter()
{
  // Number of Samples
  _k->_logger->logInfo("Minimal", "Database Entries %ld\n", _sampleDatabase.size());

  _k->_logger->logInfo("Normal", "Acceptance Rate Proposals: %.2f%%\n", 100. * _acceptanceRate);
  _k->_logger->logInfo("Normal", "Running Acceptance Rate: %.2f%%\n", 100. * _runningAcceptanceRate);
  _k->_logger->logInfo("Detailed", "Num Model Evaluations: %zu\n", _hamiltonian->_modelEvaluationCount);

  // Current Sample
  _k->_logger->logInfo("Detailed", "Current Leader:\n");
  for (size_t d = 0; d < _dimensions; ++d) _k->_logger->logData("Detailed", "         %s = %+6.3e\n", _k->_variables[d]->_name.c_str(), _positionLeader[d]);
  _k->_logger->logInfo("Detailed", "Current Candidate:\n");
  for (size_t d = 0; d < _dimensions; ++d) _k->_logger->logData("Detailed", "         %s = %+6.3e\n", _k->_variables[d]->_name.c_str(), _positionCandidate[d]);

  _k->_logger->logInfo("Detailed", "Current Metric:\n");

  auto metric = _hamiltonian->getMetric();
  if (_useDiagonalMetric == true || _eVersion == EVersion::Static)
  {
    for (size_t d = 0; d < _dimensions; ++d)
      _k->_logger->logData("Detailed", "         %+6.3e  \n", metric[d]);
  }
  else
  {
    for (size_t d = 0; d < _dimensions; ++d)
    {
      for (size_t e = 0; e < _dimensions; ++e)
        _k->_logger->logData("Detailed", "         %+6.3e  ", metric[d * _dimensions + e]);
      _k->_logger->logInfo("Detailed", "\n");
    }
  }

  // Gradient
  _k->_logger->logInfo("Detailed", "Gradient:\n");
  auto grad = _hamiltonian->dU();
  for (auto &g : grad) _k->_logger->logData("Detailed", "         %+6.3e  \n", g);

  // Inverse Metric
  _k->_logger->logInfo("Detailed", "Current Inverse Metric:\n");

  auto inverseMetric = _hamiltonian->getInverseMetric();
  if (_useDiagonalMetric == true || _eVersion == EVersion::Static)
  {
    for (size_t e = 0; e < _dimensions; ++e)
      _k->_logger->logData("Detailed", "         %+6.3e  \n", inverseMetric[e]);
  }
  else
  {
    for (size_t d = 0; d < _dimensions; ++d)
    {
      for (size_t e = 0; e < _dimensions; ++e)
        _k->_logger->logData("Normal", "         %+6.3e  ", inverseMetric[d * _dimensions + e]);
      _k->_logger->logInfo("Normal", "\n");
    }
  }

  // Chain Length + 1 = m in Algorithm
  _k->_logger->logInfo("Detailed", "Chain Length: %ld\n", _chainLength);

  if (_useAdaptiveStepSize == true)
  {
    // Step Size
    _k->_logger->logInfo("Detailed", "Step Size: %lf\n", _stepSize);
    // Dual Step Size
    _k->_logger->logInfo("Detailed", "Dual Step Size: %lf\n", std::exp(_logDualStepSize));
  }

  if (_useNUTS == false)
  {
    // Num Integration Steps
    _k->_logger->logInfo("Detailed", "Num Integration Steps: %ld\n", _numIntegrationSteps);
    _k->_logger->logInfo("Normal", "Accepted Samples: %zu\n", _acceptanceCount);
  }
  else
  {
    _k->_logger->logInfo("Detailed", "Accepted Samples Indicator (NUTS): %lf\n", _acceptanceCountNUTS);
    _k->_logger->logInfo("Detailed", "Current Depth (NUTS): %zu\n", _currentDepth);
  }

  return;
}

void HMC::finalize()
{
  _k->_logger->logInfo("Normal", "Number of Generated Samples: %zu\n", _proposedSampleCount);
  _k->_logger->logInfo("Normal", "Acceptance Rate: %.2f%%\n", 100 * _acceptanceRate);
  _k->_logger->logInfo("Normal", "Num Model Evaluations: %zu\n", _hamiltonian->_modelEvaluationCount);
  (*_k)["Results"]["Sample Database"] = _sampleDatabase;

  _modelEvaluationCount = _hamiltonian->getNumHamiltonianObjectUpdates();
}

void HMC::buildTreeUtil(std::shared_ptr<TreeHelperEuclidean> helper, const size_t depth)
{
  helper->qLeftOut = helper->qIn;
  helper->pLeftOut = helper->pIn;

  if (depth == 0)
  {
    const double deltaMax = 100;
    _integrator->step(helper->qLeftOut, helper->pLeftOut, helper->directionIn * _stepSize);

    const double leafK = _hamiltonian->K(helper->pLeftOut);
    const double leafU = _hamiltonian->U();
    const double leafH = leafU + leafK;

    helper->numValidLeavesOut = (helper->logUniSampleIn <= helper->rootHIn - leafH) ? 1.0 : 0.0;

    helper->buildCriterionOut = (helper->rootHIn - leafH + deltaMax > helper->logUniSampleIn);

    helper->alphaOut = isanynan(helper->qLeftOut) ? 0.0 : std::min(1.0, std::exp(helper->rootHIn - leafH));
    helper->numLeavesOut = 1;
    helper->qRightOut = helper->qLeftOut;
    helper->pRightOut = helper->pLeftOut;
    helper->qProposedOut = helper->qLeftOut;
  }
  else
  {
    size_t numLeavesSubtree;
    bool buildCriterionSubtree;
    double numValidLeavesSubtree, alphaSubtree;

    buildTreeUtil(helper, depth - 1);

    if (helper->buildCriterionOut == true)
    {
      auto helperSubtree = std::make_shared<TreeHelperEuclidean>();
      helperSubtree->logUniSampleIn = helper->logUniSampleIn;
      helperSubtree->directionIn = helper->directionIn;
      helperSubtree->rootHIn = helper->rootHIn;

      if (helper->directionIn == -1)
      {
        helperSubtree->qIn = helper->qLeftOut;
        helperSubtree->pIn = helper->pLeftOut;

        buildTreeUtil(helperSubtree, depth - 1);

        helper->qLeftOut = helperSubtree->qLeftOut;
        helper->pLeftOut = helperSubtree->pLeftOut;
        // helperSubtree->qRightOut = --
        // helperSubtree->pRightOut = --
      }
      else
      {
        helperSubtree->qIn = helper->qRightOut;
        helperSubtree->pIn = helper->pRightOut;

        buildTreeUtil(helperSubtree, depth - 1);

        // helperSubtree->qLeftOut = --
        // helperSubtree->pLeftOut = --
        helper->qRightOut = helperSubtree->qRightOut;
        helper->pRightOut = helperSubtree->pRightOut;
      }
      numValidLeavesSubtree = helperSubtree->numValidLeavesOut;
      buildCriterionSubtree = helperSubtree->buildCriterionOut;
      alphaSubtree = helperSubtree->alphaOut;
      numLeavesSubtree = helperSubtree->numLeavesOut;

      // First check to avoid divising by zero
      if (numValidLeavesSubtree != 0 && _uniformGenerator->getRandomNumber() < numValidLeavesSubtree / (helper->numValidLeavesOut + numValidLeavesSubtree))
      {
        helper->qProposedOut = helperSubtree->qProposedOut;
      }

      helper->numValidLeavesOut += numValidLeavesSubtree;
      helper->alphaOut += alphaSubtree;
      helper->numLeavesOut += numLeavesSubtree;

      helper->buildCriterionOut = buildCriterionSubtree && helper->computeCriterion(*_hamiltonian);
    }
  }
}

void HMC::buildTreeUtilIntegration(std::shared_ptr<TreeHelperRiemannian> helper, std::vector<double> &rho, const size_t depth)
{
  helper->qLeftOut = helper->qIn;
  helper->pLeftOut = helper->pIn;

  if (depth == 0)
  {
    const double deltaMax = 100;
    _integrator->step(helper->qLeftOut, helper->pLeftOut, helper->directionIn * _stepSize);

    _hamiltonian->updateHamiltonian(helper->pLeftOut);
    const double leafK = _hamiltonian->K(helper->pLeftOut);
    const double leafU = _hamiltonian->U();
    const double leafH = leafU + leafK;

    helper->numValidLeavesOut = (helper->logUniSampleIn <= helper->rootHIn - leafH) ? 1.0 : 0.0;

    helper->buildCriterionOut = (helper->rootHIn - leafH + deltaMax > helper->logUniSampleIn);

    helper->alphaOut = isanynan(helper->qLeftOut) ? 0.0 : std::min(1.0, std::exp(helper->rootHIn - leafH));
    helper->numLeavesOut = 1;
    helper->qRightOut = helper->qLeftOut;
    helper->pRightOut = helper->pLeftOut;
    helper->qProposedOut = helper->qLeftOut;

    std::transform(std::cbegin(rho), std::cend(rho), std::cbegin(helper->pRightOut), std::begin(rho), std::plus<double>());
  }
  else
  {
    size_t numLeavesSubtree;
    bool buildCriterionSubtree;
    double numValidLeavesSubtree, alphaSubtree;
    auto pStart = helper->pIn;
    std::vector<double> rhoFirstSubtree(_dimensions, 0.0);

    buildTreeUtilIntegration(helper, rhoFirstSubtree, depth - 1);

    if (helper->buildCriterionOut == true)
    {
      auto helperSubtree = std::make_shared<TreeHelperRiemannian>();
      helperSubtree->logUniSampleIn = helper->logUniSampleIn;
      helperSubtree->directionIn = helper->directionIn;
      helperSubtree->depthIn = helper->depthIn;
      helperSubtree->rootHIn = helper->rootHIn;

      std::vector<double> rhoSecondSubtree(_dimensions, 0.0);
      if (helper->directionIn == -1)
      {
        helperSubtree->qIn = helper->qLeftOut;
        helperSubtree->pIn = helper->pLeftOut;
        buildTreeUtilIntegration(helperSubtree, rhoSecondSubtree, depth - 1);

        helper->qLeftOut = helperSubtree->qLeftOut;
        helper->pLeftOut = helperSubtree->pLeftOut;
        // helperSubtree->qRightOut = --
        // helperSubtree->pRightOut = --
      }
      else
      {
        helperSubtree->qIn = helper->qRightOut;
        helperSubtree->pIn = helper->pRightOut;
        buildTreeUtilIntegration(helperSubtree, rhoSecondSubtree, depth - 1);

        // helperSubtree->qLeftOut = --
        // helperSubtree->pLeftOut = --
        helper->qRightOut = helperSubtree->qRightOut;
        helper->pRightOut = helperSubtree->pRightOut;
      }

      numValidLeavesSubtree = helperSubtree->numValidLeavesOut;
      buildCriterionSubtree = helperSubtree->buildCriterionOut;
      alphaSubtree = helperSubtree->alphaOut;
      numLeavesSubtree = helperSubtree->numLeavesOut;

      std::vector<double> rhoSubtree = rhoFirstSubtree;
      std::transform(std::cbegin(rhoSubtree), std::cend(rhoSubtree), std::cbegin(rhoSecondSubtree), std::begin(rhoSubtree), std::plus<double>());

      std::transform(std::cbegin(rho), std::cend(rho), std::cbegin(rhoSubtree), std::begin(rho), std::plus<double>());

      // First check to avoid divising by zero
      if (numValidLeavesSubtree != 0 && _uniformGenerator->getRandomNumber() < numValidLeavesSubtree / (helper->numValidLeavesOut + numValidLeavesSubtree))
      {
        helper->qProposedOut = helperSubtree->qProposedOut;
      }

      helper->numValidLeavesOut += numValidLeavesSubtree;
      helper->alphaOut += alphaSubtree;
      helper->numLeavesOut += numLeavesSubtree;

      std::vector<double> pEnd = helper->directionIn == -1 ? helperSubtree->pLeftOut : helperSubtree->pRightOut;
      helper->buildCriterionOut = buildCriterionSubtree && helper->computeCriterion(*_hamiltonian, pStart, pEnd, rhoSubtree);
    }
  }
}

} // namespace sampler

} // namespace solver

} // namespace korali
