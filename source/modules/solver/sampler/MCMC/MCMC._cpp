#include "modules/conduit/conduit.hpp"
#include "modules/experiment/experiment.hpp"
#include "modules/problem/problem.hpp"
#include "modules/solver/sampler/MCMC/MCMC.hpp"

#include <chrono>
#include <limits>
#include <numeric>

#include <gsl/gsl_linalg.h>
#include <gsl/gsl_matrix.h>
#include <gsl/gsl_multimin.h>
#include <gsl/gsl_sort_vector.h>
#include <gsl/gsl_statistics.h>

namespace korali
{
namespace solver
{
namespace sampler
{
void MCMC::setInitialConfiguration()
{
  if (_chainCovarianceScaling <= 0.0) KORALI_LOG_ERROR("Chain Covariance Scaling must be larger 0.0 (is %lf).\n", _chainCovarianceScaling);
  if (_leap < 1) KORALI_LOG_ERROR("Leap must be larger 0 (is %zu).\n", _leap);
  if (_burnIn < 0) KORALI_LOG_ERROR("Burn In must be larger equal 0 (is %zu).\n", _burnIn);
  if (_rejectionLevels < 1) KORALI_LOG_ERROR("Rejection Levels must be larger 0 (is %zu).\n", _rejectionLevels);
  if (_nonAdaptionPeriod < 0) KORALI_LOG_ERROR("Non Adaption Period must be larger equal 0 (is %zu).\n", _nonAdaptionPeriod);

  // Allocating MCMC memory
  _chainCandidate.resize(_rejectionLevels);
  for (size_t i = 0; i < _rejectionLevels; i++) _chainCandidate[i].resize(_k->_variables.size());

  _choleskyDecompositionCovariance.resize(_k->_variables.size() * _k->_variables.size());
  _chainLeader.resize(_k->_variables.size());
  _chainCandidatesEvaluations.resize(_rejectionLevels);
  _rejectionAlphas.resize(_rejectionLevels);
  _chainMean.resize(_k->_variables.size());
  _chainCovariancePlaceholder.resize(_k->_variables.size() * _k->_variables.size());
  _chainCovariance.resize(_k->_variables.size() * _k->_variables.size());
  _choleskyDecompositionChainCovariance.resize(_k->_variables.size() * _k->_variables.size());

  std::fill(std::begin(_choleskyDecompositionCovariance), std::end(_choleskyDecompositionCovariance), 0.0);
  std::fill(std::begin(_choleskyDecompositionChainCovariance), std::end(_choleskyDecompositionChainCovariance), 0.0);

  for (size_t i = 0; i < _k->_variables.size(); i++) _chainLeader[i] = _k->_variables[i]->_initialMean;
  for (size_t i = 0; i < _k->_variables.size(); i++) _choleskyDecompositionCovariance[i * _k->_variables.size() + i] = _k->_variables[i]->_initialStandardDeviation;

  // Init Generation
  _acceptanceCount = 0;
  _proposedSampleCount = 0;
  _chainLength = 0;
  _chainLeaderEvaluation = -std::numeric_limits<double>::infinity();
  _acceptanceRate = 1.0;
}

void MCMC::runGeneration()
{
  if (_k->_currentGeneration == 1) setInitialConfiguration();

  bool _sampleAccepted = false;

  for (size_t i = 0; i < _rejectionLevels && _sampleAccepted == false; i++)
  {
    generateCandidate(i);

    auto sample = Sample();

    _modelEvaluationCount++;
    sample["Parameters"] = _chainCandidate[i];
    sample["Sample Id"] = _sampleDatabase.size();
    sample["Module"] = "Problem";
    sample["Operation"] = "Evaluate";
    _conduit->start(sample);
    _conduit->wait(sample);

    double evaluation = KORALI_GET(double, sample, "P(x)");

    _chainCandidatesEvaluations[i] = evaluation;

    // Processing Result
    double denom;
    double _rejectionAlpha = recursiveAlpha(denom, _chainLeaderEvaluation, &_chainCandidatesEvaluations[0], i);

    if (_rejectionAlpha == 1.0 || _rejectionAlpha > _uniformGenerator->getRandomNumber())
    {
      _acceptanceCount++;
      _sampleAccepted = true;
      _chainLeaderEvaluation = _chainCandidatesEvaluations[i];
      _chainLeader = _chainCandidate[i];
    }
  }

  if ((_chainLength >= _burnIn) && (_k->_currentGeneration % _leap == 0))
  {
    _sampleDatabase.push_back(_chainLeader);
    _sampleEvaluationDatabase.push_back(_chainLeaderEvaluation);
  }

  updateState();
  _chainLength++;
}

void MCMC::choleskyDecomp(const std::vector<double> &inC, std::vector<double> &outL) const
{
  gsl_matrix *A = gsl_matrix_alloc(_k->_variables.size(), _k->_variables.size());

  for (size_t d = 0; d < _k->_variables.size(); ++d)
    for (size_t e = 0; e < d; ++e)
    {
      gsl_matrix_set(A, d, e, inC[d * _k->_variables.size() + e]);
      gsl_matrix_set(A, e, d, inC[e * _k->_variables.size() + d]);
    }
  for (size_t d = 0; d < _k->_variables.size(); ++d) gsl_matrix_set(A, d, d, inC[d * _k->_variables.size() + d]);

  int err = gsl_linalg_cholesky_decomp1(A);

  if (err == GSL_EDOM)
  {
    _k->_logger->logWarning("Normal", "Chain Covariance negative definite (not updating Cholesky Decomposition of Chain Covariance).\n");
  }
  else
  {
    for (size_t d = 0; d < _k->_variables.size(); ++d)
      for (size_t e = 0; e < d; ++e)
      {
        outL[d * _k->_variables.size() + e] = gsl_matrix_get(A, d, e);
      }
    for (size_t d = 0; d < _k->_variables.size(); ++d) outL[d * _k->_variables.size() + d] = gsl_matrix_get(A, d, d);
  }

  gsl_matrix_free(A);
}

double MCMC::recursiveAlpha(double &deonominator, const double leaderLoglikelihood, const double *loglikelihoods, size_t N) const
{
  // recursive formula from Trias[2009]

  if (N == 0)
  {
    deonominator = exp(leaderLoglikelihood);
    return std::min(1.0, exp(loglikelihoods[0] - leaderLoglikelihood));
  }
  else
  {
    // revert sample array
    double *reversedLogLikelihoods = new double[N];
    for (size_t i = 0; i < N; ++i) reversedLogLikelihoods[i] = loglikelihoods[N - 1 - i];

    // update numerator (w. recursive calls)
    double numerator = std::exp(loglikelihoods[N]);
    for (size_t i = 0; i < N; ++i)
    {
      double dummyDenominator;
      double alphaNumerator = recursiveAlpha(dummyDenominator, loglikelihoods[N], reversedLogLikelihoods, i);
      numerator *= (1.0 - alphaNumerator);
    }
    delete[] reversedLogLikelihoods;

    if (numerator == 0.0) return 0.0;

    // update denomiator
    double denominatorStar;
    double alphaDenominator = recursiveAlpha(denominatorStar, leaderLoglikelihood, loglikelihoods, N - 1);
    deonominator = denominatorStar * (1.0 - alphaDenominator);

    return std::min(1.0, numerator / deonominator);
  }
}

void MCMC::generateCandidate(size_t sampleIdx)
{
  _proposedSampleCount++;

  if (sampleIdx == 0)
    for (size_t d = 0; d < _k->_variables.size(); ++d) _chainCandidate[sampleIdx][d] = _chainLeader[d];
  else
    for (size_t d = 0; d < _k->_variables.size(); ++d) _chainCandidate[sampleIdx][d] = _chainCandidate[sampleIdx - 1][d];

  if ((_useAdaptiveSampling == false) || (_sampleDatabase.size() <= _nonAdaptionPeriod + _burnIn))
    for (size_t d = 0; d < _k->_variables.size(); ++d)
      for (size_t e = 0; e < _k->_variables.size(); ++e) _chainCandidate[sampleIdx][d] += _choleskyDecompositionCovariance[d * _k->_variables.size() + e] * _normalGenerator->getRandomNumber();
  else
    for (size_t d = 0; d < _k->_variables.size(); ++d)
      for (size_t e = 0; e < _k->_variables.size(); ++e) _chainCandidate[sampleIdx][d] += _choleskyDecompositionChainCovariance[d * _k->_variables.size() + e] * _normalGenerator->getRandomNumber();
}

void MCMC::updateState()
{
  _acceptanceRate = ((double)_acceptanceCount / (double)_chainLength);

  if (_sampleDatabase.size() == 0) return;
  if (_sampleDatabase.size() == 1)
  {
    for (size_t d = 0; d < _k->_variables.size(); d++) _chainMean[d] = _chainLeader[d];
    return;
  }

  for (size_t d = 0; d < _k->_variables.size(); d++)
    for (size_t e = 0; e < d; e++)
    {
      _chainCovariancePlaceholder[d * _k->_variables.size() + e] = (_chainMean[d] - _chainLeader[d]) * (_chainMean[e] - _chainLeader[e]);
      _chainCovariancePlaceholder[e * _k->_variables.size() + d] = (_chainMean[d] - _chainLeader[d]) * (_chainMean[e] - _chainLeader[e]);
    }
  for (size_t d = 0; d < _k->_variables.size(); d++) _chainCovariancePlaceholder[d * _k->_variables.size() + d] = (_chainMean[d] - _chainLeader[d]) * (_chainMean[d] - _chainLeader[d]);

  // Chain Mean
  for (size_t d = 0; d < _k->_variables.size(); d++) _chainMean[d] = (_chainMean[d] * (_sampleDatabase.size() - 1) + _chainLeader[d]) / _sampleDatabase.size();

  for (size_t d = 0; d < _k->_variables.size(); d++)
    for (size_t e = 0; e < d; e++)
    {
      _chainCovariance[d * _k->_variables.size() + e] = (_sampleDatabase.size() - 2.0) / (_sampleDatabase.size() - 1.0) * _chainCovariance[d * _k->_variables.size() + e] + (_chainCovarianceScaling / _sampleDatabase.size()) * _chainCovariancePlaceholder[d * _k->_variables.size() + e];
      _chainCovariance[e * _k->_variables.size() + d] = (_sampleDatabase.size() - 2.0) / (_sampleDatabase.size() - 1.0) * _chainCovariance[d * _k->_variables.size() + e] + (_chainCovarianceScaling / _sampleDatabase.size()) * _chainCovariancePlaceholder[d * _k->_variables.size() + e];
    }
  for (size_t d = 0; d < _k->_variables.size(); d++)
    _chainCovariance[d * _k->_variables.size() + d] = (_sampleDatabase.size() - 2.0) / (_sampleDatabase.size() - 1.0) * _chainCovariance[d * _k->_variables.size() + d] + (_chainCovarianceScaling / _sampleDatabase.size()) * _chainCovariancePlaceholder[d * _k->_variables.size() + d];

  if ((_useAdaptiveSampling == true) && (_sampleDatabase.size() > _nonAdaptionPeriod)) choleskyDecomp(_chainCovariance, _choleskyDecompositionChainCovariance);
}

void MCMC::printGenerationBefore() { return; }

void MCMC::printGenerationAfter()
{
  _k->_logger->logInfo("Minimal", "Database Entries %ld\n", _sampleDatabase.size());

  _k->_logger->logInfo("Normal", "Accepted Samples: %zu\n", _acceptanceCount);
  _k->_logger->logInfo("Normal", "Acceptance Rate Proposals: %.2f%%\n", 100 * _acceptanceRate);

  _k->_logger->logInfo("Detailed", "Current Sample:\n");
  for (size_t d = 0; d < _k->_variables.size(); d++) _k->_logger->logData("Detailed", "         %s = %+6.3e\n", _k->_variables[d]->_name.c_str(), _chainLeader[d]);

  _k->_logger->logInfo("Detailed", "Current Chain Mean:\n");
  for (size_t d = 0; d < _k->_variables.size(); d++) _k->_logger->logData("Detailed", "         %s = %+6.3e\n", _k->_variables[d]->_name.c_str(), _chainMean[d]);
  _k->_logger->logInfo("Detailed", "Current Chain Covariance:\n");
  for (size_t d = 0; d < _k->_variables.size(); d++)
  {
    for (size_t e = 0; e <= d; e++) _k->_logger->logData("Detailed", "         %+6.3e  ", _chainCovariance[d * _k->_variables.size() + e]);
    _k->_logger->logInfo("Detailed", "\n");
  }
}

void MCMC::finalize()
{
  _k->_logger->logInfo("Minimal", "Number of Generated Samples: %zu\n", _proposedSampleCount);
  _k->_logger->logInfo("Minimal", "Acceptance Rate: %.2f%%\n", 100 * _acceptanceRate);
  if (_sampleDatabase.size() == _maxSamples) _k->_logger->logInfo("Minimal", "Max Samples Reached.\n");
  (*_k)["Results"]["Sample Database"] = _sampleDatabase;
}

} // namespace sampler

} // namespace solver

} // namespace korali
