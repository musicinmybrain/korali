#include "modules/experiment/experiment.hpp"
#include "modules/neuralNetwork/neuralNetwork.hpp"

#ifdef _KORALI_USE_ONEDNN
  #include "auxiliar/dnnUtils.hpp"
using namespace dnnl;
#endif

/********************************************
 * Pending Performance Improvements
 * - Make sure all operations are made on memory objects with format_tag::any, reordered by oneDNN during creation.
 *   This guarantees that the best memory landscape is selected for all these operations
 * - Do not reserve memory nor create/execute primitives for differentiation when just inferring
 * - Use prop_kind::forward_inference always when inferring
 * - Some memory structures can be re-used (instead of having a separate diff vector, reuse the data vector)
 ********************************************/

namespace korali
{
NeuralNetwork::NeuralNetwork()
{
  _isInitialized = false;
}

void NeuralNetwork::initialize()
{
#ifndef _KORALI_USE_ONEDNN

  KORALI_LOG_ERROR("OneDNN has not been properly installed to support NN operations.\n");

#endif

  if (_isInitialized)
    KORALI_LOG_ERROR("Neural Network has already been initialized!.\n");

#ifdef _KORALI_USE_ONEDNN

  // Initializing Engine and stream

  if (_engineKind == "CPU") _engine = engine(engine::kind::cpu, 0);
  if (_engineKind == "GPU") _engine = engine(engine::kind::gpu, 0);

  _stream = stream(_engine);

#endif

  // Checking if batch size if correct
  if (_batchSize == 0) KORALI_LOG_ERROR("You should provide an input batch size larger than zero.\n");

  // Creating layer chain
  ssize_t layerCount = _layers.size();
  _layers[0]->_prevLayer = NULL;
  for (ssize_t i = 1; i < layerCount; i++) _layers[i]->_prevLayer = _layers[i-1];

  _layers[layerCount-1]->_nextLayer = NULL;
  for (ssize_t i = layerCount-2; i >= 0; i--) _layers[i]->_nextLayer = _layers[i+1];

  // Creating forward-propagation pipeline
  createForwardPipeline();

  // Creating backward-propagation pipeline
  createBackwardPipeline();

  // Configuration required for when we use normalization
  // If we use batch normalization, we set bias to zero
  for (size_t i = 1; i < _layers.size(); i++)
    if (_layers[i]->_batchNormalizationEnabled)
    {
      std::vector<float> biasData(_layers[i]->_nodeCount, 0.0);
      write_to_dnnl_memory(biasData.data(), _layers[i]->_biasMem);
    }

  // If we use batch normalization, we set mean and variances to neutral values
  std::vector<double> meanData(_normalizationParameterCount, 0.0);
  std::vector<double> varianceData(_normalizationParameterCount, 1.0);

  setNormalizationMeans(meanData);
  setNormalizationVariances(varianceData);

  // Making sure we do not re-initialize
  _isInitialized = true;
}

std::vector<double> NeuralNetwork::generateInitialHyperparameters()
{
  // Setting initial values for hyperparameters
  std::vector<double> initialHyperparameters;

  for (size_t i = 0; i < _layers.size(); i++)
  {
   auto layerParameters = _layers[i]->generateInitialHyperparameters();
   initialHyperparameters.insert(initialHyperparameters.begin(), layerParameters.begin(), layerParameters.end());
  }

  return initialHyperparameters;
}

void NeuralNetwork::createForwardPipeline()
{
#ifdef _KORALI_USE_ONEDNN

  /****************************************************************************
    * Checking input/output configuration
    ****************************************************************************/

  // Obtaining NN dimensions
  size_t layerCount = _layers.size();
  memory::dim N = _batchSize;

  // Checking Layer sizes
  for (size_t i = 0; i < layerCount; i++)
    if (_layers[i]->_nodeCount == 0)
      KORALI_LOG_ERROR("Node count for layer (%lu) should be larger than zero.\n", i);

  /*********************************************************************************
  *  Initializing memory objects and primitives for FORWARD propagation
  *********************************************************************************/

  // Creating layer's data memory storage and activation function
  for (size_t i = 0; i < layerCount; i++)
  {
    const memory::dim OC = _layers[i]->_nodeCount;
    const memory::dims layerDims = {N, OC};
    auto dataMemDesc = memory::desc(layerDims, memory::data_type::f32, memory::format_tag::ab);
    _layers[i]->_nodeMem = memory(dataMemDesc, _engine);
    _layers[i]->_activationMem = memory(dataMemDesc, _engine);
    if (_layers[i]->_batchNormalizationEnabled) _layers[i]->_batchNormalizationMem = memory(dataMemDesc, _engine);

    /*****************************************
    * Creating Activation Function primitive and memory
    * ***************************************/

    if (_layers[i]->_activationFunctionType == "Clip") _layers[i]->_activationAlgorithm = algorithm::eltwise_clip;
    if (_layers[i]->_activationFunctionType == "Linear") _layers[i]->_activationAlgorithm = algorithm::eltwise_linear;
    if (_layers[i]->_activationFunctionType == "Log") _layers[i]->_activationAlgorithm = algorithm::eltwise_log;
    if (_layers[i]->_activationFunctionType == "ReLU") _layers[i]->_activationAlgorithm = algorithm::eltwise_relu;
    if (_layers[i]->_activationFunctionType == "Tanh") _layers[i]->_activationAlgorithm = algorithm::eltwise_tanh;
    if (_layers[i]->_activationFunctionType == "Logistic") _layers[i]->_activationAlgorithm = algorithm::eltwise_logistic;

    float alpha = _layers[i]->_activationFunctionAlpha;
    float beta = _layers[i]->_activationFunctionBeta;

    // Creating descriptor
    auto activationDesc = eltwise_forward::desc(prop_kind::forward_training, _layers[i]->_activationAlgorithm, _layers[i]->_nodeMem.get_desc(), alpha, beta);

    // Create primitive descriptor.
    _layers[i]->_forwardActivationPrimitiveDesc = eltwise_forward::primitive_desc(activationDesc, _engine);

    // Create the primitive.
    _layers[i]->_forwardActivationPrimitive = eltwise_forward(_layers[i]->_forwardActivationPrimitiveDesc);

    // Primitive arguments.
    if (_layers[i]->_batchNormalizationEnabled)
      _layers[i]->_forwardActivationArgs.insert({DNNL_ARG_SRC, _layers[i]->_batchNormalizationMem});
    else
      _layers[i]->_forwardActivationArgs.insert({DNNL_ARG_SRC, _layers[i]->_nodeMem});

    _layers[i]->_forwardActivationArgs.insert({DNNL_ARG_DST, _layers[i]->_activationMem});
  }

  // Starting to count hyperparameters and normalization parameters
  _hyperparameterCount = 0;
  _normalizationParameterCount = 0;

  // Initializing Wx+b Operation (also called inner product in oneDNN)
  for (size_t i = 1; i < layerCount; i++)
  {
    // Defining memory sizes
    const memory::dim IC = _layers[i - 1]->_nodeCount;
    const memory::dim OC = _layers[i]->_nodeCount;
    memory::dims weightDims = {OC, IC};

    // Adding these weights hyperparameters to the count
    _hyperparameterCount += IC * OC;

    // Allocating weight memory
    auto weightMemDesc = memory::desc(weightDims, memory::data_type::f32, memory::format_tag::ab);
    _layers[i]->_weightsMem = memory(weightMemDesc, _engine);
    _layers[i]->_weightsWorkMem = _layers[i]->_weightsMem;

    // Allocating weight work memory with format::any for oneDNN to decide the best layour
    auto weightsWorkMemDesc = memory::desc(weightDims, memory::data_type::f32, memory::format_tag::any);

    // Allocating bias memory
    auto biasMemDesc = memory::desc({OC}, memory::data_type::f32, memory::format_tag::a);
    _layers[i]->_biasMem = memory(biasMemDesc, _engine);

    // Adding bias hyperparameters to the count if not using normalization
    if (_layers[i]->_batchNormalizationEnabled == false) _hyperparameterCount += OC;

    // Create operation descriptor.
    auto inner_product_d = inner_product_forward::desc(prop_kind::forward_training, _layers[i - 1]->_activationMem.get_desc(), weightsWorkMemDesc, biasMemDesc, _layers[i]->_nodeMem.get_desc());

    // Create inner product primitive descriptor.
    dnnl::primitive_attr forwardPrimitiveAttributes;
    _layers[i]->_forwardInnerProductPrimitiveDesc = inner_product_forward::primitive_desc(inner_product_d, forwardPrimitiveAttributes, _engine);

    // If oneDNN ultimately decided to use a different layout for weight work memory, then use it
    if (_layers[i]->_weightsWorkMem.get_desc() != _layers[i]->_forwardInnerProductPrimitiveDesc.weights_desc())
      _layers[i]->_weightsWorkMem = memory(_layers[i]->_forwardInnerProductPrimitiveDesc.weights_desc(), _engine);

    // Create the weights+bias primitive.
    _layers[i]->_forwardInnerProductPrimitive = inner_product_forward(_layers[i]->_forwardInnerProductPrimitiveDesc);

    // Configuring inner product arguments
    _layers[i]->_forwardInnerProductArgs.insert({DNNL_ARG_SRC, _layers[i - 1]->_activationMem});
    _layers[i]->_forwardInnerProductArgs.insert({DNNL_ARG_WEIGHTS, _layers[i]->_weightsWorkMem});
    _layers[i]->_forwardInnerProductArgs.insert({DNNL_ARG_BIAS, _layers[i]->_biasMem});
    _layers[i]->_forwardInnerProductArgs.insert({DNNL_ARG_DST, _layers[i]->_nodeMem});
  }

  // Initializing forward layer normalization operations
  for (size_t i = 0; i < layerCount; i++)
    if (_layers[i]->_batchNormalizationEnabled)
    {
      const memory::dim OC = _layers[i]->_nodeCount;
      memory::dims scale_shift_dims = {2, OC};

      // Adding normalization scale/shift hyperparameters to the count
      _hyperparameterCount += 2 * OC;
      _normalizationParameterCount += OC;

      // Allocating normalization scale/shift memory structure
      auto normalizationMemDesc = memory::desc(scale_shift_dims, memory::data_type::f32, memory::format_tag::nc);
      _layers[i]->_batchNormalizationScaleShiftMem = memory(normalizationMemDesc, _engine);

      auto normalizationFlags = normalization_flags::use_scale_shift;

      // If mean and variances are defined, then normalize with respect to them
      if (_usePreloadedNormalizationData)
        normalizationFlags |= normalization_flags::use_global_stats;

      // Create operation descriptor.
      auto forwardNormalizationDesc = batch_normalization_forward::desc(prop_kind::forward_training, _layers[i]->_nodeMem.get_desc(), _layers[i]->_batchNormalizationEpsilon, normalizationFlags);

      // Create inner product primitive descriptor.
      _layers[i]->_forwardNormalizationPrimitiveDesc = batch_normalization_forward::primitive_desc(forwardNormalizationDesc, _engine);

      // Creating mean and variance mem structures
      _layers[i]->_batchNormalizationMeanMem = memory(_layers[i]->_forwardNormalizationPrimitiveDesc.mean_desc(), _engine);
      _layers[i]->_batchNormalizationVarianceMem = memory(_layers[i]->_forwardNormalizationPrimitiveDesc.variance_desc(), _engine);
      _layers[i]->_batchNormalizationWorkMem = memory(_layers[i]->_forwardNormalizationPrimitiveDesc.workspace_desc(), _engine);

      // Create the normalization primitive.
      _layers[i]->_forwardNormalizationPrimitive = batch_normalization_forward(_layers[i]->_forwardNormalizationPrimitiveDesc);

      // Configuring inner product arguments
      _layers[i]->_forwardNormalizationArgs.insert({DNNL_ARG_SRC, _layers[i]->_nodeMem});                                 // Input
      _layers[i]->_forwardNormalizationArgs.insert({DNNL_ARG_SCALE_SHIFT, _layers[i]->_batchNormalizationScaleShiftMem}); // Input
      _layers[i]->_forwardNormalizationArgs.insert({DNNL_ARG_MEAN, _layers[i]->_batchNormalizationMeanMem});              // Output
      _layers[i]->_forwardNormalizationArgs.insert({DNNL_ARG_VARIANCE, _layers[i]->_batchNormalizationVarianceMem});      // Output
      _layers[i]->_forwardNormalizationArgs.insert({DNNL_ARG_WORKSPACE, _layers[i]->_batchNormalizationWorkMem});         // Output
      _layers[i]->_forwardNormalizationArgs.insert({DNNL_ARG_DST, _layers[i]->_batchNormalizationMem});                   // Output
    }

#endif
}

void NeuralNetwork::createBackwardPipeline()
{
  /*********************************************************************************
  *  Initializing memory objects and primitives for BACKWARD propagation
  *********************************************************************************/

#ifdef _KORALI_USE_ONEDNN

  size_t layerCount = _layers.size();
  const memory::dim N = _batchSize;

  // Creating layer's gradient memory storage
  for (size_t i = 0; i < layerCount; i++)
  {
    const memory::dim OC = _layers[i]->_nodeCount; // Output Channels

    // Creating data-related gradient memory
    const memory::dims layerDims = {N, OC};
    auto dataDiffMemDesc = memory::desc(layerDims, memory::data_type::f32, memory::format_tag::ab);
    _layers[i]->_nodeDiffMem = memory(dataDiffMemDesc, _engine);
    _layers[i]->_batchNormalizationDiffMem = memory(dataDiffMemDesc, _engine);
    _layers[i]->_activationDiffMem = memory(dataDiffMemDesc, _engine);

    // Creating normalization-related gradient memory
    if (_layers[i]->_batchNormalizationEnabled)
    {
      const memory::dims normalizationDims = {2, OC};
      auto dataDiffMemDesc = memory::desc(normalizationDims, memory::data_type::f32, memory::format_tag::ab);
      _layers[i]->_batchNormalizationScaleShiftDiffMem = memory(dataDiffMemDesc, _engine);
    }

    // Creating weight-related gradient memory
    if (i > 0)
    {
      // Allocating bias gradient memory
      const memory::dims biasDims = {OC};
      auto biasMemDesc = memory::desc(biasDims, memory::data_type::f32, memory::format_tag::a);
      _layers[i]->_biasDiffMem = memory(biasMemDesc, _engine);

      // Creating weights gradient memory
      const memory::dim IC = _layers[i - 1]->_nodeCount; // Input Channels
      memory::dims weightDiffDims = {OC, IC};
      auto weightDiffMemDesc = memory::desc(weightDiffDims, memory::data_type::f32, memory::format_tag::ab);
      _layers[i]->_weightsDiffMem = memory(weightDiffMemDesc, _engine);
    }
  }

  // Creating the backward propagation operations
  for (ssize_t i = layerCount - 1; i >= 0; i--)
  {
    // Creating backward propagation primitives for activation functions
    float alpha = _layers[i]->_activationFunctionAlpha;
    float beta = _layers[i]->_activationFunctionBeta;

    // Creating descriptor
    auto activationDesc = eltwise_backward::desc(_layers[i]->_activationAlgorithm, _layers[i]->_nodeMem.get_desc(), _layers[i]->_activationMem.get_desc(), alpha, beta);

    // Create primitive descriptor.
    auto backwardActivationPrimitiveDesc = eltwise_backward::primitive_desc(activationDesc, _engine, _layers[i]->_forwardActivationPrimitiveDesc);

    // Create the primitive.
    _layers[i]->_backwardActivationPrimitive = eltwise_backward(backwardActivationPrimitiveDesc);

    // Primitive arguments.
    if (_layers[i]->_batchNormalizationEnabled)
      _layers[i]->_backwardActivationArgs.insert({DNNL_ARG_SRC, _layers[i]->_batchNormalizationMem}); // Input
    else
      _layers[i]->_backwardActivationArgs.insert({DNNL_ARG_SRC, _layers[i]->_nodeMem}); // Input

    _layers[i]->_backwardActivationArgs.insert({DNNL_ARG_DIFF_DST, _layers[i]->_activationDiffMem}); // Input

    if (_layers[i]->_batchNormalizationEnabled)
      _layers[i]->_backwardActivationArgs.insert({DNNL_ARG_DIFF_SRC, _layers[i]->_batchNormalizationDiffMem}); // Output
    else
      _layers[i]->_backwardActivationArgs.insert({DNNL_ARG_DIFF_SRC, _layers[i]->_nodeDiffMem}); // Output

    // We do not define the following primitives for the first layer
    if (i > 0)
    {
      auto backwardDataDesc = inner_product_backward_data::desc(
        _layers[i - 1]->_nodeDiffMem.get_desc(),
        _layers[i]->_weightsWorkMem.get_desc(),
        _layers[i]->_nodeMem.get_desc());

      // Create the primitive.
      auto backwardDataPrimitiveDesc = inner_product_backward_data::primitive_desc(backwardDataDesc, _engine, _layers[i]->_forwardInnerProductPrimitiveDesc);
      _layers[i]->_backwardDataPrimitive = inner_product_backward_data(backwardDataPrimitiveDesc);

      _layers[i]->_backwardDataArgs.insert({DNNL_ARG_DIFF_DST, _layers[i]->_nodeDiffMem});           // Input
      _layers[i]->_backwardDataArgs.insert({DNNL_ARG_WEIGHTS, _layers[i]->_weightsWorkMem});         // Input
      _layers[i]->_backwardDataArgs.insert({DNNL_ARG_DIFF_SRC, _layers[i - 1]->_activationDiffMem}); // Output

      auto backwardWeightsDesc = inner_product_backward_weights::desc(
        _layers[i - 1]->_nodeMem.get_desc(),
        _layers[i]->_weightsMem.get_desc(),
        _layers[i]->_biasMem.get_desc(),
        _layers[i]->_nodeDiffMem.get_desc());

      // Create the primitive.
      auto backwardWeightsPrimitiveDesc = inner_product_backward_weights::primitive_desc(backwardWeightsDesc, _engine, _layers[i]->_forwardInnerProductPrimitiveDesc);
      _layers[i]->_backwardWeightsPrimitive = inner_product_backward_weights(backwardWeightsPrimitiveDesc);

      _layers[i]->_backwardWeightsArgs.insert({DNNL_ARG_SRC, _layers[i - 1]->_activationMem});       // Input
      _layers[i]->_backwardWeightsArgs.insert({DNNL_ARG_DIFF_DST, _layers[i]->_nodeDiffMem});        // Input
      _layers[i]->_backwardWeightsArgs.insert({DNNL_ARG_DIFF_WEIGHTS, _layers[i]->_weightsDiffMem}); // Output
      _layers[i]->_backwardWeightsArgs.insert({DNNL_ARG_DIFF_BIAS, _layers[i]->_biasDiffMem});       // Output
    }

    // Initializing backward layer normalization operations
    if (_layers[i]->_batchNormalizationEnabled)
    {
      auto backwardNormalizationDesc = batch_normalization_backward::desc(
        prop_kind::backward,
        _layers[i]->_nodeDiffMem.get_desc(),
        _layers[i]->_nodeMem.get_desc(),
        _layers[i]->_batchNormalizationEpsilon,
        normalization_flags::use_scale_shift);

      // Create the primitive.
      auto normalizationPrimitiveDesc = batch_normalization_backward::primitive_desc(backwardNormalizationDesc, _engine, _layers[i]->_forwardNormalizationPrimitiveDesc);
      _layers[i]->_backwardNormalizationPrimitive = batch_normalization_backward(normalizationPrimitiveDesc);

      _layers[i]->_backwardNormalizationArgs.insert({DNNL_ARG_SRC, _layers[i]->_nodeMem});                                          // Input
      _layers[i]->_backwardNormalizationArgs.insert({DNNL_ARG_DIFF_DST, _layers[i]->_batchNormalizationDiffMem});                   // Input
      _layers[i]->_backwardNormalizationArgs.insert({DNNL_ARG_MEAN, _layers[i]->_batchNormalizationMeanMem});                       // Input
      _layers[i]->_backwardNormalizationArgs.insert({DNNL_ARG_VARIANCE, _layers[i]->_batchNormalizationVarianceMem});               // Input
      _layers[i]->_backwardNormalizationArgs.insert({DNNL_ARG_SCALE_SHIFT, _layers[i]->_batchNormalizationScaleShiftMem});          // Input
      _layers[i]->_backwardNormalizationArgs.insert({DNNL_ARG_DIFF_SRC, _layers[i]->_nodeDiffMem});                                 // Output
      _layers[i]->_backwardNormalizationArgs.insert({DNNL_ARG_DIFF_SCALE_SHIFT, _layers[i]->_batchNormalizationScaleShiftDiffMem}); // Output
    }
  }

#endif
}

void NeuralNetwork::setInput(const std::vector<std::vector<double>> &input)
{
  size_t inputSize = _layers[0]->_nodeCount;

  // Checking input
  if (input.size() != _batchSize)
    KORALI_LOG_ERROR("Input data set has a different batch size (%lu) than the one for which the NN was created for (%lu).\n", input.size(), _batchSize);

  for (size_t i = 0; i < input.size(); i++)
    if (input[i].size() != inputSize)
      KORALI_LOG_ERROR("Input data set %lu has a different number of elements (%lu) than the input layer node count (%lu).\n", i, input[i].size(), inputSize);

  // Copying input data to first layer
  std::vector<float> batchInput(_batchSize * inputSize);
  for (size_t i = 0; i < _batchSize; i++)
    for (size_t j = 0; j < inputSize; j++)
      batchInput[i * inputSize + j] = input[i][j];

  write_to_dnnl_memory(batchInput.data(), _layers[0]->_nodeMem);
}

void NeuralNetwork::setHyperparameters(const std::vector<double> &hyperparameters)
{
#ifdef _KORALI_USE_ONEDNN

  if (hyperparameters.size() != _hyperparameterCount)
    KORALI_LOG_ERROR("Wrong number of hyperparameters passed to the neural network. Expected: %lu, provided: %lu.\n", _hyperparameterCount, hyperparameters.size());

  // Creating single precision floating-point version of the hyperparameters
  auto fParams = std::vector<float>(hyperparameters.begin(), hyperparameters.end());

  size_t layerCount = _layers.size();
  size_t currPos = 0;
  for (size_t i = 0; i < layerCount; i++)
  {
    const memory::dim IC = _layers[i - 1]->_nodeCount;
    const memory::dim OC = _layers[i]->_nodeCount;

    if (i > 0)
    {
      // Setting weight data to the layer's weight memory
      write_to_dnnl_memory(&fParams[currPos], _layers[i]->_weightsMem);
      currPos += IC * OC;

      // Copying weight mem to weight work mem, if they are not the same
      if (_layers[i]->_weightsMem.get_desc() != _layers[i]->_weightsWorkMem.get_desc())
        reorder(_layers[i]->_weightsMem, _layers[i]->_weightsWorkMem).execute(_stream, _layers[i]->_weightsMem, _layers[i]->_weightsWorkMem);

      // Setting weight data to the layer's weight memory, only if batch normalization is not being used
      if (_layers[i]->_batchNormalizationEnabled == false)
      {
        write_to_dnnl_memory(&fParams[currPos], _layers[i]->_biasMem);
        currPos += OC;
      }
    }

    // If layer normalization is enabled, we fill in scale/shift data
    if (_layers[i]->_batchNormalizationEnabled == true)
    {
      write_to_dnnl_memory(&fParams[currPos], _layers[i]->_batchNormalizationScaleShiftMem);
      currPos += 2 * OC;
    }
  }

#endif
}

std::vector<double> NeuralNetwork::getHyperparameters()
{
  // Creating single precision floating-point version of the hyperparameters
  auto fParams = std::vector<float>(_hyperparameterCount);

#ifdef _KORALI_USE_ONEDNN

  size_t layerCount = _layers.size();
  size_t currPos = 0;
  for (size_t i = 0; i < layerCount; i++)
  {
    const memory::dim IC = _layers[i - 1]->_nodeCount;
    const memory::dim OC = _layers[i]->_nodeCount;

    // Setting weight data to the layer's weight memory
    if (i > 0)
    {
      read_from_dnnl_memory(&fParams[currPos], _layers[i]->_weightsMem);
      currPos += IC * OC;

      // Setting weight data to the layer's weight memory, only if batch normalization is not being used
      if (_layers[i]->_batchNormalizationEnabled == false)
      {
        read_from_dnnl_memory(&fParams[currPos], _layers[i]->_biasMem);
        currPos += OC;
      }
    }

    // If layer normalization is enabled, we fill in scale/shift data
    if (_layers[i]->_batchNormalizationEnabled == true)
    {
      read_from_dnnl_memory(&fParams[currPos], _layers[i]->_batchNormalizationScaleShiftMem);
      currPos += 2 * OC;
    }
  }

#endif

  // Returning the hyperparameters converted to double-precision
  return std::vector<double>(fParams.begin(), fParams.end());
}

std::vector<double> NeuralNetwork::getHyperparameterGradients(const std::vector<double> &outputDifferential)
{
  // Converting input to float, for oneDNN to use
  std::vector<float> floatDiffs(outputDifferential.begin(), outputDifferential.end());

  // Running backward propagation
  size_t layerCount = _layers.size();
  size_t lastLayer = layerCount - 1;

  // Writing to last layers differential information wrt data
  write_to_dnnl_memory(floatDiffs.data(), _layers[lastLayer]->_activationDiffMem);

  // Backward propagating neural network
  for (ssize_t i = lastLayer; i >= 0; i--)
  {
    _layers[i]->_backwardActivationPrimitive.execute(_stream, _layers[i]->_backwardActivationArgs);
    if (_layers[i]->_batchNormalizationEnabled) _layers[i]->_backwardNormalizationPrimitive.execute(_stream, _layers[i]->_backwardNormalizationArgs);

    if (i > 0)
    {
      _layers[i]->_backwardDataPrimitive.execute(_stream, _layers[i]->_backwardDataArgs);
      _layers[i]->_backwardWeightsPrimitive.execute(_stream, _layers[i]->_backwardWeightsArgs);
    }
  }

  // Wait for the computation to finalize.
  _stream.wait();

  // Copying back the gradients and biases back
  std::vector<float> gradientVectorFloat(_hyperparameterCount);

  // Retrieving hyperparameter gradients
  size_t currPos = 0;
  for (size_t i = 0; i < layerCount; i++)
  {
    const memory::dim IC = _layers[i - 1]->_nodeCount;
    const memory::dim OC = _layers[i]->_nodeCount;

    if (i > 0)
    {
      // Reading weight gradients
      read_from_dnnl_memory(&gradientVectorFloat[currPos], _layers[i]->_weightsDiffMem);
      currPos += OC * IC;

      // If not using layer normalization, we get the bias gradients
      if (_layers[i]->_batchNormalizationEnabled == false)
      {
        read_from_dnnl_memory(&gradientVectorFloat[currPos], _layers[i]->_biasDiffMem);
        currPos += OC;
      }
    }

    // If using layer normalization, we get normalization gradients
    if (_layers[i]->_batchNormalizationEnabled == true)
    {
      read_from_dnnl_memory(&gradientVectorFloat[currPos], _layers[i]->_batchNormalizationScaleShiftDiffMem);
      currPos += 2 * OC;
    }
  }

  // Getting the double version of the gradient vector
  std::vector<double> gradientVector(gradientVectorFloat.begin(), gradientVectorFloat.end());

  return gradientVector;
}

std::vector<double> NeuralNetwork::getNormalizationMeans()
{
  // Creating single precision floating-point version of the hyperparameters
  auto fParams = std::vector<float>(_normalizationParameterCount);

#ifdef _KORALI_USE_ONEDNN

  size_t layerCount = _layers.size();
  size_t currPos = 0;
  for (size_t i = 0; i < layerCount; i++)
    if (_layers[i]->_batchNormalizationEnabled == true)
    {
      const memory::dim OC = _layers[i]->_nodeCount;
      read_from_dnnl_memory(&fParams[currPos], _layers[i]->_batchNormalizationMeanMem);
      currPos += OC;
    }

#endif

  // Returning the hyperparameters converted to double-precision
  return std::vector<double>(fParams.begin(), fParams.end());
}

void NeuralNetwork::setNormalizationMeans(const std::vector<double> &normalizationMeans)
{
#ifdef _KORALI_USE_ONEDNN

  if (normalizationMeans.size() != _normalizationParameterCount)
    KORALI_LOG_ERROR("Wrong number of normalization parameters passed to the neural network. Expected: %lu, provided: %lu.\n", _normalizationParameterCount, normalizationMeans.size());

  // Creating single precision floating-point version of the normalization parameters
  auto fParams = std::vector<float>(normalizationMeans.begin(), normalizationMeans.end());

  size_t layerCount = _layers.size();
  size_t currPos = 0;
  for (size_t i = 0; i < layerCount; i++)
    if (_layers[i]->_batchNormalizationEnabled == true)
    {
      const memory::dim OC = _layers[i]->_nodeCount;
      write_to_dnnl_memory(&fParams[currPos], _layers[i]->_batchNormalizationMeanMem);
      currPos += OC;
    }

#endif
}

std::vector<double> NeuralNetwork::getNormalizationVariances()
{
  // Creating single precision floating-point version of the hyperparameters
  auto fParams = std::vector<float>(_normalizationParameterCount);

#ifdef _KORALI_USE_ONEDNN

  size_t layerCount = _layers.size();
  size_t currPos = 0;
  for (size_t i = 0; i < layerCount; i++)
    if (_layers[i]->_batchNormalizationEnabled == true)
    {
      const memory::dim OC = _layers[i]->_nodeCount;
      read_from_dnnl_memory(&fParams[currPos], _layers[i]->_batchNormalizationVarianceMem);
      currPos += OC;
    }

#endif

  // Returning the hyperparameters converted to double-precision
  return std::vector<double>(fParams.begin(), fParams.end());
}

void NeuralNetwork::setNormalizationVariances(const std::vector<double> &normalizationVariances)
{
#ifdef _KORALI_USE_ONEDNN

  if (normalizationVariances.size() != _normalizationParameterCount)
    KORALI_LOG_ERROR("Wrong number of normalization parameters passed to the neural network. Expected: %lu, provided: %lu.\n", _normalizationParameterCount, normalizationVariances.size());

  // Creating single precision floating-point version of the normalization parameters
  auto fParams = std::vector<float>(normalizationVariances.begin(), normalizationVariances.end());

  size_t layerCount = _layers.size();
  size_t currPos = 0;
  for (size_t i = 0; i < layerCount; i++)
    if (_layers[i]->_batchNormalizationEnabled == true)
    {
      const memory::dim OC = _layers[i]->_nodeCount;
      write_to_dnnl_memory(&fParams[currPos], _layers[i]->_batchNormalizationVarianceMem);
      currPos += OC;
    }

#endif
}

void NeuralNetwork::forward()
{
#ifdef _KORALI_USE_ONEDNN

  size_t layerCount = _layers.size();

  // forward propagating neural network
  for (size_t i = 0; i < layerCount; i++)
  {
    if (i > 0) _layers[i]->_forwardInnerProductPrimitive.execute(_stream, _layers[i]->_forwardInnerProductArgs);
    if (_layers[i]->_batchNormalizationEnabled) _layers[i]->_forwardNormalizationPrimitive.execute(_stream, _layers[i]->_forwardNormalizationArgs);
    _layers[i]->_forwardActivationPrimitive.execute(_stream, _layers[i]->_forwardActivationArgs);
  }

  // Wait for the computation to finalize.
  _stream.wait();

  // Restoring the output later node values
  size_t lastLayer = layerCount - 1;
  size_t nodeCount = _layers[lastLayer]->_nodeCount;
  std::vector<float> resultData(_batchSize * nodeCount);
  read_from_dnnl_memory(resultData.data(), _layers[lastLayer]->_activationMem);

  _outputValues.resize(_batchSize);
  for (size_t i = 0; i < _batchSize; i++)
  {
    _outputValues[i].resize(nodeCount);
    for (size_t j = 0; j < nodeCount; j++)
      _outputValues[i][j] = resultData[i * nodeCount + j];
  }

#endif
}

void NeuralNetwork::backwardData(std::vector<float> &outputDifferential)
{
#ifdef _KORALI_USE_ONEDNN

  size_t layerCount = _layers.size();
  size_t lastLayer = layerCount - 1;

  auto outputBatchSize = _layers[lastLayer]->_nodeCount * _batchSize;
  if (outputDifferential.size() != outputBatchSize)
    KORALI_LOG_ERROR("Incorrect size of output differential provided. Given: %lu, Expected: %lu. \n", outputDifferential.size(), outputBatchSize);

  // Writing to last layers differential information wrt data
  write_to_dnnl_memory(outputDifferential.data(), _layers[lastLayer]->_activationDiffMem);

  // Backward propagating neural network
  for (ssize_t i = lastLayer; i >= 0; i--)
  {
    _layers[i]->_backwardActivationPrimitive.execute(_stream, _layers[i]->_backwardActivationArgs);
    if (_layers[i]->_batchNormalizationEnabled) _layers[i]->_backwardNormalizationPrimitive.execute(_stream, _layers[i]->_backwardNormalizationArgs);
    if (i > 0) _layers[i]->_backwardDataPrimitive.execute(_stream, _layers[i]->_backwardDataArgs);
  }

  // Wait for the computation to finalize.
  _stream.wait();

  // Retreiving gradient of the input
  size_t inputSize = _layers[0]->_nodeCount;
  std::vector<float> dataDiff(_batchSize * inputSize);

  if (_layers[0]->_batchNormalizationEnabled)
    read_from_dnnl_memory(dataDiff.data(), _layers[0]->_batchNormalizationDiffMem);
  else
    read_from_dnnl_memory(dataDiff.data(), _layers[0]->_nodeDiffMem);

  _inputGradient.resize(_batchSize);
  for (size_t i = 0; i < _batchSize; i++)
  {
    _inputGradient[i].resize(inputSize);
    for (size_t j = 0; j < inputSize; j++)
      _inputGradient[i][j] = dataDiff[i * inputSize + j];
  }

#endif
}

} // namespace korali
