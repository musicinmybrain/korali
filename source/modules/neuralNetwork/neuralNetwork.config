{

 "Configuration Settings":
 [
   { 
    "Name": [ "Engine Kind" ],
    "Type": "std::string",
    "Options": [
                { "Value": "CPU", "Description": "Uses the host CPU processor." },
                { "Value": "GPU", "Description": "Uses the host GPU device." }
               ],
    "Description": "Indicates which processor to use for NN operations."
   },
   {
    "Name": [ "Layers" ],
    "Type": "std::vector<korali::neuralNetwork::Layer*>", 
    "Description": "Complete description of the NN's layers."
   },
   {
    "Name": [ "Use Preloaded Normalization Data" ],
    "Type": "bool",
    "Description": "Specifies whether the mean and variance for each layer is given, or calculated upon normalization."
   },
   {
    "Name": [ "Output Scaling" ],
    "Type": "std::vector<double>", 
    "Description": "Gives a scaling factor for each of the output values of the NN."
   },
   {
    "Name": [ "Output Shift" ],
    "Type": "std::vector<double>", 
    "Description": "Shifts the output of the NN by the values given."
   }
 ],

 "Internal Settings": 
 [
   {
    "Name": [ "Current Training Loss" ],
    "Type": "double",
    "Description": "Current value of the training loss."
   },
   {  
    "Name": [ "Output Values" ],
    "Type": "std::vector<std::vector<double>>",
    "Description": "Stores a batch of values for the NN's output."
   },
   {
    "Name": [ "Xavier Generator" ],
    "Type": "korali::distribution::univariate::Uniform*",
    "Description": "Uniform random number generator for setting the initial value of the weights and biases based on the Xavier algorithm."
   },
   {
    "Name": [ "Batch Size" ],
    "Type": "size_t",
    "Description": "Remembers the number of input sets will provided as input batch."
   }
 ],
 
 "Module Defaults": 
 { 
    "Engine Kind": "CPU",
    "Input Values": [ ],
    "Xavier Generator":
    {
     "Type": "Univariate/Uniform",
     "Minimum": -1.0,
     "Maximum": 1.0
    },
   "Output Scaling": [ ],
   "Output Shift": [ ],  
   "Use Preloaded Normalization Data": false
 }
 
}
