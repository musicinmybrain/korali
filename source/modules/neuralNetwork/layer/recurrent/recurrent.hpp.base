@startIncludeGuard

#include "modules/neuralNetwork/layer/layer.hpp"

@startNamespace

class @className : public @parentClassName
{
  public:
  /**
  * @brief Indicates the number of recurrent gates (depends on the architecture)
  */
  size_t _gateCount;

#ifdef _KORALI_USE_ONEDNN

  /**
 * @brief oneDNN Memory object descriptor to contain the hidden state of the recurrent layer -- vector, one per timestep
 */
  std::vector<dnnl::memory> _hiddenStateMem;

  /**
  * @brief oneDNN Memory object descriptor to contain the gradients of the hidden state of the recurrent layer -- vector, one per timestep
  */
  std::vector<dnnl::memory> _hiddenStateGradientMem;

  /**
  * @brief oneDNN Memory object descriptor to contain a null source input hidden state
  */
  dnnl::memory _nullStateInputMem;

  /**
  * @brief oneDNN Memory object descriptor to contain a null source output hidden state
  */
  dnnl::memory _nullStateOutputMem;

  /**
  * @brief oneDNN Memory object descriptor to contain the weights of to apply to the input
  */
  dnnl::memory _weightsLayerMem;

  /**
  * @brief oneDNN Memory object descriptor to contain the gradients of the weights of to apply to the input
  */
  dnnl::memory _weightsLayerGradientMem;

  /**
   * @brief oneDNN Memory object descriptor to contain the weights of to apply to the recurrent gate
   */
  dnnl::memory _weightsRecurrentMem;

  /**
   * @brief oneDNN Memory object descriptor to contain the gradients of the weights of to apply to the recurrent gate
   */
  dnnl::memory _weightsRecurrentGradientMem;

  /**
  * @brief oneDNN Memory object descriptor to contain the bias to apply to the input
  */
  dnnl::memory _biasMem;

  /**
  * @brief oneDNN Memory object descriptor to contain the gradients of the bias to apply to the input
  */
  dnnl::memory _biasGradientMem;

  /**
  * @brief oneDNN Memory object descriptor to contain the workspace
  */
  std::vector<dnnl::memory> _workspaceMem;

#endif

#ifdef _KORALI_USE_CUDNN

  /**
   * @brief cuDNN Specifies what type of RNN operation to perform
   */
  cudnnRNNMode_t _rnnMode;

  /**
  * @brief cuDNN Descriptor for the hidden state tensor memory
  */
  cudnnTensorDescriptor_t _hTensorDesc;

  /**
  * @brief cuDNN Device memory pointers for the internal layer's hidden state input
  */
  std::vector<void *> _hStateTensor;

  /**
   * @brief cuDNN Device memory pointers for the internal layer's hidden state input gradients
   */
  std::vector<void *> _hGradientTensor;

  /**
  * @brief cuDNN descriptor for the dropout operator
  */
  cudnnDropoutDescriptor_t _dropoutDesc;

  /**
   * @brief cuDNN descriptor for the RNN operator
   */
  cudnnRNNDescriptor_t _rnnDesc;

  /**
  * @brief cuDNN Device memory pointers for layer's weights
  */
  void *_weightsTensor;

  /**
  * @brief cuDNN Device memory pointers for layer's weight gradients
  */
  void *_weightsGradientTensor;

  /**
  * @brief cuDNN Device RNN data descriptor for the input
  */
  cudnnRNNDataDescriptor_t _inputRNNDataDesc;

  /**
  * @brief cuDNN Device RNN data descriptor for the output
  */
  cudnnRNNDataDescriptor_t _outputRNNDataDesc;

  /**
  * @brief cuDNN Device memory pointer to of all gate weights
  */
  std::vector<void *> _gateWeightTensors;

  /**
   * @brief cuDNN Device memory pointer to of all gate biases
   */
  std::vector<void *> _gateBiasTensors;

  /**
   * @brief cuDNN Weights size
   */
  size_t _weightsSize;

  /**
   * @brief cuDNN Workspace size
   */
  size_t _workSpaceSize;

  /**
   * @brief cuDNN reserve space size
   */
  size_t _reserveSpaceSize;

  /**
  * @brief cuDNN Device memory pointers for workspace tensor
  */
  std::vector<void *> _workSpaceTensor;

  /**
   * @brief cuDNN Device memory pointers for reserve space tensor
   */
  std::vector<void *> _reserveSpaceTensor;

  /**
   * @brief cuDNN Device memory for sequence lenght array
   */
  int *_devSequenceLengths;

#endif

  void initialize() override;
  void createHyperparameterMemory() override;
  void backwardHyperparameters(const size_t t) override;
  void createBackwardPipeline() override;
  void copyHyperparameterPointers(Layer *dstLayer);
  std::vector<float> generateInitialHyperparameters() override;
  void setHyperparameters(float *hyperparameters) override;
  void getHyperparameters(float *hyperparameters) override;
  void getHyperparameterGradients(float *gradient) override;
};

@endNamespace

@endIncludeGuard
