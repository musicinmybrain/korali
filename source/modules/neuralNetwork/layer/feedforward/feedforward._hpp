#ifndef _KORALI_LAYER_FEED_FORWARD_HPP_
#define _KORALI_LAYER_FEED_FORWARD_HPP_

#include "modules/neuralNetwork/layer/layer.hpp"

namespace korali
{
namespace neuralNetwork
{
namespace layer
{
class FeedForward : public Layer
{
  public:

 /********************************************************
 * Engine specific members
 *******************************************************/

#ifdef _KORALI_USE_EIGEN

 /**
* @brief Contains the output of the inner product (Wx+b) operation
*/
 float *_weightsOutputValues;

 /**
* @brief Contains the gradients of the output of the inner product (Wx+b) operation
*/
 float *_weightsOutputGradient;

 /**
* @brief Contains the values of the weights
*/
 float *_weightValues;

 /**
* @brief Contains the gradients of the weights
*/
 float *_weightGradient;

 /**
* @brief Contains the values of the bias
*/
 float *_biasValues;

 /**
* @brief Contains the gradients of the bias
*/
 float *_biasGradient;

#endif

#ifdef _KORALI_USE_ONEDNN

 /********************************************************
* oneDNN Layers's Memory Structures for Forward Propagation
*******************************************************/

 /**
 * @brief oneDNN Memory object descriptor to contain the output of the inner product (Wx+b) operation
 */
 dnnl::memory _weightsOutputMem;

 /**
 * @brief oneDNN Gradients of the output of the inner product (Wx+b) operation
 */
 dnnl::memory _weightsOutputGradientMem;

 /**
 * @brief oneDNN Memory object descriptor to contain the weights of inner product with incoming channels
 */
 dnnl::memory _weightsMem;

 /**
 * @brief oneDNN Memory object descriptor to contain the bias to add to incoming channels
 */
 dnnl::memory _biasMem;

 /********************************************************
* Declaring Layers's Memory Structures for Gradients
*******************************************************/

 /**
 * @brief oneDNN Memory object descriptor to contain the gradient of the weights
 */
 dnnl::memory _weightsGradientMem;

 /**
 * @brief oneDNN Memory object descriptor to contain the gradient of the biases
 */
 dnnl::memory _biasGradientMem;

 /*****************************************************************
* Declaring Layers's Forward Activation Function Primitive Configuration
******************************************************************/

 /**
 * @brief oneDNN Algorithm chosen for activation function
 */
 dnnl::algorithm _activationAlgorithm;

 /**
 * @brief oneDNN Arguments to the activation function
 */
 std::unordered_map<int, dnnl::memory> _forwardActivationArgs;

 /**
 * @brief oneDNN primitive attributes that describe a softmax activation function
 */
 dnnl::softmax_forward::primitive_desc _forwardSoftmaxActivationPrimitiveDesc;

 /**
 * @brief oneDNN primitive attributes that describe an element-wise activation function
 */
 dnnl::eltwise_forward::primitive_desc _forwardEltwiseActivationPrimitiveDesc;

 /**
 * @brief oneDNN primitive to run the activation function operation
 */
 dnnl::primitive _forwardActivationPrimitive;

 /*****************************************************************
 * Declaring Layers's Forward Inner Product Primitive Configuration
 ******************************************************************/

 /**
 * @brief oneDNN Arguments to the inner product operation
 */
 std::unordered_map<int, dnnl::memory> _forwardInnerProductArgs;

 /**
 * @brief oneDNN primitive attributes that describe the full forward propagation primitive
 */
 dnnl::inner_product_forward::primitive_desc _forwardInnerProductPrimitiveDesc;

 /**
 * @brief oneDNN primitive to run the inner product + bias addition operation
 */
 dnnl::primitive _forwardInnerProductPrimitive;

 /*****************************************************************
 * Declaring Layers's Backward Propagation Configuration
 ******************************************************************/

 /**
 * @brief oneDNN Arguments for the backward propagation of the gradient wrt activation functions
 */
 std::unordered_map<int, dnnl::memory> _backwardActivationArgs;

 /**
 * @brief oneDNN primitive for the backward propagation of the gradient wrt activation functions
 */
 dnnl::primitive _backwardActivationPrimitive;

 /**
 * @brief oneDNN Arguments for the backward propagation of the gradient wrt Data
 */
 std::unordered_map<int, dnnl::memory> _backwardDataArgs;

 /**
 * @brief oneDNN primitive for the backward propagation of the gradient wrt Data
 */
 dnnl::primitive _backwardDataPrimitive;

 /**
 * @brief oneDNN Arguments for the backward propagation of the gradient wrt Weights and Biases
 */
 std::unordered_map<int, dnnl::memory> _backwardWeightsArgs;

 /**
 * @brief oneDNN primitive for the backward propagation of the gradient wrt Weights and Biases
 */
 dnnl::primitive _backwardWeightsPrimitive;

#endif

#ifdef _KORALI_USE_CUDNN

 /**
 * @brief cuDNN Device memory pointer for the output of the inner product (Wx+b) operation
 */
 void *_weightsOutputTensor;

 /**
 * @brief cuDNN Device memory pointer for the gradients of the output of the inner product (Wx+b) operation
 */
 void *_weightsOutputGradientTensor;

 /**
 * @brief cuDNN Descriptor for the filter weights
 */
 cudnnFilterDescriptor_t _weightsFilterDesc;

 /**
 * @brief cuDNN Device memory pointer for the filter weights
 */
 void *_weightsFilter;

 /**
 * @brief cuDNN Device memory pointer for the filter weights gradients
 */
 void *_weightsGradientFilter;

 /**
 * @brief cuDNN Descriptor for the bias memory
 */
 cudnnTensorDescriptor_t _biasTensorDesc;

 /**
 * @brief cuDNN Device memory pointer for the bias tensor
 */
 void *_biasTensor;

 /**
 * @brief cuDNN Device memory pointer for the bias gradients
 */
 void *_biasGradientTensor;

 /**
 * @brief cuDNN Descriptor for the convolution operation
 */
 cudnnConvolutionDescriptor_t _convolutionDesc;

 /**
 * @brief cuDNN Placeholder for the convolution workspace size (bytes)
 */
 size_t _convolutionWorkspaceSize;

 /**
 * @brief cuDNN Device memory pointer for the convolution workspace
 */
 void *_convolutionWorkspace;

 /**
 * @brief cuDNN Descriptor for the activation function
 */
 cudnnActivationDescriptor_t _activationDesc;

#endif

  void forwardActivationFunction();
  void backwardActivationFunction();

  std::vector<float> generateInitialHyperparameters() override;
  void createHyperparameterMemory() override;
  void createForwardPipeline() override;
  void createBackwardPipeline() override;
  void forwardData() override;

  void setHyperparameters(float *hyperparameters) override;
  void getHyperparameters(float *hyperparameters) override;
  void getHyperparameterGradients(float *gradient) override;
  void backwardData() override;
  void backwardHyperparameters() override;
};

} // namespace layer

} // namespace neuralNetwork

} // namespace korali

#endif // _KORALI_LAYER_FEED_FORWARD_HPP_
