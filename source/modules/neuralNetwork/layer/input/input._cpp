#include "modules/neuralNetwork/layer/input/input.hpp"
#include "modules/neuralNetwork/neuralNetwork.hpp"

#ifdef _KORALI_USE_CUDNN
  #include "auxiliar/cudaUtils.hpp"
#endif

#ifdef _KORALI_USE_ONEDNN
  #include "auxiliar/dnnUtils.hpp"
using namespace dnnl;
#endif

#ifdef _KORALI_USE_EIGEN
  #include <Eigen/Dense>
using namespace Eigen;
#endif

namespace korali
{
namespace neuralNetwork
{
namespace layer
{

void Input::initialize()
{
 // Checking Layer size
 if (_outputChannels == 0) KORALI_LOG_ERROR("Output Channels for layer (%lu) should be larger than zero.\n", _index);

 // Checking position
 if (_index != 0) KORALI_LOG_ERROR("Input layers can only be placed at the start of the NN\n");
}

void Input::forwardData()
{
 size_t N = _nn->_batchSize;
 size_t OC = _outputChannels;
 int t = _nn->_currentTimestep;

 if (_nn->_batchInputData.size() != N * OC)
  KORALI_LOG_ERROR("Wrong size of batch input NN parameters: %lu. Expected: %lu\n", _nn->_batchInputData.size(), N * OC);

 #ifdef _KORALI_USE_EIGEN
   if (_nn->_engine == "Korali")
   {
     memcpy(_outputValues, _nn->_batchInputData.data(), N * OC * sizeof(float));
   }
 #endif

 #ifdef _KORALI_USE_ONEDNN
   if (_nn->_engine == "OneDNN")
   {
     write_to_dnnl_memory(_nn->_batchInputData.data(), _outputMem);
   }
 #endif

 #ifdef _KORALI_USE_CUDNN
   if (_nn->_engine == "CuDNN")
   {
     cudaErrCheck(cudaMemcpy(_outputTensor[t], _nn->_batchInputData.data(), N * OC * sizeof(float), cudaMemcpyHostToDevice));
   }
 #endif
}

void Input::backwardData()
{
  int N = _nn->_batchSize;
  int OC = _outputChannels;
  int t = _nn->_currentTimestep;

  if (_nn->_batchInputGradients.size() != N * OC)
   KORALI_LOG_ERROR("Wrong size of batch input gradients NN parameters: %lu. Expected: %lu\n", _nn->_batchInputGradients.size(), N * OC);

  #ifdef _KORALI_USE_EIGEN
    if (_nn->_engine == "Korali")
    {
      memcpy(_nn->_batchInputGradients.data(), _outputGradient, N * OC * sizeof(float));
    }
  #endif

  #ifdef _KORALI_USE_ONEDNN
    if (_nn->_engine == "OneDNN")
    {
      read_from_dnnl_memory(_nn->_batchInputGradients.data(), _outputGradientMem);
    }
  #endif

  #ifdef _KORALI_USE_CUDNN
    if (_nn->_engine == "CuDNN")
    {
      cudaErrCheck(cudaMemcpy(_nn->_batchInputGradients.data(), _outputGradientTensor[t], N * OC * sizeof(float), cudaMemcpyDeviceToHost));
    }
  #endif
}


} // namespace layer

} // namespace neuralNetwork

} // namespace korali
