#pragma once

#include "modules/neuralNetwork/layer/layer.hpp"

__startNamespace__;

class __className__ : public __parentClassName__
{
  public:
  /********************************************************
 * Engine specific members
 *******************************************************/

 /**
 * @brief Pre-calculated value for Mini-Batch Size
 */
 ssize_t N;

 /**
  * @brief Pre-calculated value for Input Channels
  */
 ssize_t IC;

 /**
  * @brief Pre-calculated value for Input Image Height
  */
 ssize_t IH;

 /**
  * @brief Pre-calculated value for Input Image Width
  */
 ssize_t IW;

 /**
  * @brief Pre-calculated value for Output Channels
  */
 ssize_t OC;

 /**
  * @brief Pre-calculated value for Output Image Height
  */
 ssize_t OH;

 /**
  * @brief Pre-calculated value for Output Image Width
  */
 ssize_t OW;

 /**
  * @brief Pre-calculated value for Kernel Image Height
  */
 ssize_t KH;

 /**
  * @brief Pre-calculated value for Kernel Image Width
  */
 ssize_t KW;

 /**
  * @brief Pre-calculated values for padding left
  */
 ssize_t PL;

 /**
  * @brief Pre-calculated values for padding right
  */
 ssize_t PR;

 /**
  * @brief Pre-calculated values for padding top
  */
 ssize_t PT;

 /**
  * @brief Pre-calculated values for padding bottom
  */
 ssize_t PB;

 /**
  * @brief Pre-calculated values for horizontal stride
  */
 ssize_t SH;

 /**
  * @brief Pre-calculated values for vertical stride
  */
 ssize_t SV;

#ifdef _KORALI_USE_ONEDNN

 /**
  * @brief Memory descriptor for the 2D mapping of the scalar input channels
  */
  dnnl::memory::desc _srcMemDesc;

  /**
   * @brief Memory descriptor for the 2D mapping of the scalar output channels
   */
  dnnl::memory::desc _dstMemDesc;

  /**
 * @brief oneDNN Memory object descriptor to contain the weights of inner product with incoming channels
 */
  dnnl::memory _weightsMem;

  /**
 * @brief oneDNN Memory object descriptor to contain the weights of inner product with incoming channels
 */
  dnnl::memory _weightsReorderMem;

  /**
 * @brief oneDNN Memory object descriptor to contain the bias to add to incoming channels
 */
  dnnl::memory _biasMem;

  /**
 * @brief oneDNN Memory object descriptor to contain the gradient of the weights
 */
  dnnl::memory _weightsGradientMem;

  /**
 * @brief oneDNN Memory object descriptor to contain the gradient of the biases
 */
  dnnl::memory _biasGradientMem;

  /**
 * @brief oneDNN primitive attributes that describe the forward deconvolution primitive
 */
  dnnl::deconvolution_forward::primitive_desc _forwardDeconvolutionPrimitiveDesc;

  /**
 * @brief oneDNN primitive to run the inner product + bias addition operation
 */
  dnnl::primitive _forwardDeconvolutionPrimitive;

  /**
 * @brief oneDNN Arguments for the backward propagation of the gradient wrt Data
 */
  std::unordered_map<int, dnnl::memory> _backwardDataArgs;

  /**
 * @brief oneDNN primitive for the backward propagation of the gradient wrt Data
 */
  dnnl::primitive _backwardDataPrimitive;

  /**
 * @brief oneDNN primitive for the backward propagation of the gradient wrt Weights and Biases
 */
  dnnl::primitive _backwardWeightsPrimitive;

#endif

  void copyHyperparameterPointers(Layer *dstLayer) override;
  void initialize() override;
  std::vector<float> generateInitialHyperparameters() override;
  void createHyperparameterMemory() override;
  void createForwardPipeline() override;
  void createBackwardPipeline() override;
  void forwardData(const size_t t) override;

  void setHyperparameters(float *hyperparameters) override;
  void getHyperparameters(float *hyperparameters) override;
  void getHyperparameterGradients(float *gradient) override;
  void backwardData(const size_t t) override;
  void backwardHyperparameters(const size_t t) override;
};

__endNamespace__;
