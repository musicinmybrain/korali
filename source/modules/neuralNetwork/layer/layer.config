{
 "Configuration Settings":
 [
   { 
    "Name": [ "Node Count" ],
    "Type": "size_t",
    "Description": "Indicates the node count of the current layer."
   },
   { 
    "Name": [ "Activation Function", "Type" ],
    "Type": "std::string",
    "Options": [
                { "Value": "Elementwise/Linear", "Description": "Transforms (s) input element-wise to alpha*s + beta. The default represents an identity transformation." },
                { "Value": "Elementwise/Tanh", "Description": "Applies the element-wise tanh function." },
                { "Value": "Elementwise/ReLU", "Description": "Applies an element-wise rectifier linear unit function." },
                { "Value": "Elementwise/Logistic", "Description": "Applies an element-wise logistic (sigmoid) function." },
                { "Value": "Elementwise/Clip", "Description": "Clips the input (s) to be clipped into the alpha < s < beta range." },
                { "Value": "Elementwise/Log", "Description": "Applies the element-wise log function." },
                { "Value": "Softmax", "Description": "Applies the layer-wide softmax operation." }
               ],
    "Description": "Indicates the activation function for the weighted inputs to the current layer."
   },
   { 
    "Name": [ "Activation Function", "Alpha" ],
    "Type": "float",
    "Description": "First (alpha) argument to the activation function, as detailed in https://oneapi-src.github.io/oneDNN/dev_guide_eltwise.html"
   },
   { 
    "Name": [ "Activation Function", "Beta" ],
    "Type": "float",
    "Description": "Second (beta) argument to the activation function, as detailed in https://oneapi-src.github.io/oneDNN/dev_guide_eltwise.html"
   }
 ],
 
  "Internal Settings":
 [
 ],
 
 "Module Defaults":
 {
  "Node Count": 0,
  "Activation Function":
  {
   "Alpha": 1.0,
   "Beta": 0.0
  }
 }
}
