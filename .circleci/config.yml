version: 2.1

executors:
  ubuntu_openmpi_onednn:
    docker:
      - image: docker.io/cselab/ubuntu_openmpi_onednn:latest
      
  fedora_openmpi_onednn:
    docker:
      - image: docker.io/cselab/fedora_openmpi_onednn:latest
  
  macos_openmpi_onednn:
    docker:
      - image: docker.io/cselab/macos_openmpi_onednn:latest      
      
jobs:
  build:
    parameters:
      image:
        type: executor
      CC:
        type: string
        default: gcc
      CXX:
        type: string
        default: g++
      buildtype:
        type: string
        default: debugoptimized
      runTests:
        type: string
        default: 'true'
      buildargs: 
        type: string
        default: "-Donednn_path=/usr/local -Dmpi=true"
    resource_class: xlarge
    executor: << parameters.image >>  
    working_directory: ~/korali
    steps:
      - checkout
      - run:
          name: Build and test and install
          command: |
            CC=<< parameters.CC >> CXX=<< parameters.CXX >> meson setup build --prefix=~/test_install << parameters.buildargs >> --buildtype=<< parameters.buildtype >>
            ninja -C build
            source tools/helper/set_env.sh build
            if [ "<< parameters.runTests >>" == "true" ]; then meson test -C build; fi
            meson install -C build
      - store_artifacts:
          path: build/meson-logs

workflows:
  korali_release:
    jobs:
      - build:
          name: ubuntu_openmpi_gcc
          image: ubuntu_openmpi_onednn
          buildtype: release
      - build:
          name: fedora_openmpi_gcc
          image: fedora_openmpi_onednn
          buildtype: release
      - build:
          name: macos_openmpi_clang
          image: macos_openmpi_onednn
          buildargs: ""
          CC: /home/linuxbrew/.linuxbrew/bin/clang
          CXX: /home/linuxbrew/.linuxbrew/bin/clang++
          runTests: 'false'
          buildtype: release
          